<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>BMMB554 | Fall 2016</title>
    <link>http://nekrut.github.io/BMMB554/</link>
    <description>Recent content on BMMB554 | Fall 2016</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 28 Nov 2016 16:20:10 -0500</lastBuildDate>
    <atom:link href="http://nekrut.github.io/BMMB554/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Assembly basics</title>
      <link>http://nekrut.github.io/BMMB554/post/topic12/</link>
      <pubDate>Mon, 28 Nov 2016 16:20:10 -0500</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic12/</guid>
      <description>

&lt;p&gt;Genome assembly is a difficult task. In trying to explain it I will be relying on two highly regarded sources:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;Ben Langmead&amp;rsquo;s Teaching Materials&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.amazon.com/Bioinformatics-Algorithms-Active-Learning-Approach/dp/0990374602&#34;&gt;Pevzner and Compeau Bioinformatics Book&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;genomes-and-reads-strings-and-k-mers&#34;&gt;Genomes and reads: Strings and &lt;em&gt;k&lt;/em&gt;-mers&lt;/h1&gt;

&lt;h2 id=&#34;k-mer-composition&#34;&gt;&lt;em&gt;k&lt;/em&gt;-mer composition&lt;/h2&gt;

&lt;p&gt;Genomes are strings of text. When we sequence genomes we use sequencing machines that generate reads. For now let&amp;rsquo;s assume that all reads have the same length &lt;em&gt;k&lt;/em&gt; and every &lt;em&gt;k&lt;/em&gt;-mer is sequenced only once. We will relax these assumptions at the end. Thus sequencing a genome generates a large list of &lt;em&gt;k&lt;/em&gt;-mers.&lt;/p&gt;

&lt;p&gt;Suppose we are dealing with a &lt;em&gt;very&lt;/em&gt; short genome &lt;code&gt;TATGGGGTGC&lt;/code&gt;. Its &lt;em&gt;k&lt;/em&gt;-mer composition (note the subscript) $Composition_k(Text)$ is the collection of all $k$-mer substrings (including repeated ones). When &lt;em&gt;k&lt;/em&gt; = 3 we get (basically we split sequence into windows of length 3 sliding window by 1 base every time):&lt;/p&gt;

&lt;div&gt;
$$
Composition_3(\texttt{TATGGGGTGC}) = \texttt{ATG, GGG, GGG, GGT, GTG, TAT, TGC, TGG}
$$
&lt;/div&gt;

&lt;p&gt;Note that we have listed &lt;em&gt;k&lt;/em&gt;-mers in lexicographic order (i.e., how they would appear in a dictionary) rather than in the order of their appearance in $\texttt{TATGGGGTGC}$. We have done this because the correct ordering of the reads is unknown when they are generated (i.e., a sequencing machine does not generate reads in any particular order).&lt;/p&gt;

&lt;h2 id=&#34;assembly-by-overlap&#34;&gt;Assembly by overlap&lt;/h2&gt;

&lt;p&gt;In the example above we know what the &amp;ldquo;genome&amp;rdquo; sequence is. In real life we don&amp;rsquo;t know that and our goal is to determine genome sequence given a scrambled collection of &lt;em&gt;k&lt;/em&gt;-mers. Let&amp;rsquo;s consider the following collection of 3-mers representing a hypothetical genome:&lt;/p&gt;

&lt;div&gt;
  $$
\texttt{AAT ATG GTT TAA TGT}
$$
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s &amp;ldquo;tile&amp;rdquo; &lt;em&gt;k&lt;/em&gt;-mers if they overlap in &lt;em&gt;k&lt;/em&gt;-1 nucleotides:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAA
 AAT
  ATG
   TGT
    GTT
-------
TAATGTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let&amp;rsquo;s apply it to slightly longer &amp;ldquo;genome&amp;rdquo; with the following 3-mer composition sorted in a lexicographic order:&lt;/p&gt;

&lt;div&gt;
  $$
  \texttt{AAT ATG ATG ATG CAT CCA GAT GCC GGA GGG GTT TAA TGC TGG TGT}
$$
&lt;/div&gt; 

&lt;p&gt;&lt;code&gt;TAA&lt;/code&gt; looks like a great beginning and we are continuing:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;1 TAA
2  AAT
3   ATG
4    TGT
5     GTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;There is nothing in the original 3-mer composition, which starts with &lt;code&gt;TT&lt;/code&gt;. Let&amp;rsquo;s track back and instead of &lt;code&gt;TGT&lt;/code&gt; in step 4 insert &lt;code&gt;TGC&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 1 TAA
 2  AAT
 3   ATG
 4    TGC
 5     GCC
 6      CCA
 7       CAT
 8        ATG
 9         TGG
10          GGA
11           GAT
12            ATG
13             TGT
14              GTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We only used 14 3-mers from the total of 15, so our genome is shorter (we have extra parts!). This difficulty is related to the fact that there are three repeated &lt;code&gt;ATG&lt;/code&gt; motifs in this genome and as a result each &lt;code&gt;ATG&lt;/code&gt; can be extended by either &lt;code&gt;TGG&lt;/code&gt;, &lt;code&gt;TGC&lt;/code&gt;, or &lt;code&gt;TGT&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;the-concept-of-coverage&#34;&gt;The concept of coverage&lt;/h2&gt;

&lt;p&gt;&lt;em&gt;Coverage&lt;/em&gt; is the number of reads covering a particular position in the genome. For example, in the following case:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAA
 AAT
  ATG     &amp;lt;- &amp;quot;reads&amp;quot; (15 bases total)
   TGT
    GTT
-------
TAATGTT   &amp;lt;- &amp;quot;genome&amp;quot; (7 bases)
-------
0123456    
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The &lt;em&gt;Coverage&lt;/em&gt; at positions 1 and 6 is &lt;em&gt;1&lt;/em&gt;, at positions 1 and 5 is &lt;em&gt;2&lt;/em&gt;, and at position 2, 3, and 4 is &lt;em&gt;3&lt;/em&gt;. &lt;br&gt;The &lt;em&gt;Average Coverage&lt;/em&gt; will be $\frac{15}{7}\approx2\times$&lt;/p&gt;

&lt;p&gt;Below is another, slightly more realistic example where average coverage is $\frac{177}{35}\approx7\times$&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                  CTAGGCCCTCAATTTTT
                CTCTAGGCCCTCAATTTTT
              GGCTCTAGGCCCTCATTTTTT
           CTCGGCTCTAGCCCCTCATTTT
        TATCTCGACTCTAGGCCCTCA         &amp;lt;- 177 bases
        TATCTCGACTCTAGGCC
    TCTATATCTCGGCTCTAGG
GGCGTCTATATCTCG
GGCGTCGATATCT
GGCGTCTATATCT
-----------------------------------
GGCGTCTATATCTCGGCTCTAGGCCCTCATTTTTT   &amp;lt;- 35 bases
-----------------------------------
|         |         |         |   |
0         10        20        30  34
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;the-first-and-the-second-laws-of-assembly&#34;&gt;The First and the Second laws of assembly&lt;/h1&gt;

&lt;p&gt;The goal of assembly process is to reconstruct an unknown genome sequence given a collection of scrambled sequencing reads:&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;CTAGGCCCTCAATTTTT
CTCTAGGCCCTCAATTTTT
GGCTCTAGGCCCTCATTTTTT
CTCGGCTCTAGCCCCTCATTTT
TATCTCGACTCTAGGCCCTCA                 &amp;lt;- Reads (Given)
TATCTCGACTCTAGGCC
TCTATATCTCGGCTCTAGG
GGCGTCTATATCTCG
GGCGTCGATATCT
GGCGTCTATATCT
-----------------------------------
???????????????????????????????????   &amp;lt;- Genome (Unknown)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;The goal of assembly process&lt;/strong&gt;. Given sequencing reads reconstruct underlying genome sequence.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We&amp;rsquo;ve seen that this can (in principle) be accomplished by finding overlaps. We also discussed the concept of the coverage.  We can now formulate the two first assembly laws.&lt;/p&gt;

&lt;h2 id=&#34;the-first-assembly-law-overlaps-imply-co-location&#34;&gt;The First Assembly Law: Overlaps imply co-location&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s define terms &lt;strong&gt;Prefix&lt;/strong&gt; and &lt;strong&gt;Suffix&lt;/strong&gt; using string $\texttt{TAA}$ as an example:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$Prefix(\texttt{TAA}) = \texttt{TA}$&lt;/li&gt;
&lt;li&gt;$Suffix(\texttt{TAA}) = \texttt{AA}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The First law states that if a &lt;em&gt;suffix&lt;/em&gt; of one read is similar to a &lt;em&gt;prefix&lt;/em&gt; of another read&amp;hellip;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TCTATATCTCGGCTCTAGG    &amp;lt;- read 1
    ||||||| ||||||| 
    TATCTCGACTCTAGGCC  &amp;lt;- read 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&amp;hellip;then they may overlap (may be derived from the same location) within the genome.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;      TCTATATCTCGGCTCTAGG                  &amp;lt;- read 1
 -------------------------------------
 AGCGTTCTATATCTCGGCTCTAGGCCGTGCAGGACGT     &amp;lt;- genome
 -------------------------------------
          TATCTCGACTCTAGGCC                &amp;lt;- read 2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note that in the above example suffix of the first read is &lt;em&gt;not&lt;/em&gt; exactly identical to the prefix of the second read: they differ by a G-to-A substitution. Such differences are quite common in real life and may be caused by:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;sequencing errors&lt;/strong&gt; - experimental or computational artifacts of DNA sequencing procedures.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;allelic differences&lt;/strong&gt; - organisms such as human are diploid (and others, such as wheat are hexaploid) which maternal and paternal genomes being different at a number of genomic sites.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;polymorphic sites&lt;/strong&gt; - DNA that is being sequenced is usually isolated from a large number of cells (e.g., white blood cells) or individuals (bacterial and viral cultures). Natural variation present in these cell (or viral particle) populations will manifest itself as these differences.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;the-second-assembly-law-the-higher-the-coverage-the-better&#34;&gt;The Second Assembly Law: The higher the coverage, the better&lt;/h2&gt;

&lt;p&gt;The Second law states that higher coverage leads to more frequent and longer overlaps:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                   CTAGGCCCTCAATTTTT
         TATCTCGACTCTAGGCCCTCA         &amp;lt;- Low coverage
 GGCGTCTATATCT
 -----------------------------------
 GGCGTCTATATCTCGGCTCTAGGCCCTCATTTTTT   &amp;lt;- Genome
 -----------------------------------
                   CTAGGCCCTCAATTTTT
                 CTCTAGGCCCTCAATTTTT
               GGCTCTAGGCCCTCATTTTTT
            CTCGGCTCTAGCCCCTCATTTT
         TATCTCGACTCTAGGCCCTCA         &amp;lt;- Higher coverage
         TATCTCGACTCTAGGCC
     TCTATATCTCGGCTCTAGG
 GGCGTCTATATCTCG
 GGCGTCGATATCT
 GGCGTCTATATCT
&lt;/code&gt;&lt;/pre&gt;

&lt;h1 id=&#34;solving-assembly-problem-with-graphs&#34;&gt;Solving assembly problem with graphs&lt;/h1&gt;

&lt;p&gt;We can solve assembly challenge using overlaps between sequencing reads. However, to solve this problem effectively we need to first represent all overlaps in a way that would facilitate further analysis. &lt;em&gt;Directed graphs&lt;/em&gt; help achieving this.&lt;/p&gt;

&lt;h2 id=&#34;directed-graphs&#34;&gt;Directed graphs&lt;/h2&gt;

&lt;p&gt;Finding overlaps is identical to building a &lt;em&gt;directed graph&lt;/em&gt; where directed &lt;em&gt;edges&lt;/em&gt; connect &lt;em&gt;nodes&lt;/em&gt; representing overlapping reads:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dag.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Directed graph&lt;/strong&gt; representing overlapping reads. (Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/assembly_scs.pdf&#34;&gt;Ben Langmead&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, the following string reconstruction:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 1 TAA
 2  AAT
 3   ATG
 4    TGC
 5     GCC
 6      CCA
 7       CAT
 8        ATG
 9         TGG
10          GGA
11           GAT
12            ATG
13             TGT
14              GTT
   TAATGCCATGGATGTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;can be represented as a following directed graph (or genome path):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Genome path&lt;/strong&gt;. Trimers composing the $\texttt{TAATGCCATGGGATGTT}$ sequence represented as the &amp;ldquo;genome&amp;rdquo; path. (Fig. 4.6 from CP). In this path a suffix of a 3-mer is equal to prefix of the next 3-mer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;However&lt;/strong&gt;, we do not know the actual genome! All we have in real life is a collection of reads. Let&amp;rsquo;s first build an overlap graph by connecting two 3-mers if suffix of one is equal to the prefix of the other:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Overlap graph&lt;/strong&gt;. All possible overlap connections for our 3-mer collection. (Fig. 4.7 from CP)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;So to determine the sequence of the underlying genome we are looking a path in this graph that visits every node (3-mer) once. Such path is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamiltonian_path&#34;&gt;Hamiltonial path&lt;/a&gt; and it may not be unique. For example for our 3-mer collection there two possible Hamiltonian paths:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.9a.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.9b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Two Hamiltonian paths for the 15 3-mers&lt;/strong&gt;. Edges spelling &amp;ldquo;genomes&amp;rdquo; $\texttt{TAATGCCATGGGATGTT}$ and $\texttt{TAATGGGATGCCATGTT}$ are highlighted in black. (Fig. 4.9. from CP).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The reason for this &amp;ldquo;duality&amp;rdquo; is the fact that we have a &lt;em&gt;repeat&lt;/em&gt;: 3-mer $\texttt{ATG}$ is present twice on our data (red and blue). As we will see later repeats cause a lot of trouble in genome assembly.&lt;/p&gt;

&lt;h2 id=&#34;finding-overlaps&#34;&gt;Finding overlaps&lt;/h2&gt;

&lt;p&gt;In the example above we had a collection of 3-mers and were always looking for overlaps of length two. In real life things may not be so &amp;ldquo;regular&amp;rdquo;. Suppose we have two reads:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Read X CTCTAGGCC
Read Y TAGGCCCTC
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;what is the overlap between these two reads? For now we will define overlap of $length - l$ suffix of Read X matches $length - l$ prefix of Read Y, where $l$ is given. To find these overlap we look in Read Y for instances $length - l$ suffix of Read X. We will start with some minimal match of length $k$. Once a match is found it will be extended to the left to verify that the entire prefix of Read Y matches:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/find_overlap.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding overlaps&lt;/strong&gt; between Read X and Read Y (Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/assembly_scs.pdf&#34;&gt;Ben Langmead&lt;/a&gt;). As a result we represent two two reads are connected nodes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/og1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Number above the edge shows the length of the overlap.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While with just two reads the problem may seen quite straightforward. Let now consider a set of reads representing a very short genome $\texttt{GTACGTACGAT}$:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GTACGT
TACGTA
CGTACG
ACGTAC
GTACGA
TACGAT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Building an overlap graph with overlap of $length \geq 4$ will give us the following:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/og2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see that there is a path through this graph that would spell out the original genome sequence $\texttt{GTACGTACGAT}$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/og3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here we are lucky enough to have all nodes having a single outgoing edge with the highest number (the length of overlap).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;the-shortest-common-superstring-problem&#34;&gt;The Shortest Common Superstring Problem&lt;/h2&gt;

&lt;p&gt;The problem of reconstructing genome using the overlap graph that we have just illustrated can be initially formulated as the &lt;em&gt;Shortest Common Superstring (SCS)&lt;/em&gt; problem. It states: &lt;em&gt;given a collection of strings S, find SCS(S), which is the shortest string that contains all strings from the set S as substrings&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;For simplicity let&amp;rsquo;s suppose that we have the following set of strings $S$:&lt;/p&gt;

&lt;div&gt;
  $$
  S: \texttt{BAA AAB BBA ABA ABB BBB AAA BAB}
  $$
&lt;/div&gt;

&lt;p&gt;one way of getting a string that would contain all of these as substrings will simply be concatenating them:&lt;/p&gt;

&lt;div&gt;
  $$
  Concat(S):  \texttt{BAAAABBBAABAABBBBBAAABAB}\ (length = 24)
$$
&lt;/div&gt;

&lt;p&gt;this, however, is not the &lt;em&gt;shortest&lt;/em&gt; superstring that contains all strings from $S$. Instead the SCS is (just trust us here):&lt;/p&gt;

&lt;div&gt;
  $$
  SCS(S): \texttt{AAABBBABAA}\ (length = 10)
  $$
  &lt;/div&gt;

&lt;p&gt;It looks like finding SCS for a set of sequencing reads may just be what we need to produce a genome assembly. But how can this work in practice? One potential idea is to order the strings in some way and &amp;ldquo;reduce&amp;rdquo; them into a superstring (following examples are from Ben Langmead):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s look at the first two strings. They can be &amp;ldquo;reduced&amp;rdquo; to &lt;code&gt;AAAB&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The next two add an &lt;code&gt;A&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Third and fourth add &lt;code&gt;BB&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Continuing this we will eventually get &lt;code&gt;AAABABBAABABBABB&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;But &lt;code&gt;AAABABBAABABBABB&lt;/code&gt; is the shortest only for this particular ordering. So let&amp;rsquo;s reorder and try again:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/scs6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we did better, but maybe we can do even better.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Ultimately we need to try all possible ordering and pick the shortest among all. Using this approach is we have $S$ strings we will need to do $S!$ tries. This can quickly get impossible. For our set of
eight strings $8! = 40320$. If we get, say, a 1,000,000 reads from an Illumina machine then the factorial of a million is not going to be an attractive analysis option.&lt;/p&gt;

&lt;h2 id=&#34;shortest-common-superstring-greedy-approach&#34;&gt;Shortest common superstring: Greedy approach&lt;/h2&gt;

&lt;p&gt;As we&amp;rsquo;ve seen it will be impossible to assemble the genome using SCS logic. There is a simplification called &lt;em&gt;Greedy&lt;/em&gt; approach to SCS problem. Let&amp;rsquo;s take the following set of &amp;ldquo;reads&amp;rdquo;:&lt;/p&gt;

&lt;div&gt;
  $$
  S: \texttt{AAA AAB ABB BBA BBB}
  $$
&lt;/div&gt;

&lt;p&gt;and first build an overlap graph:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An overlap graph&lt;/strong&gt; for set $S: \texttt{AAA AAB ABB BBA BBB}$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next, we start collapsing the nodes to maximize the overlap (and hence to decrease the length of the SCS we are trying to construct):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;In the graph below there are multiple ties: nodes with outgoing edges of identical weights (e.g., edges pointing from &lt;code&gt;ABB&lt;/code&gt; to both &lt;code&gt;BBA&lt;/code&gt; and &lt;code&gt;BBB&lt;/code&gt; have weight of two. Remember, that the weight is the length of overlap between two nodes&amp;rsquo; labels). In this situation we will break ties by randomly picking an edge to traverse. Let&amp;rsquo;s pick &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AAA&lt;/code&gt; &amp;#8594; &lt;code&gt;AAB&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We then merge &lt;code&gt;AAA&lt;/code&gt; and &lt;code&gt;AAB&lt;/code&gt; into an SCS containing both, which will be &lt;code&gt;AAAB&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now let&amp;rsquo;s pick edge &lt;font color=&#34;red&#34;&gt;&lt;code&gt;ABB&lt;/code&gt; &amp;#8594; &lt;code&gt;BBB&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Collapse the nodes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Pick &lt;font color=&#34;red&#34;&gt;&lt;code&gt;ABBB&lt;/code&gt; &amp;#8594; &lt;code&gt;BBA&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Collapse the nodes:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Pick &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AAAB&lt;/code&gt; &amp;#8594; &lt;code&gt;ABBBA&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Collapse again and now we are left with a superstring of length 7:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above procedure can be computed &lt;em&gt;very&lt;/em&gt; quickly. But there is a catch: it does not guarantee that it will give us truly the shortest superstring. It really depends on how we choose edges. Below is another example of using the same dataset in which we traverse graph an a slightly different way:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We start the same way as before by choosing &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AAA&lt;/code&gt; &amp;#8594; &lt;code&gt;AAB&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Merge &lt;code&gt;AAA&lt;/code&gt; and &lt;code&gt;AAB&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;But now we pick a different edge &lt;font color=&#34;red&#34;&gt;&lt;code&gt;ABB&lt;/code&gt; &amp;#8594; &lt;code&gt;BBA&lt;/code&gt;&lt;/font&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy4_alt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Collapsing these nodes dramatically changes the graph:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy5_alt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we pick &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AAAB&lt;/code&gt; &amp;#8594; &lt;code&gt;ABBA&lt;/code&gt;&lt;/font&gt; as this is the edge with the highest weight:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy6_alt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Collapsing it produces two nodes that are not connected to each other:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/greedy7_alt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And the SCS of these two will be a concatenation &lt;code&gt;AAABBABBB&lt;/code&gt; of length 9. Thus a greedy approach may produce different answers. However, it is a sufficient approximation as the superstring yielded this way will not be more than ~2.5 times longer than the true SCS (&lt;a href=&#34;https://www.amazon.com/Algorithms-Strings-Trees-Sequences-Computational/dp/0521585198&#34;&gt;Gusfield&lt;/a&gt; 16.17.1).&lt;/p&gt;

&lt;h1 id=&#34;the-third-law-of-assembly-repeats-are-evil&#34;&gt;The Third Law of Assembly: Repeats are Evil!&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s again apply Greedy SCS to a different &amp;ldquo;genome&amp;rdquo;. Suppose we want to reconstruct the phrase:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a_long_long_long_time 
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;from all 6-mers that overlap by at least 3 characters. The list of 6-mers is:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ng_lon 
_long_
a_long
long_l 
ong_ti
ong_lo
long_t
g_long
g_time
ng_tim
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;An overlap graph will look like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/long.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;An overlap graph&lt;/strong&gt; for with overlap length $\geq 3$.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we proceed with Greedy SCS we will follow the following trajectory through the graph:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/long_opt.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;To make things even clearer let&amp;rsquo;s isolate the path:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/long_opt_focus.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The total overlap here (the sum of edge weights) is 4+5+5+5+5+5+5+5+5=44 but it gives us &lt;code&gt;a_long_long_time&lt;/code&gt; as the shortest superstring:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a_long
  long_l
   ong_lo
    ng_lon
     g_long
      _long_
       long_t
        ong_ti
         ng_tim
          g_time
----------------
a_long_long_time
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;p&gt;We are missing one instance of &amp;lsquo;long&amp;rsquo; in this string. The following graph shows the path that would return the &lt;em&gt;correct&lt;/em&gt; string:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/long_corr.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A path yielding the correct string with three repeats. The total overlap here is 5+3+3+5+4+4+5+5+5=39, which is &lt;em&gt;worse&lt;/em&gt; than the previous path if our goal is to find the shortest superstring:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;a_long
 _long_
    ng_lon
       long_l
        ong_lo
          g_long
            long_t
             ong_ti
              ng_tim
               g_time
---------------------
a_long_long_long_time
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;are-we-really-looking-for-the-shortest-superstring&#34;&gt;Are we really looking for the shortest superstring?&lt;/h2&gt;

&lt;p&gt;As we&amp;rsquo;ve seen above the shortest common superstring (SCS) is:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Difficult to obtain&lt;/strong&gt; as Greedy SCS algorithm does not guarantee funding it. So the answer we get may be longer that the real genome we are trying to assemble.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;May be shorter than we want&lt;/strong&gt; because if the genome contains repeats that are longer than the reads we are using, Greedy SCS will collapse them and make assembly shorter that the genome we are trying to get.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Let&amp;rsquo;s talk about an alternative way to represent the relationship between &lt;em&gt;k&lt;/em&gt;-mers that may give us a more efficient algorithm.&lt;/p&gt;

&lt;h1 id=&#34;de-bruijn-graphs&#34;&gt;de Bruijn graphs&lt;/h1&gt;

&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Nicolaas_Govert_de_Bruijn&#34;&gt;Nicolaas de Bruijn&lt;/a&gt; had a purely theoretical interest of constructing &lt;em&gt;k&lt;/em&gt;-universal strings for an arbitrary value of &lt;em&gt;k&lt;/em&gt;. A &lt;em&gt;k&lt;/em&gt;-universal string contains every possible &lt;em&gt;k&lt;/em&gt;-mer only once:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nature.com/nbt/journal/v29/n11/abs/nbt.2023.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/deBruijn.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;de Bruijn graph&lt;/strong&gt;. From &lt;a href=&#34;http://www.nature.com/nbt/journal/v29/n11/abs/nbt.2023.html&#34;&gt;Compeau:2011&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This problem is equivalent to a string reconstruction problem we have been talking about above: finding a &lt;em&gt;k&lt;/em&gt;-universal string is equivalent to finding a Hamiltonian path in an overlap graph constructed from all &lt;em&gt;k&lt;/em&gt;-mers. Yet finding a Hamiltonian path in a really large graph (representing a real genome) is not a tractable problem as we have seen. Instead de Bruijn decided to represent &lt;em&gt;k&lt;/em&gt;-mer composition in a graph using a slightly different logic. Again, suppose we have a &amp;ldquo;genome&amp;rdquo; $\texttt{TAATGCCATGGGATGTT}$ split in a collection of 3-mers:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAA AAT ATG TGC GCC CCA CAT ATG TGG GGG GGA GAT ATG TGT GTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We will assign 3-mers to &lt;em&gt;edges&lt;/em&gt; instead or &lt;em&gt;nodes&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.12.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;k&lt;/em&gt;-mers as edges&lt;/strong&gt;. Edges represented by 3-mers connect nodes representing the overlaps. (Fig. 4.12 from CP)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This graph can be simplified by gluing identical nodes together:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here the complexity of the graph is reduced by first gluing redundant &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AT&lt;/code&gt;&lt;/font&gt; nodes&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13c.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13d.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Next, &lt;font color=&#34;blue&#34;&gt;&lt;code&gt;TG&lt;/code&gt;&lt;/font&gt; nodes are merged&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13e.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13f.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;And, finally the two &lt;font color=&#34;green&#34;&gt;&lt;code&gt;GG&lt;/code&gt;&lt;/font&gt; nodes are resolved. (Fig. 4.13 from CP)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Because we now represent &lt;em&gt;k&lt;/em&gt;-mers as edges (rather than nodes), our problem has morphed into finding a path that visits every &lt;em&gt;edge&lt;/em&gt; once, or an &lt;a href=&#34;https://en.wikipedia.org/wiki/Eulerian_path&#34;&gt;Eulerian Path&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.15.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Eulerian paths for the 15 3-mers&lt;/strong&gt;. Numbering of edges provides a way to reconstruct the original &amp;ldquo;genome&amp;rdquo;. (Fig. 4.15 from CP)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;euler-s-theorem&#34;&gt;Euler&amp;rsquo;s Theorem&lt;/h2&gt;

&lt;p&gt;Some definitions:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Balanced node&lt;/strong&gt; - a node where the number of incoming edges is equal to the number of outgoing edges&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Balanced graph&lt;/strong&gt; - a graph where all nodes are balanced&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Strongly connected graph&lt;/strong&gt; - any node can be reached from any other node&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Euler&amp;rsquo;s Theorem&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Every balanced, strongly connected directed graph is Eulerian.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s apply Euler&amp;rsquo;s Theorem to a classical problem: The bridges of Köninsberg problem. Here the question is: &lt;em&gt;Can you walk through all of Köninsberg traversing every bridge exactly one time?&lt;/em&gt; In other words: &lt;em&gt;Is there a Eulerian path through the city of Köninsberg?&lt;/em&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/koninsberg.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Köninsberg and Euler&amp;rsquo;s Theorem&lt;/strong&gt;. (a) A map of old Königsberg, in which each area of the city is labeled with a different color point. (b) The Königsberg Bridge graph, formed by representing each of four land areas as a node and each of the city&amp;rsquo;s seven bridges as an edge. (From &lt;a href=&#34;http://www.nature.com/nbt/journal/v29/n11/abs/nbt.2023.html#close&#34;&gt;Campeau:2011&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;By looking at this graph we can see that it is &lt;em&gt;unblanaced&lt;/em&gt;. If one arrives to, say, the &lt;font color=&#34;orange&#34;&gt;orange&lt;/font&gt; node from the &lt;font color=&#34;blue&#34;&gt;blue&lt;/font&gt; node there are two ways to get out. Thus there is no way to see all of the city and traverse every bridge once!&lt;/p&gt;

&lt;h2 id=&#34;repeats-are-still-a-challenge&#34;&gt;Repeats are still a challenge&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s look at the de Bruijn graph from above again. But this time let&amp;rsquo;s drop edge numbering and pretend that the genome is now really known to us (as is usually the case in real life):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dg1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Eulerian paths for the 15 3-mers&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the original sequence &lt;code&gt;TAATGCCATGGGATGTT&lt;/code&gt; &lt;em&gt;k&lt;/em&gt;-mer &lt;font color=&#34;red&#34;&gt;&lt;code&gt;AT&lt;/code&gt;&lt;/font&gt; is present 3 times and &lt;em&gt;k&lt;/em&gt;-mer &lt;font color=&#34;blue&#34;&gt;&lt;code&gt;TG&lt;/code&gt;&lt;/font&gt; is found twice. Thus &lt;em&gt;multiple&lt;/em&gt; Eulerian walks are now possible like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dg2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Possible path #1&lt;/strong&gt;. Here after we reach &lt;font color=&#34;blue&#34;&gt;&lt;code&gt;TG&lt;/code&gt;&lt;/font&gt; node we turn &lt;strong&gt;up&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The above path spells out:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAA
 AAT
  ATG
   TGC
    GCC
     CCA
      CAT
       ATG
        TGG
         GGG
          GGA
           GAT
            ATG
             TGT
              GTT
-----------------
TAATGCCATGGGATGTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Yet there is an alternative:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dg3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Possible path #2&lt;/strong&gt;. Here after we reach &lt;font color=&#34;blue&#34;&gt;&lt;code&gt;TG&lt;/code&gt;&lt;/font&gt; node we turn &lt;strong&gt;dow&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Which spells:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAA
 AAT
  ATG
   TGG
    GGA
     GAT
      ATG
       TGC
        GCC
         CCA
          CAT
           ATG
            TGT
             GTT
----------------
TAATGGATGCCATGTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note how different these are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;TAATGCCATGGGATGTT

TAATGGATGCCATGTTT
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and only one of them is correct. Repeats are evil!&lt;/p&gt;

&lt;h2 id=&#34;k-mer-size-affects-repeat-resolution&#34;&gt;&lt;em&gt;k&lt;/em&gt;-mer size affects repeat resolution&lt;/h2&gt;

&lt;p&gt;In the above example we have used &lt;em&gt;k&lt;/em&gt;-mer size of 3. But what if we try 4 or 5? Below are DeBruijn graphs for different values of &lt;em&gt;k&lt;/em&gt;:&lt;/p&gt;

&lt;h4 id=&#34;k-3&#34;&gt;&lt;em&gt;k&lt;/em&gt; = 3&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/k2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is our original graph&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;k-4&#34;&gt;&lt;em&gt;k&lt;/em&gt; = 4&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/k3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here complexity is decreasing, but we still have the problem with having &lt;code&gt;ATG&lt;/code&gt; twice.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;k-5&#34;&gt;&lt;em&gt;k&lt;/em&gt; = 5&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/k4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In this case there is only one path. This because our &lt;em&gt;k&lt;/em&gt; is larger that the repeat size, so we can resolve it accurately.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This is why technologies producing long sequencing reads stimulate so much enthusiasm - they will allow to resolve and produce accurate assembly of large genomes.&lt;/p&gt;

&lt;h1 id=&#34;assembly-in-real-life&#34;&gt;Assembly in real life&lt;/h1&gt;

&lt;p&gt;In this topic we&amp;rsquo;ve learned about two ways of representing the relationship between reads derived from a genome we are trying to assemble:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Overlap graphs&lt;/strong&gt; - nodes are reads, edges are overlaps between reads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;DeBruijn graphs&lt;/strong&gt; - nodes are overlaps, edges are reads.&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;A&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/4.13f.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;B.&lt;/strong&gt;
An overlap (A) and DeBruijn (B) graphs for the same string.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Whatever the representation will be it will be messy:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/t12_mess.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A fragment of a very large DeBruijn graph (Image from &lt;a href=&#34;https://github.com/BenLangmead/ads1-slides/blob/master/0580_asm__practice.pdf&#34;&gt;BL&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are multiple reasons for such messiness:&lt;/p&gt;

&lt;h3 id=&#34;sequence-errors&#34;&gt;Sequence errors&lt;/h3&gt;

&lt;p&gt;Sequencing machines do not give perfect data. This results in spurious deviations on the graph. Some sequencing technologies such as Oxford Nanopore have very high error rate of ~15%.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/t12_errors.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Graph components resulting from sequencing errors (Image from &lt;a href=&#34;https://github.com/BenLangmead/ads1-slides/blob/master/0580_asm__practice.pdf&#34;&gt;BL&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;ploidy&#34;&gt;Ploidy&lt;/h3&gt;

&lt;p&gt;As we discussed earlier humans are, for example, diploid and there are multiple differences between maternal and paternal genomes. This creates &amp;ldquo;bubbles&amp;rdquo; on assembly graphs:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/t12_bubble.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Bubbles due to a heterozygous site  (Image from &lt;a href=&#34;https://github.com/BenLangmead/ads1-slides/blob/master/0580_asm__practice.pdf&#34;&gt;BL&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;repeats&#34;&gt;Repeats&lt;/h3&gt;

&lt;p&gt;As we&amp;rsquo;ve seen the third law of assembly is unbeatable. As a result some regions of the genome simply cannot be resolved and are reported in segments called &lt;em&gt;contigs&lt;/em&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/t12_contigs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The following &amp;ldquo;genomic&amp;rdquo; segment will be reported in three pieces corresponding to reagions flanking the repeat and repeat itself (Image from &lt;a href=&#34;https://github.com/BenLangmead/ads1-slides/blob/master/0580_asm__practice.pdf&#34;&gt;BL&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;next&#34;&gt;Next&lt;/h1&gt;

&lt;p&gt;Next topic will cover assembly in practice as we will attempt to put together an &lt;em&gt;E. coli&lt;/em&gt; genome sequenced with Illumina and Oxford Nanopore.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Reference-based RNA-seq</title>
      <link>http://nekrut.github.io/BMMB554/post/topic11/</link>
      <pubDate>Wed, 16 Nov 2016 09:51:16 -0500</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic11/</guid>
      <description>

&lt;h1 id=&#34;rnaseq-reference-based&#34;&gt;RNAseq: Reference-based&lt;/h1&gt;

&lt;blockquote&gt;
&lt;p&gt;This tutorial is inspired by an exceptional &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/&#34;&gt;RNAseq course&lt;/a&gt; at the Weill Cornell Medical College compiled by Friederike Dündar, Luce Skrabanek, and Paul Zumbo and by tutorials produced by Björn Grüning (@bgruening) for Freiburg Galaxy instance. Much of Galaxy-related features described in this section have been developed by Björn Grüning (@bgruening) and configured by Dave Bouvier (@davebx).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;RNAseq can be roughly divided into two &amp;ldquo;types&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reference genome-based&lt;/strong&gt; - an assembled genome exists for a species for which an RNAseq experiment is performed. It allows reads to be aligned against the reference genome and significantly improves our ability to reconstruct transcripts. This category would obviously include humans and most model organisms but excludes the majority of truly biologically intereting species (e.g., &lt;a href=&#34;https://en.wikipedia.org/wiki/Hyacinth_macaw&#34;&gt;Hyacinth macaw&lt;/a&gt;);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reference genome-free&lt;/strong&gt; - no genome assembly for the species of interest is available. In this case one would need to assemble the reads into transcripts using &lt;em&gt;de novo&lt;/em&gt; approaches. This type of RNAseq is as much of an art as well as science because assembly is heavily parameter-dependent and difficult to do well.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this lesson we will focus on the &lt;strong&gt;Reference genome-based&lt;/strong&gt; type of RNA seq.&lt;/p&gt;

&lt;h2 id=&#34;experimental-procedures-affect-downstream-analyses&#34;&gt;Experimental procedures affect downstream analyses&lt;/h2&gt;

&lt;p&gt;The &lt;em&gt;Everything&amp;rsquo;s connected&lt;/em&gt; slide by Dündar et al. (2015) explains the overall idea:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/everything_connected.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There is a variety of ways in which RNA is treated during its conversion to cDNA and eventual preparation of sequencing libraries. In general the experimental workflow includes the following steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;RNA purification;&lt;/li&gt;
&lt;li&gt;Reverse transcription using Reverse Transcriptase (RT), which produces the first strand of cDNA (&amp;ldquo;c&amp;rdquo; stands for &lt;em&gt;complimentary&lt;/em&gt;);&lt;/li&gt;
&lt;li&gt;Second strand synthesis using DNA polymerase;&lt;/li&gt;
&lt;li&gt;Library preparation for sequencing.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In listing these basic steps we are ignoring a vast amount of details such as, for example, normalization strategies and procedures needed to deal with rare RNAs or degraded samples (see &lt;a href=&#34;http://nature.com/nmeth/journal/v10/n7/full/nmeth.2483.html&#34;&gt;Adiconis:2013&lt;/a&gt;). Yet, there are two important experimental considerations that would effect the ways in which one analyses data and interprets the results. These are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Priming for the first cDNA strand synthesis;&lt;/li&gt;
&lt;li&gt;Stranded versus Non-stranded libraries.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;priming-for-the-first-strand-synthesis&#34;&gt;Priming for the first strand synthesis&lt;/h3&gt;

&lt;p&gt;Reverse Transcriptase (RT) requires a primer. One can leverage the fact that the majority of processed mRNAs are polyadenylated and use oligo-dT primer to (mostly) restrict cDNA synthesis to fully processed mRNAs. Alternatively one can use a mix of random oligonucleotides to prime RT at a multitude of internal sites irrespective of RNA type and maturation status:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dT_random.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Oligo-dT vs. random priming&lt;/strong&gt;&lt;br&gt;
Oligo-dT (&lt;strong&gt;A&lt;/strong&gt;) and random priming (&lt;strong&gt;B&lt;/strong&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Depending on the choice of the approach one would have different types of RNAs included in the final sequencing outcome. For example, if one attempts to study RNAs that are not polyadenylated or not fully processed, it would be unwise to use oligo-dT priming approach.&lt;/p&gt;

&lt;h3 id=&#34;strand-specific-rnaseq&#34;&gt;Strand-specific RNAseq&lt;/h3&gt;

&lt;p&gt;RNAs that are typically targeted in RNAseq experiments are single stranded (e.g., mRNAs) and thus have polarity (5&amp;rsquo; and 3&amp;rsquo; ends that are functionally distinct):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/dna_rna.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Relationship between DNA and RNA orientation&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;During a typical RNAseq experiment the information about strandedness is lost after both strands of cDNA are synthesized, size selected, and converted into sequencing library. However, this information can be quite useful for various aspects of RNAseq analysis such as transcript reconstruction and quantification. There is a number of methods for creating so called &lt;em&gt;stranded&lt;/em&gt; RNAseq libraries that preserve the strand information (for an excellent overview see Levin et al. &lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n9/full/nmeth.1491.html&#34;&gt;2010&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n9/fig_tab/nmeth.1491_F1.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/stranded_protocols.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Generation of stranded RNAseq libraries&lt;/strong&gt;&lt;br&gt;
Different types of stranded library generation protocols from &lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n9/full/nmeth.1491.html&#34;&gt;Levin:2010&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Depending on the approach and whether one performs single- or paired-end sequencing there are multiple possibilities on how to interpret the results of mapping of these reads onto genome/transcriptome:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://sailfish.readthedocs.org/en/master/library_type.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/lib_type.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Effects of RNAseq library types&lt;/strong&gt;&lt;br&gt;
Image and description below is from &lt;a href=&#34;http://sailfish.readthedocs.org/en/master/library_type.html&#34;&gt;Sailfish documentation&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The relative orientation of the reads is only relevant if the library is pair-ended. The possible options are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;I&lt;/strong&gt; = inward;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;O&lt;/strong&gt; = outward;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt; = matching (co-directional).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Library can be stranded (&lt;strong&gt;S&lt;/strong&gt;) or unstranded (&lt;strong&gt;U&lt;/strong&gt;). If this library is stranded than depending on the protocols reads (single reads or forward reads in a paired-end run) may originate from:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;F&lt;/strong&gt; = read 1 in paired-end sequencing or single-end read is derived from the Forward strand;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;R&lt;/strong&gt; = read 1 in paired-end sequencing or single-end read is derived from the Reverse strand.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So by combining the relative orientation of reads is I, O, or M (if reads are paired), strandedness or the library (S or U), and whether the reads originate from forward and reverse strand (F or R) there can be quite a number of possibilities:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;IU  - (an unstranded paired-end library where the reads face each other)&lt;/li&gt;
&lt;li&gt;SF  - (a stranded single-end protocol where the reads come from the forward strand)&lt;/li&gt;
&lt;li&gt;OSR - (a stranded paired-end protocol where the reads face away from each other,
  read1 comes from reverse strand and read2 comes from the forward strand).
  and so on&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;However, in practice, if you use Illumina paired-end RNAseq protocols you are unlikely to uncover many of these possibilities. You will either deal with:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;unstranded RNAseq data (&lt;strong&gt;IU&lt;/strong&gt; type from above. Also called &lt;strong&gt;fr-unstranded&lt;/strong&gt; in TopHat/Cufflinks jargon);&lt;/li&gt;
&lt;li&gt;stranded RNAseq data produced with Illumina TrueSeq RNAseq kits and &lt;a href=&#34;http://nar.oxfordjournals.org/content/37/18/e123&#34;&gt;dUTP tagging&lt;/a&gt; (&lt;strong&gt;ISR&lt;/strong&gt; type from above or &lt;strong&gt;fr-firststrand&lt;/strong&gt; in TopHat/Cufflinks nomenclature).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The implication of stranded RNAseq is that you can distinguish whether the reads are derived from forward- or reverse-encoded transcripts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/stranded_result.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stranded RNAseq data look like this&lt;/strong&gt;&lt;br&gt;
This example contrasts unstranded and stranded RNAseq experiments. &lt;font color=&#34;red&#34;&gt;Red transcripts&lt;/font&gt; are from + strand and &lt;font color=&#34;blue&#34;&gt;blue&lt;/font&gt; are from - strand. In stranded example reads are clearly stratified between the two strands.  A small number of reads from opposite strand may represent anti-sense transcription. The image from GATC Biotech.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;replicates-biological-or-technical-and-how-many&#34;&gt;Replicates: Biological or Technical and how many?&lt;/h3&gt;

&lt;p&gt;An RNAseq experiment without a sufficient number of replicates will be a waste of money. Replicates are essential to be able to correct for variation due to differences within/among organisms, cells, sequencing machines, library preparation protocols and numerous other potential factors. There are two types of replicates (as described by &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf&#34;&gt;Dündar:2015&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Technical replicates&lt;/strong&gt; can be defined as &lt;em&gt;different library preparations from the same RNA sample&lt;/em&gt;. They should account for batch effects from the library preparation such as reverse transcription and PCR amplification. To avoid possible lane effects (e.g., differences in the sample loading, cluster amplification, and efficiency of the sequencing reaction), it is good practice to multiplex the same sample over different lanes of the same flowcell. In most cases, technical variability introduced by the sequencing protocol is quite low and well controlled.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Biological replicates&lt;/strong&gt;. There is an on-going debate over what kinds of samples represent true biological replicates. Obviously, the variability between different samples will be greater between RNA extracted from two unrelated humans than between RNA extracted from two different batches of the same cell line. In the latter case, most of the variation that will eventually be detected was probably introduced by the experimenter (e.g., slightly differing media and plating conditions). Nevertheless, this is variation the researcher is typically not interested in assessing, therefore the ENCODE consortium defines biological replicates as RNA from an independent growth of cells/tissue (ENCODE &lt;a href=&#34;https://genome.ucsc.edu/ENCODE/protocols/dataStandards/ENCODE_RNAseq_Standards_V1.0.pdf&#34;&gt;2011&lt;/a&gt;).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The number of replicates should be as high as practically possible. Most RNAseq experiments include three replicates and some have as many as 12 (see Schurch et al. &lt;a href=&#34;http://arxiv.org/abs/1505.02017&#34;&gt;2015&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;read-mapping&#34;&gt;Read mapping&lt;/h2&gt;

&lt;p&gt;After sequencing is performed you have a collection of sequencing reads for each sample/replicate. In a reference-based RNAseq experiment these need to be mapped against the genome. Because in the case of eukaryotic transcriptome most reads originate from processed mRNAs lacking exons, they cannot be simply mapped back to the genome. Instead they can be separated into two categories:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Reads that map entirely within exons&lt;/li&gt;
&lt;li&gt;Reads that cannot be mapped within an exon across their entire length because they span two or more exons&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Spliced&lt;/em&gt; mappers have been developed to efficiently map transcript-derived reads against genome.&lt;/p&gt;

&lt;h3 id=&#34;tophat-tophat2-and-hisat&#34;&gt;TopHat, TopHat2, and HiSat&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/9/1105.abstract&#34;&gt;Tophat&lt;/a&gt; was one of the first tools designed specifically to address this problem by identifying potential exons using reads that do map to the genome, generating possible splices between neighboring exons, and comparing reads that did not initially map to the genome agaisnt these &lt;em&gt;in silico&lt;/em&gt; created junctions:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/9/1105/F1.expansion.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/tophat.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TopHat and TopHat2: Mapping RNAseq regions to genome&lt;/strong&gt;&lt;br&gt;
In TopHat reads are mapped against the genome and are separated into two categories: (1) those that map, and (2) those that initially unmapped (IUM). &amp;ldquo;Piles&amp;rdquo; of reads representing potential exons are extended in search of potential donor/acceptor splice sites and potential splice junctions are reconstructed. IUMs are then mapped to these junctions. Image from &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/9/1105.full&#34;&gt;Trapnell:2009&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/gb-2013-14-4-r36&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/tophat2.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TopHat has been subsequently improved with the development of TopHat2&lt;/strong&gt;&lt;br&gt;
Image from &lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/gb-2013-14-4-r36&#34;&gt;Kim:2012&lt;/a&gt; summarizes steps involved in aligning of RNAseq reads with TopHat2&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To further optimize and speed up spliced read alignment Kim at al. &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html&#34;&gt;2015&lt;/a&gt; developed &lt;a href=&#34;http://ccb.jhu.edu/software/hisat2/index.shtml&#34;&gt;HISAT&lt;/a&gt;. It uses a set of &lt;a href=&#34;https://en.wikipedia.org/wiki/FM-index&#34;&gt;FM-indices&lt;/a&gt; consisting one global genome-wide index and a collection of ~48,000 local overlapping 42 kb indices (~55,000 56 kb indices in HiSat2). This allows to find initial seed locations for potential read alignments in the genome using global index and to rapidly refine these alignments using a corresponding local index:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/hisat.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hierarchical Graph FM index in HiSat/HiSat2&lt;/strong&gt;&lt;br&gt;
A part of the read (blue arrow) is first mapped to the genome using the global FM index. The HiSat then tries to extend the alignment directly utilizing the genome sequence (violet arrow). In (&lt;strong&gt;a&lt;/strong&gt;) it succeeds and this read aligned as it completely resides within an exon. In (&lt;strong&gt;b&lt;/strong&gt;) the extension hits a mismatch. Now HiSat takes advantage of the local FM index overlapping this location to find the appropriate matting for the remainder of this read (green arrow). The (&lt;strong&gt;c&lt;/strong&gt;) shows a combination these two strategies: the beginning of the read is mapped using global FM index (blue arrow), extended until it reaches the end of the exon (violet arrow), mapped using local FM index (green arrow) and extended again (violet arrow). Image from &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n4/full/nmeth.3317.html&#34;&gt;Kim:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;star-mapper&#34;&gt;STAR mapper&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/alexdobin/STAR&#34;&gt;STAR aligner&lt;/a&gt; is a fast alternative for mapping RNAseq reads against genome utilizing uncompressed &lt;a href=&#34;https://en.wikipedia.org/wiki/Suffix_array&#34;&gt;suffix array&lt;/a&gt;. It operates in &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2012/10/25/bioinformatics.bts635.abstract&#34;&gt;two stages&lt;/a&gt;. In the first stage it performs seed search:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/star.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;STAR&amp;rsquo;s seed search&lt;/strong&gt;&lt;br&gt;
Here a read is split between two consecutive exons. STAR starts to look for a &lt;em&gt;maximum mappable prefix&lt;/em&gt; (MMP) from the beginning of the read until it can no longer match continuously. After this point it start to MMP for the unmatched portion of the read (&lt;strong&gt;a&lt;/strong&gt;). In the case of mismatches (&lt;strong&gt;b&lt;/strong&gt;) and unalignable regions (&lt;strong&gt;c&lt;/strong&gt;) MMPs serve as anchors from which to extend alignments. Image from &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2012/10/25/bioinformatics.bts635.full.pdf+html&#34;&gt;Dobin:2013&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;At the second stage STAR stitches MMPs to generate read-level alignments that (contrary to MMPs) can contain mismatches and indels. A scoring scheme is used to evaluate and prioritize stitching combinations and to evaluate reads that map to multiple locations. STAR is extremely fast but requires a substantial amount of RAM to run efficiently.&lt;/p&gt;

&lt;h2 id=&#34;transcript-reconstruction&#34;&gt;Transcript reconstruction&lt;/h2&gt;

&lt;p&gt;The previous step - mapping - assigns RNAseq reads to genomic locations and identifies splice junctions from reads that originate from different exons. At transcript reconstruction step this information is taken further in attempt to build transcript models. There is a number of tools for performing this task. A benchmarking paper by &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2015/09/03/bioinformatics.btv488.full.pdf+html&#34;&gt;Hayer:2015&lt;/a&gt; attempted to compare performance of existing approaches with one of the outcomes shown below:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2015/09/08/bioinformatics.btv488/F5.large.jpg&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/rnaseq_comparison.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Comparison of transcript reconsruction approaches&lt;/strong&gt;&lt;br&gt;
Here &lt;em&gt;recall&lt;/em&gt; (the number of correctly constructed forms divided by the total number of real forms) versus &lt;em&gt;precision&lt;/em&gt; (true positives divided by the sum of true positives and false positives) are plotted for seven transcript assemblers tested on two simulated datasets: &lt;em&gt;EnsemblPerfect&lt;/em&gt; and &lt;em&gt;EnsemblRealistic&lt;/em&gt;. The shaded region is indicating suboptimal performance (i.e., the white, unshaded region is &amp;ldquo;good&amp;rdquo;). The figure is from &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/early/2015/09/03/bioinformatics.btv488.full.pdf+html&#34;&gt;Hayer:2015&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Based on these results &lt;a href=&#34;http://cole-trapnell-lab.github.io/cufflinks/&#34;&gt;Cufflinks&lt;/a&gt; and &lt;a href=&#34;https://ccb.jhu.edu/software/stringtie/&#34;&gt;StringTie&lt;/a&gt; have satisfactory performence. The following discussion is based on inner workings of StringTie.&lt;/p&gt;

&lt;h3 id=&#34;transcriptome-assembly-with-stringtie&#34;&gt;Transcriptome assembly with StringTie&lt;/h3&gt;

&lt;p&gt;&lt;a href=&#34;https://ccb.jhu.edu/software/stringtie/&#34;&gt;StringTie&lt;/a&gt; assembles transcripts from spliced read alignemnts produced by tools such as STAR, TopHat, or HISAT and simultaneously estimates their abundances using counts of reads assigned to each transcript. The following images illustrates details of StringTie workflow:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/stringtie1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;StringTie workflow&lt;/strong&gt;&lt;br&gt;
Image from &lt;a href=&#34;http://www.nature.com/nbt/journal/v33/n3/full/nbt.3122.html&#34;&gt;Pertea:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In essence StringTie builds an alternative splice graph from overlapping reads in a given locus. In such a graph nodes correspond to exons (or, rather, contiguous regions of genome covered by reads; colored regions on the figure above), while edges are represented by reads connecting these exons. Next, it identifies a path within the splice graph that has the highest weight (largest number of reads on edges). Such path would correspond to an assembled transcript at this iteration of the algorithm. Because the edge weight is equal to the number of the reads StringTie estimates the coverage level for this transcript (see below) which can be used to estimate the transcript&amp;rsquo;s abundance. Reads that are associated with the transcript that was just assembled are then removed and the graph is updated to perform the next iteration of the algorithm.&lt;/p&gt;

&lt;h2 id=&#34;transcript-quantification&#34;&gt;Transcript quantification&lt;/h2&gt;

&lt;p&gt;Transcriptome quantification attempts to estimate expression levels of individuals transcripts. This is performed by assigning RNAseq reads to transcripts, counting, and normalization.&lt;/p&gt;

&lt;h3 id=&#34;assigning-reads-to-transcripts&#34;&gt;Assigning reads to transcripts&lt;/h3&gt;

&lt;p&gt;To associate reads with transcripts they (the reads) need to be aligned to the transcriptome. Tools like Cufflinks and StringTie reconstruct transcripts from spliced read alignments generated by other programs (TopHat, HISAT, STAR), so they already have the information about which reads belong to each reconstructed transcript. Other tools such as &lt;a href=&#34;http://www.cs.cmu.edu/~ckingsf/software/sailfish/&#34;&gt;Sailfish&lt;/a&gt;, &lt;a href=&#34;http://pachterlab.github.io/kallisto/&#34;&gt;Kallisto&lt;/a&gt;, and &lt;a href=&#34;http://combine-lab.github.io/salmon/&#34;&gt;Salmon&lt;/a&gt; perform &lt;em&gt;lightweight&lt;/em&gt; alignment of RNAseq reads against existing transcriptome sequences. The goal of lightweight alignment is to quickly distribute the reads across transcripts they likely originate from without worrying too much about producing high quality alignments. The upside of this is that the entire procedure can be performed very quickly. The downside is that these tools require high quality transcriptome as input, which is not a problem if you work with humans or mice, but is a problem if you are studying Hyacinth macaw or any other brilliantly colored creatures.&lt;/p&gt;

&lt;h4 id=&#34;lightweight-alignment&#34;&gt;Lightweight alignment&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www.cs.cmu.edu/~ckingsf/software/sailfish/&#34;&gt;Sailfish&lt;/a&gt; has been initially designed to utilize &lt;a href=&#34;https://en.wikipedia.org/wiki/K-mer&#34;&gt;&lt;em&gt;k&lt;/em&gt;-mer&lt;/a&gt; matching for finding association between reads and corresponding transcripts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/sailfish.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assigning reads to transcripts: Sailfish&lt;/strong&gt;&lt;br&gt;
Sailfish indexes input transcriptome for a fixed &lt;em&gt;k&lt;/em&gt;-mer length and compares &lt;em&gt;k&lt;/em&gt;-mers derived from RNAseq reads against this index. Image from &lt;a href=&#34;http://www.nature.com/nbt/journal/v32/n5/full/nbt.2862.html&#34;&gt;Patro:2014&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The current version of Sailfish uses &lt;a href=&#34;http://biorxiv.org/content/biorxiv/early/2015/10/22/029652.full.pdf&#34;&gt;quasi-alignment&lt;/a&gt; to extend exact matches found with &lt;em&gt;k&lt;/em&gt;-mers:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/quasi_aln.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Quasi-alignment of reads in Sailfish&lt;/strong&gt;&lt;br&gt;
In Sailfish version &lt;a href=&#34;https://github.com/kingsfordgroup/sailfish/releases/tag/v0.7.0&#34;&gt;0.7.0&lt;/a&gt; and up transcriptome is concatenated into a single sequence using &lt;code&gt;$&lt;/code&gt; separators from which a &lt;a href=&#34;https://en.wikipedia.org/wiki/Suffix_array&#34;&gt;suffix array&lt;/a&gt; and a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hash_table&#34;&gt;hash table&lt;/a&gt; are constructed. A &lt;em&gt;k&lt;/em&gt;-mer from an RNAseq read (green) is looked up in the hash table, which immediately gives its position in the suffix array allowing to extend the march as described in the legend and the &lt;a href=&#34;http://biorxiv.org/content/biorxiv/early/2015/10/22/029652.full.pdf&#34;&gt;paper&lt;/a&gt;. Image from  &lt;a href=&#34;http://biorxiv.org/content/biorxiv/early/2015/10/22/029652.full.pdf&#34;&gt;Srivastava:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;http://pachterlab.github.io/kallisto/&#34;&gt;Kallisto&lt;/a&gt; also utilizes &lt;em&gt;k&lt;/em&gt;-mer matching but uses a different data structure. It constructs a &lt;a href=&#34;https://en.wikipedia.org/wiki/De_Bruijn_graph&#34;&gt;De Bruijn graph&lt;/a&gt; from transcriptome input (pane &lt;strong&gt;b&lt;/strong&gt; of the figure below). This graph is different from De Bruijn graphs used for genome assembly in that its nodes are &lt;em&gt;k&lt;/em&gt;-mers and transcripts correspond to paths through the graph. To accommodate multiple transcripts that can lay along the same path (or sub-path) the paths are &amp;ldquo;colored&amp;rdquo; with each transcript given a distinct &amp;ldquo;color&amp;rdquo; (in genome assembly the graph is built from the reads and nodes usually correspond to overlaps between &lt;em&gt;k&lt;/em&gt;-mers forming incoming and outgoing edges). Non-branching sections of the graph that have identical coloring are &amp;ldquo;glued&amp;rdquo; into contigs. Finally a &lt;a href=&#34;https://en.wikipedia.org/wiki/Hash_table&#34;&gt;hash table&lt;/a&gt; is built that stores the position of each transcriptome &lt;em&gt;k&lt;/em&gt;-mer within the graph:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/kallisto.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assigning reads to transcripts: Kallisto&lt;/strong&gt;&lt;br&gt;
Here a black read is being associated with a set consisting of red, blue, and green transcripts (&lt;strong&gt;a&lt;/strong&gt;). First, a graph is built from transcriptome (&lt;strong&gt;b&lt;/strong&gt;). Next, by finding common &lt;em&gt;k&lt;/em&gt;-mers between the read and the graph the read is &amp;ldquo;threaded&amp;rdquo; along a path (&lt;strong&gt;c&lt;/strong&gt; and &lt;strong&gt;d&lt;/strong&gt;). The colors along that path would indicate which transcripts it is likely derived from. Specifically, this is done by taking intersection of &amp;ldquo;colors&amp;rdquo; (&lt;strong&gt;c&lt;/strong&gt;). It this case the read is assigned to two transcripts: red and blue. Image from &lt;a href=&#34;http://arxiv.org/pdf/1505.02710v2.pdf&#34;&gt;Bray:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;a href=&#34;https://combine-lab.github.io/salmon/about/&#34;&gt;Salmon&lt;/a&gt; does not use &lt;em&gt;k&lt;/em&gt;-mer matching approach. Instead it creates &lt;a href=&#34;https://github.com/lh3/bwa&#34;&gt;bwa&lt;/a&gt;-like &lt;a href=&#34;https://en.wikipedia.org/wiki/FM-index&#34;&gt;FM-index&lt;/a&gt; and uses it to finds chains of &lt;em&gt;Maximal Exact Matches&lt;/em&gt; (MEMs) and &lt;em&gt;Super Maximal Exact Matches&lt;/em&gt; (SMEMs) between a read and the transcriptome.&lt;br /&gt;
&lt;a href=&#34;http://biorxiv.org/content/biorxiv/early/2015/06/27/021592.full.pdf&#34;&gt;Patro:2015&lt;/a&gt; define a MEM as &amp;ldquo;&lt;em&gt;a substring that is shared by the query (read) and reference (transcript) that cannot be extended in either direction without introducing a mismatch&lt;/em&gt;&amp;rdquo;. Similraly, a SMEM is defined as a &amp;ldquo;&lt;em&gt;MEM that is not contained within any other MEM on the query.&lt;/em&gt;&amp;rdquo; One of the advantages of utilizing the FM-index is that a new index does not need to re-generated for a search with different set of parameters. In the case of Sailfish and Kallisto an index is dependent on &lt;em&gt;k&lt;/em&gt;-mer length and has to be recomputed every time the &lt;em&gt;k&lt;/em&gt; is changed. The overall schematics of Salmon operation is as follows:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/salmon.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Assigning reads to transcripts: Salmon&lt;/strong&gt;&lt;br&gt;
Image from &lt;a href=&#34;http://biorxiv.org/content/biorxiv/early/2015/06/27/021592.full.pdf&#34;&gt;Patro:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;estimating-transcript-levels&#34;&gt;Estimating transcript levels&lt;/h3&gt;

&lt;p&gt;Once reads are apportioned across individual transcripts they can be quantified. There are several approaches for quantification.&lt;/p&gt;

&lt;h4 id=&#34;flow-networks&#34;&gt;Flow networks&lt;/h4&gt;

&lt;p&gt;StringTie, which performs assembly and quantification simultaneously converts splice graph into a flow network for which it solves &lt;a href=&#34;https://en.wikipedia.org/wiki/Maximum_flow_problem&#34;&gt;the maximum flow problem&lt;/a&gt;. The maximum flow is such network represents the expression level for a given transcript:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/stringtie2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;StringTie flow network&lt;/strong&gt;&lt;br&gt;
Here each exon node from the splice graph is split into &lt;em&gt;in&lt;/em&gt; and &lt;em&gt;out&lt;/em&gt; nodes connected with an edge weighted by the number of reads corresponding to that exon. For example, the first exon is covered by seven reads and so the edge between 1-in and 1-out has a weight of 7. Expression level would correspond to the maximum flow through a path representing a given transcript. Image from &lt;a href=&#34;http://www.nature.com/nbt/journal/v33/n3/full/nbt.3122.html&#34;&gt;Pertea:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;expectation-maximization&#34;&gt;Expectation Maximization&lt;/h4&gt;

&lt;p&gt;The Expectation/Maximization framework (EM) is utilized in a number of tools such as &lt;a href=&#34;http://bio.math.berkeley.edu/eXpress/index.html&#34;&gt;eXpress&lt;/a&gt; and more recently &lt;a href=&#34;http://www.cs.cmu.edu/~ckingsf/software/sailfish/&#34;&gt;Sailfish&lt;/a&gt;, &lt;a href=&#34;http://pachterlab.github.io/kallisto/&#34;&gt;Kallisto&lt;/a&gt;, and &lt;a href=&#34;https://combine-lab.github.io/salmon/about/&#34;&gt;Salmon&lt;/a&gt; (As an alternative strategy Salmon also utilizes &lt;a href=&#34;http://arxiv.org/pdf/1308.5953v1.pdf&#34;&gt;variational Bayesian method&lt;/a&gt;. The principle of EM is nicely illustrated by &lt;a href=&#34;https://liorpachter.wordpress.com/&#34;&gt;Lior Pachter&lt;/a&gt; in his transcript quantification &lt;a href=&#34;http://arxiv.org/pdf/1104.3889v2.pdf&#34;&gt;review&lt;/a&gt;. Suppose, as shown on the image below, there are three transcripts (green, red, and blue). There are five reads associated with these transcripts. One read (&lt;em&gt;d&lt;/em&gt;) is unique to the red transcript, while others correspond to two (&lt;em&gt;b&lt;/em&gt;, &lt;em&gt;c&lt;/em&gt;, &lt;em&gt;e&lt;/em&gt;) or three (&lt;em&gt;a&lt;/em&gt;) transcripts. The EM is an iterative procedure. In the first round transcript abundances are initialized as equal (0.33 each as there are three transcripts) and during expectation reads are apportioned across transcripts based on these abundances. Next, during maximization step transcript abundances are re-calculated as follow. For red transcript we sum up fraction of each read as 0.33 + 0 + 0.5 + 1 + 0.5 for reads a, b, c, d, and e, respectively. We now divide this by the sum of read allocations for each transcript as 2.33 + 1.33 + 1.33 for red, green, and blue transcripts respectively. For all three transcript calculation will look like this:&lt;/p&gt;

&lt;div&gt;
    $$

\color{red}{red}   =  \frac{0.33 + 0.0 + 0.5 + 1.0 + 0.5}{2.33 + 1.33 + 1.33} = 0.47\\

\color{green}{green} =  \frac{0.33 + 0.5 + 0.0 + 0.0 + 0.5}{2.33 + 1.33 + 1.33} = 0.27\\

\color{blue}{blue}  =  \frac{0.33 + 0.5 + 0.5 + 0.0 + 0.0}{2.33 + 1.33 + 1.33} = 0.27
   
    $$
&lt;/div&gt;

&lt;p&gt;During next expectation stage read are re-apportioned across transcripts and the procedure is repeated until convergence:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/em.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Expectation Maximization (EM)&lt;/strong&gt;&lt;br&gt;
Image from &lt;a href=&#34;http://arxiv.org/pdf/1104.3889v2.pdf&#34;&gt;Pacher:2011&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;understanding-quantification-metrics&#34;&gt;Understanding quantification metrics&lt;/h3&gt;

&lt;p&gt;As we&amp;rsquo;ve seen above quantification for a transcript is estimated using the number of associated reads. Yet the count is not a very good measure as it will be severely biased by multiple factors such as, for example, transcript length. Thus these counts need to be normalized. Normalization strategies can be roughly divided into two groups:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Normalization for comparison within a &lt;strong&gt;single&lt;/strong&gt; sample;&lt;/li&gt;
&lt;li&gt;Normalization for comparison among &lt;strong&gt;multiple&lt;/strong&gt; samples/conditions.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In their &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/&#34;&gt;tutorial&lt;/a&gt; Dündar et al. have compiled a table summarizing various metrics. Below is description of normalization technique for within sample comparisons (between sample comparison can be found in the next section on differential expression analysis):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/within_norm.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;RNAseq normalization metrics: Within sample comparisons&lt;/strong&gt;&lt;br&gt;
Table from Dündar et al. &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/&#34;&gt;2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In addition, an excellent overview of these metrics can be found &lt;a href=&#34;https://haroldpimentel.wordpress.com/2014/05/08/what-the-fpkm-a-review-rna-seq-expression-units/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;font-color-red-9888-you-should-never-ever-use-rpkm-fpkm-or-tpm-to-compare-expression-levels-across-samples-these-are-relative-measures-consider-yourself-warned-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;&amp;#9888; &lt;strong&gt;You should NEVER EVER use RPKM, FPKM, or TPM to compare expression levels &lt;em&gt;across&lt;/em&gt; samples. These are RELATIVE measures! Consider yourself warned!&lt;/strong&gt;&lt;/font&gt;&lt;/h4&gt;

&lt;h2 id=&#34;finding-expression-differences&#34;&gt;Finding expression differences&lt;/h2&gt;

&lt;p&gt;The goal of differential expression analysis (DE) is to find gene (DGE) or transcript (DTE) differences between conditions, developmental stages, treatments etc. In particular DE has two goals:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Estimate the &lt;em&gt;magnitude&lt;/em&gt; of expression differences;&lt;/li&gt;
&lt;li&gt;Estimate the &lt;em&gt;significance&lt;/em&gt; of expression differences.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For this expression is estimated from read counts and attempts are made to correct for variability in measurements using replicates that are absolutely essential accurate results (see below). We begin our short discussion on DE by reproducing a figure from &lt;a href=&#34;http://www.nature.com/nbt/journal/v31/n1/abs/nbt.2450.html&#34;&gt;Trapnell:2013&lt;/a&gt; highlighting some of the challenges associated with judging expression differences from read counts:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/diff.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Differential expression: Read counts and Expression levels&lt;/strong&gt;&lt;br&gt;
&lt;strong&gt;Change in fragment count for a gene does not necessarily equal a change in expression&lt;/strong&gt;. (&lt;strong&gt;a&lt;/strong&gt;) Simple read-counting schemes sum the fragments incident on a gene’s exons. The exon-union model counts reads falling on any of a gene’s exons, whereas the exon-intersection model counts only reads on constitutive exons. (&lt;strong&gt;b&lt;/strong&gt;) Both of the exon-union and exon intersection counting schemes may incorrectly estimate a change in expression in genes with multiple isoforms. The true expression is estimated by the sum of the length-normalized isoform read counts. The discrepancy between a change in the union or intersection count and a change in gene expression is driven by a change in the abundance of the isoforms with respect to one another. In the top row, the gene generates the same number of reads in conditions A and B, but in condition B, all of the reads come from the shorter of the two isoforms, and thus the true expression for the gene is higher in condition B. The intersection count scheme underestimates the true change in gene expression, and the union scheme fails to detect the change entirely. In the middle row, the intersection count fails to detect a change driven by a shift in the dominant isoform for the gene. The union scheme detects a shift in the wrong direction. In the bottom row, the gene’s expression is constant, but the isoforms undergo a complete switch between conditions A and B. Both simplified counting schemes register a change in count that does not reflect a change in gene expression. Figure from &lt;a href=&#34;http://www.nature.com/nbt/journal/v31/n1/abs/nbt.2450.html&#34;&gt;Trapnell:2013&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following discussion of DGE logic is reproduced from &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/&#34;&gt;Dündar:2015&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;To determine the genes whose read count differences between two conditions are greater than expected by chance, DGE tools must make assumptions about the distribution of read counts. The null hypothesis – that the mean read counts of the samples of condition &lt;strong&gt;A&lt;/strong&gt; are equal to the mean read counts of the samples of condition &lt;strong&gt;B&lt;/strong&gt; – is tested for each gene individually. One of the most popular choices to model the read counts is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Poisson_distribution&#34;&gt;Poisson distribution&lt;/a&gt; because:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;individual reads can be interpreted as binary data (Bernoulli trials): they either originate from gene &lt;em&gt;i&lt;/em&gt; or not;&lt;/li&gt;
&lt;li&gt;we are trying to model the discrete probability distribution of the number of successes (success = read is present in the sequenced library);&lt;/li&gt;
&lt;li&gt;the pool of possible reads that could be present is large, while the proportion of reads belonging to
gene &lt;strong&gt;i&lt;/strong&gt; is quite small.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The nice feature of a Poisson distribution is that variance = mean. Thus, if the RNA-seq experiment gives us a precise estimate of the mean read counts per condition, we implicitly know what kind of variance to expect for read counts that are not truly changing between two conditions. This, in turn, then allows us to identify those genes that show greater differences between the two conditions than expected by chance. While read counts of the same library preparation (&lt;em&gt;technical replicates&lt;/em&gt;) can indeed be well approximated by the Poisson distribution, it has been shown that biological replicates have greater variance (noise) than expected. This &lt;a href=&#34;https://en.wikipedia.org/wiki/Overdispersion&#34;&gt;overdispersion&lt;/a&gt; can be captured with the &lt;a href=&#34;https://en.wikipedia.org/wiki/Negative_binomial_distribution&#34;&gt;negative binomial distribution&lt;/a&gt;, which is a more general form of the Poisson distribution that allows the variance to exceed the mean. The square root of the dispersion is the coefficient of variation – SD/mean – after subtracting the variance we expect due to Poisson sampling.&lt;/p&gt;

&lt;p&gt;In contrast to the Poisson distribution, we now need to estimate two parameters from the read counts: the mean as well as the dispersion. The precision of these estimates strongly depends on the number (and variation) of replicates – the more replicates, the better the grasp on the underlying mean expression values of unchanged genes and the variance that is due to biological variation rather than the experimental treatment. For most RNA-seq experiments, only two to three replicates are available, which is not enough for reliable mean and variance estimates. Some tools therefore compensate for the lack of replication by borrowing information across genes with similar expression values and shrink a given gene’s variance towards the regressed values. These fitted values of the mean and dispersion are then used instead of the raw estimates
to test for differential gene expression.&lt;/p&gt;

&lt;p&gt;The best performing tools tend to be &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/edgeR.html&#34;&gt;edgeR&lt;/a&gt;, &lt;a href=&#34;https://bioconductor.org/packages/release/bioc/html/DESeq2.html&#34;&gt;DESeq/DESeq2&lt;/a&gt;, and &lt;a href=&#34;https://www.bioconductor.org/packages/release/bioc/html/limma.html&#34;&gt;limma-voom&lt;/a&gt; (see Rapaport et al. (&lt;a href=&#34;http://link.springer.com/article/10.1186/gb-2013-14-9-r95&#34;&gt;2013&lt;/a&gt;); Soneson and Delorenzi (&lt;a href=&#34;https://bmcbioinformatics.biomedcentral.com/articles/10.1186/1471-2105-14-91&#34;&gt;2013&lt;/a&gt;); Schurch et al. (&lt;a href=&#34;http://arxiv.org/abs/1505.02017&#34;&gt;2015&lt;/a&gt;) for reviews of DGE tools). DESeq and limma-voom tend to be more conservative than edgeR (better control of false positives), but edgeR is recommended for experiments with fewer than 12 replicates (Schurch et al., &lt;a href=&#34;http://arxiv.org/abs/1505.02017&#34;&gt;2015&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;let-s-try-it&#34;&gt;Let&amp;rsquo;s try it&lt;/h2&gt;

&lt;h3 id=&#34;the-data&#34;&gt;The data&lt;/h3&gt;

&lt;p&gt;In this example we will use a downsampled version of simulated &lt;em&gt;Drosophila melanogaster&lt;/em&gt; RNA-seq data used by Trapnell et al. &lt;a href=&#34;http://www.nature.com/nprot/journal/v7/n3/full/nprot.2012.016.html&#34;&gt;2012&lt;/a&gt;. These include two conditions (&lt;strong&gt;C1&lt;/strong&gt; and &lt;strong&gt;C2&lt;/strong&gt;), each containing three replicates (&lt;strong&gt;R1&lt;/strong&gt;, &lt;strong&gt;R2&lt;/strong&gt;, and &lt;strong&gt;R3&lt;/strong&gt;) sequenced as a paired end library. Thus in total there are 12 fastq datasets.&lt;/p&gt;

&lt;p&gt;Here is what to do to load the data:&lt;/p&gt;

&lt;h4 id=&#34;loading-the-data-and-create-dataset-collections&#34;&gt;Loading the data and create dataset collections&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;Go to the &lt;a href=&#34;https://usegalaxy.org/library/list#folders/Ff4ce53393dae30ee&#34;&gt;data library&lt;/a&gt; and select all fastq files. Then Click &lt;code&gt;to History&lt;/code&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/rnaseq_library.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The datasets will appear in your history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/rnaseq_data_in_history.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Twelve datasets make a lot of clicking necessary. To avoid this annoyance we will combine them into two collections - &lt;strong&gt;c1&lt;/strong&gt; and &lt;strong&gt;c2&lt;/strong&gt; as shown in the video below. Also, see this &lt;a href=&#34;https://github.com/nekrut/galaxy/wiki/Processing-many-samples-at-once&#34;&gt;tutorial&lt;/a&gt; for yet another explanation of dataset collections.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/163625221&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;

&lt;/blockquote&gt;

&lt;h3 id=&#34;mapping-reads&#34;&gt;Mapping reads&lt;/h3&gt;

&lt;p&gt;We will map the reads with TopHat2. Select &lt;strong&gt;TopHat&lt;/strong&gt; from &lt;strong&gt;NGS: RNA Analysis&lt;/strong&gt; section of the tool menu (left pane of Galaxy&amp;rsquo;s interface):&lt;/p&gt;

&lt;h4 id=&#34;mapping-with-tophat2&#34;&gt;Mapping with TopHat2&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;In this case the input to TopHat is &lt;strong&gt;not&lt;/strong&gt; individual datasets, but a collection instead. The &lt;a href=&#34;https://vimeo.com/163625221&#34;&gt;video&lt;/a&gt; above shows how to generate collection. Since we have created two collection as was described above, we will used them as inputs (note that &lt;strong&gt;Is this single-end or paired-end data?&lt;/strong&gt; is set to &lt;code&gt;Paired-end (as collection)&lt;/code&gt;). Make sure that the top part of TopHat interface looks like in the image below. Here the following parameters are set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mean Inner Distance between Mate Pairs&lt;/strong&gt; = &lt;code&gt;28&lt;/code&gt; This is because paired reads are 100 bp and mean insert size is 228 bp so that 228 - (100 + 100) = 28&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Use a built in reference genome or own from your history&lt;/strong&gt; = &lt;code&gt;Use a build-in genome&lt;/code&gt; and &lt;code&gt;dm3&lt;/code&gt; is selected. This is because the reads are from &lt;em&gt;D. melanogaster&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;TopHat settings to use&lt;/strong&gt; = &lt;code&gt;Full parameter list&lt;/code&gt; This is done to be able to specify the strandedness of the library.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Library Type&lt;/strong&gt; = &lt;code&gt;FR First Strand&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/tophat_interface.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The same procedure is then repeated for collection &lt;strong&gt;c2&lt;/strong&gt;. In the end it generates a lot of datasets in the history resulting in something resembling an image below. TopHat produces five types of output and because we started with dataset collections every one of the green boxes shown below is actually a collection of outputs for &lt;strong&gt;c1&lt;/strong&gt; and &lt;strong&gt;c2&lt;/strong&gt;, respectively.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/tophat_output.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s now take a look at some of the alignments. We will use IGV for this purpose.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;First, let&amp;rsquo;s drill down to actual alignments produced by TopHat. For example, in figure shown above simply click on &lt;strong&gt;TopHat on collection 14: accepted_hits&lt;/strong&gt; and you will see a list of datasets corresponding to alignments of reads derived from each conditions:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/accepted_hits_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now, click on &lt;strong&gt;c2-r1x&lt;/strong&gt; and the following will appear:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/accepted_hits_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, use &lt;strong&gt;D. melanogaster&lt;/strong&gt; link (highlighted above) and follow the on-screen instructions. By focusing IGV on genomic position &lt;code&gt;chrX:11,897,111-11,920,446&lt;/code&gt; you will be able to see spliced alignments produced by TopHat:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/igv_tophat.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and &lt;a href=&#34;https://www.broadinstitute.org/igv/Sashimi&#34;&gt;sashimi plots&lt;/a&gt; highlighting potential splice junctions:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/sashimi.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;performing-differential-expression-analysis&#34;&gt;Performing differential expression analysis&lt;/h3&gt;

&lt;p&gt;Using mapped reads produced by TopHat we will perform analysis of differential gene expression using HTSeq/DESeq2 pipeline.&lt;/p&gt;

&lt;h4 id=&#34;gene-based-read-counting-with-htseq-count&#34;&gt;Gene-based read counting with HTseq-count&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;http://www-huber.embl.de/users/anders/HTSeq/doc/count.html&#34;&gt;&lt;code&gt;HTSeq-count&lt;/code&gt;&lt;/a&gt; is one of the most popular tools for gene quantification. &lt;code&gt;HTseq-count&lt;/code&gt; gives you multiple choices on how to handle read mapping to multiple locations, reads overlapping introns, or reads that overlap more than one genomic feature:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www-huber.embl.de/users/anders/HTSeq/doc/count.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/htseq_count.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;code&gt;HTseq-count&lt;/code&gt; read/feature overlap modes&lt;/strong&gt;&lt;br&gt;
The &lt;code&gt;htseq-count&lt;/code&gt; script of the HTSeq suite offers three different modes to handle details of read–feature overlaps that are depicted here. The default of featureCounts is the behavior of the union option. Image is from &lt;a href=&#34;http://www-huber.embl.de/users/anders/HTSeq/doc/count.html&#34;&gt;HTseq documentation&lt;/a&gt;; Caption by &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/&#34;&gt;Dündar:2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Before we can use &lt;code&gt;HTseq-count&lt;/code&gt; we need to download gene annotations for version &lt;code&gt;dm3&lt;/code&gt; of the &lt;em&gt;Drosophila melanogaster&lt;/em&gt; genome. We use version &lt;code&gt;dm3&lt;/code&gt; because it is the same genome we have mapped reads against during the TopHat step.&lt;/p&gt;

&lt;h4 id=&#34;getting-drosophila-malanogaster-gene-annotation-from-ucsc&#34;&gt;Getting &lt;em&gt;Drosophila malanogaster&lt;/em&gt; gene annotation from UCSC&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;Select &lt;strong&gt;UCSC Main&lt;/strong&gt; from &lt;strong&gt;Get Data&lt;/strong&gt; section of the menu. Within the UCSC Genome Browser interface set parameters as shown below. In particular make sure that &lt;strong&gt;assembly&lt;/strong&gt; is set ti &lt;code&gt;dm3&lt;/code&gt; and &lt;strong&gt;output format&lt;/strong&gt; is set to &lt;code&gt;GTF&lt;/code&gt;. Click &lt;strong&gt;get output&lt;/strong&gt;.
&lt;a href=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/ucsc_dm3.png&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/ucsc_dm3.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This &lt;a href=&#34;http://www.ensembl.org/info/website/upload/gff.html&#34;&gt;GTF&lt;/a&gt; dataset will be used one of the input for HTseq-count.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;code&gt;HTseq-count&lt;/code&gt; takes two inputs: (1) mapped reads in BAM format and (2) a GTF dataset containing annotation of genes. Using these inputs it will compute the number of reads per gene.&lt;/p&gt;

&lt;h4 id=&#34;using-htseq-count-in-galaxy&#34;&gt;Using HTseq-count in Galaxy&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;htseq-count&lt;/code&gt; needs strand information to proceed. The strand information is specified as &lt;code&gt;+&lt;/code&gt;, &lt;code&gt;-&lt;/code&gt;, or &lt;code&gt;.&lt;/code&gt; (unknown) in a GTF dataset. &lt;code&gt;htseq-count&lt;/code&gt; does not like &lt;code&gt;.&lt;/code&gt; and will generate an error if such unstranded features appear in data. To prevent these errors from happening we will filter them out from GTF file using &lt;strong&gt;Filter&lt;/strong&gt; tool from &lt;strong&gt;Filter and Sort&lt;/strong&gt; section of tool menu. Here &lt;code&gt;c7 != &amp;quot;.&amp;quot;&lt;/code&gt; means that we need to filter all rows where strand column (column #7) contains a dot:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/filter_gtf.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;strong&gt;htseq-count&lt;/strong&gt; from &lt;strong&gt;NGS: RNA analysis&lt;/strong&gt; section on the left side of the menu. Set parameters as shown below. The red arrow points that to enable &lt;code&gt;htseq-count&lt;/code&gt; to see collections, you need to select the &amp;lsquo;folder&amp;rsquo; button. In the case of this particular Galaxy &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/rna-seq-tutorial&#34;&gt;history&lt;/a&gt; we will need to run &lt;code&gt;htseq-count&lt;/code&gt; twice. Once on TopHat alignemnts for collection &lt;strong&gt;c1&lt;/strong&gt; (dataset #37; shown below) and then on alignments for collection &lt;strong&gt;c2&lt;/strong&gt; (dataset # 57).|
|&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/htseq_count_interface.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will generate &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5d1e80eae6d363142/display/?preview=True&#34;&gt;read counts per gene&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;normalizing-read-counts-and-computing-differential-expression-with-deseq2&#34;&gt;Normalizing read counts and computing differential expression with &lt;code&gt;DESeq2&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;DESeq2&lt;/code&gt; takes read counts produced by &lt;code&gt;HTseq-count&lt;/code&gt; and apply size factor normalization. Specifically, &lt;code&gt;DESeq2&lt;/code&gt; will:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;For each gene, compute the geometric mean of read counts across all samples;&lt;/li&gt;
&lt;li&gt;Every gene count in then divided by the geometric mean;&lt;/li&gt;
&lt;li&gt;The median of these ratios is a sample&amp;rsquo;s size factor used for normalization.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;font color=&#34;red&#34;&gt;&amp;#10148;&lt;/font&gt; &lt;strong&gt;Note&lt;/strong&gt;: For a comprehensive overview of differential gene expression with DESeq2 see &lt;a href=&#34;https://www.bioconductor.org/packages/3.3/bioc/vignettes/DESeq2/inst/doc/DESeq2.pdf&#34;&gt;Love:2016&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;deseq2-in-galaxy&#34;&gt;DESeq2 in Galaxy&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;The &lt;code&gt;DESeq2&lt;/code&gt; Galaxy&amp;rsquo;s interface is shown below. &lt;code&gt;DESeq2&lt;/code&gt; allows to incorporate multiple &lt;em&gt;factors&lt;/em&gt; in the analysis. In our case we only have one factor, which we call &lt;strong&gt;Conditions&lt;/strong&gt;. This is because we are trying to find genes that are differentially expressed between two conditions. The first condition will the first &lt;strong&gt;factor level&lt;/strong&gt;, while condition 2 will be the second &lt;strong&gt;factor level&lt;/strong&gt;. Here the input for this first factor level is set to a collection &lt;code&gt;84: htseq-count on collection 37&lt;/code&gt; and the input for the second input is set to &lt;code&gt;92: htseq-count on collection 57&lt;/code&gt;. Make sure that &lt;strong&gt;Visualising the analysis results&lt;/strong&gt; is set to &lt;code&gt;Yes&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/deseq2_interface.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will produce &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5d648fe21c36ac662/display/?preview=True&#34;&gt;output&lt;/a&gt; as shown below. The columns are: (&lt;strong&gt;1&lt;/strong&gt;) gene identifier, (&lt;strong&gt;2&lt;/strong&gt;) mean normalised counts, averaged over all samples from both conditions, (&lt;strong&gt;3&lt;/strong&gt;) logarithm (base 2) of the fold change, (&lt;strong&gt;4&lt;/strong&gt;) the standard error estimate for the log2 fold change estimate, (&lt;strong&gt;5&lt;/strong&gt;) &lt;a href=&#34;https://en.wikipedia.org/wiki/Wald_test&#34;&gt;Wald test&lt;/a&gt; statistic, (&lt;strong&gt;6&lt;/strong&gt;) p value for the statistical significance of this change, and (&lt;strong&gt;7&lt;/strong&gt;) &lt;em&gt;p&lt;/em&gt;-value adjusted for multiple testing with the Benjamini-Hochberg procedure which controls false discovery rate (&lt;a href=&#34;https://en.wikipedia.org/wiki/False_discovery_rate&#34;&gt;FDR&lt;/a&gt;). There is only one gene with significant change in gene expression between conditions: &lt;code&gt;CG1803-RC&lt;/code&gt; with &lt;em&gt;p&lt;/em&gt;-value = 1.6x10&lt;sup&gt;-05&lt;/sup&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/deseq2_output.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;In addition to the &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5d648fe21c36ac662/display/?preview=True&#34;&gt;list of genes&lt;/a&gt; DESeq2 outputs a graphical summary of the result. It includes a number of plots that should be used to evaluate the quality of the experiment. The histogram of &lt;em&gt;p&lt;/em&gt;-values below shows that in our sample there is in fact just one instance of a significant &lt;em&gt;p&lt;/em&gt;-value:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/p_val_hist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/MA_plot&#34;&gt;MA plot&lt;/a&gt; below shows the relationship between the expression change (M) and average expression strength (A). Genes with adjusted &lt;em&gt;p&lt;/em&gt;-value &amp;lt; 0.1 are in red (there is only one such gene in thi sample at the bottom of the graph):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/MA_plot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The Principal Component Analysis (&lt;a href=&#34;https://en.wikipedia.org/wiki/Principal_component_analysis&#34;&gt;PCA&lt;/a&gt;) shows the separation between Condition 1 and 2. This type of plot is useful for visualizing the overall effect of experimental covariates and batch effects (each replicate is plotted as an individual data point):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pca.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A heatmap of sample-to-sample distance matrix gives us an overview over similarities and dissimilarities between samples:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/euc_dist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;what-s-next&#34;&gt;What&amp;rsquo;s next&lt;/h2&gt;

&lt;p&gt;You will next learn:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;ad hoc&lt;/em&gt; analyses with R using Galaxy&amp;rsquo;s interactive environment. This will allow executing R code directly in Galaxy as it is used in many RNAseq tutorials;&lt;/li&gt;
&lt;li&gt;reference-free RNAseq with &lt;code&gt;Trinity&lt;/code&gt;;&lt;/li&gt;
&lt;li&gt;Differential Transcript expression with &lt;code&gt;Sailfish&lt;/code&gt; and &lt;code&gt;DESeq2&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Duplex sequence analysis</title>
      <link>http://nekrut.github.io/BMMB554/post/topic10/</link>
      <pubDate>Wed, 09 Nov 2016 17:19:07 -0500</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic10/</guid>
      <description>

&lt;p&gt;This page explains how to perform discovery of low frequency variants from duplex sequencing data. As an example we use the &lt;em&gt;ABL1&lt;/em&gt; dataset published by &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n5/full/nmeth.3351.html&#34;&gt;Schmitt and colleagues&lt;/a&gt; (SRA accession &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/sra/?term=SRR1799908&#34;&gt;SRR1799908&lt;/a&gt;).&lt;/p&gt;

&lt;h1 id=&#34;background&#34;&gt;Background&lt;/h1&gt;

&lt;p&gt;Calling low frequency variants from next generation sequencing (NGS) data is challenging due to significant amount of noise characteristic of these technologies. &lt;a href=&#34;http://www.pnas.org/content/109/36/14508.short&#34;&gt;Duplex sequencing&lt;/a&gt; (DS) was designed to address this problem by increasing sequencing accuracy by over four orders of magnitude. DS uses randomly generated barcodes to uniquely tag each molecule in a sample. The tagged fragments are then PCR amplified prior to the preparation of a sequencing library, creating fragment families characterized by unique combination of barcodes at both 5’ and 3’ ends:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.pnas.org/content/109/36/14508/F1.expansion.html&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/ds.png&#34; alt=&#34;duplex&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;The logic of duplex sequencing. From &lt;a href=&#34;http://www.pnas.org/content/109/36/14508.short&#34;&gt;Schmitt:2012&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The computational analysis of DS data (Part &lt;code&gt;C&lt;/code&gt; in the figure above) produces two kinds of output:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Single Strand Consensus Sequences (SSCS; panel &lt;code&gt;iv&lt;/code&gt; in the figure above);&lt;/li&gt;
&lt;li&gt;Duplex Consensus Sequences (DCS; panel &lt;code&gt;v&lt;/code&gt; in the figure above).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The DCSs have the ultimate accuracy, yet the SSCSs can also be very useful when ampliconic DNA is used as an input to a DS experiment. Let us illustrate the utility of SSCSs with the following example. Suppose one is interested in quantifying variants in a virus that has a very low titer in body fluids. Since DS procedure requires a substantial amount of starting DNA (between &lt;a href=&#34;http://nature.com/nprot/journal/v9/n11/full/nprot.2014.170.html&#34;&gt;between 0.2 and 3 micrograms&lt;/a&gt;) the virus needs to be enriched. This can be done, for example, with a PCR designed to amplify the entire genome of the virus. Yet the problem is that during the amplification heterologous strands will almost certainly realign to some extent forming hetoroduplex molecules:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/het.png&#34; alt=&#34;hd&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Heteroduplex formation in ampliconic templates. Image by Barbara Arbeithuber from &lt;a href=&#34;https://genomebiology.biomedcentral.com/articles/10.1186/s13059-016-1039-4&#34;&gt;Stoler:2016&lt;/a&gt;. Here there are two distinct types of viral genomes: carrying &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;G&lt;/code&gt;. Because the population of genomes is enriched via PCR, heteroduplex formation takes place, skewing frequency estimates performed using DCSs.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the image above there are two alleles: green (A) and red (G). After PCR a fraction of molecules are in heteroduplex state. If this PCR-derived DNA is now used as the starting material for a DS experiment, the heteroduplex molecules will manifest themselves as having an &lt;code&gt;N&lt;/code&gt; base at this site (because &lt;em&gt;Du Novo&lt;/em&gt; interprets disagreements as &lt;code&gt;N&lt;/code&gt;s during consensus generation). So, DSCs produced from this dataset will have &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt;, and &lt;code&gt;N&lt;/code&gt; at the polymorphic site. Yet, SSCSs will only have &lt;code&gt;A&lt;/code&gt; and &lt;code&gt;G&lt;/code&gt;. Thus SSCS will give a more accurate estimate of the allele frequency at this site in this particular case. In &lt;em&gt;Du Novo&lt;/em&gt; SSCSs are generated when the &lt;strong&gt;Output single-strand consensus sequences&lt;/strong&gt; option of &lt;strong&gt;Du Novo: Make consensus reads&lt;/strong&gt; tool is set to &lt;code&gt;Yes&lt;/code&gt; (see &lt;a href=&#34;#generating-duplex-consensus-sequences-dcs&#34;&gt;here&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;how-to-use-this-tutorial&#34;&gt;How to use this tutorial&lt;/h2&gt;

&lt;p&gt;The entire analysis described here is accessible as a &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/duplex-analysis-abl1&#34;&gt;Galaxy history&lt;/a&gt; (by clicking on this link you can create your own copy and play with it).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/duplex/histItem.png&#34; alt=&#34;History Item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Each history item has a Rerun &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-refresh.png&#34; alt=&#34;refresh&#34; /&gt; button. Clicking this button will show you how this tool was run with all parameters filled in exactly.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This analysis (and consequently the Galaxy&amp;rsquo;s history) can be divided into three parts
 1. Consensus generation from initial sequencing reads;
 2. Analysis of Duplex Consensus Sequences (DCS);
 3. Analysis of Single Strand Consensus Sequences (SSCS):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/steps.png&#34; alt=&#34;steps&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Analysis outline&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;start-generating-consensus-sequences&#34;&gt;Start: Generating consensus sequences&lt;/h1&gt;

&lt;p&gt;The starting point of the analyses are sequencing reads (usually in &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;fastq&lt;/a&gt; format) produced from a duplex sequencing library.&lt;/p&gt;

&lt;h2 id=&#34;getting-data-in-and-assessing-quality&#34;&gt;Getting data in and assessing quality&lt;/h2&gt;

&lt;p&gt;We uploaded &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n5/full/nmeth.3351.html&#34;&gt;Schmitt:2015&lt;/a&gt;) data directly from SRA as shown in &lt;a href=&#34;https://vimeo.com/121187220&#34;&gt;this screencast&lt;/a&gt;. This created two datasets in our galaxy history: one for forward reads and one for reverse. We then evaluated the quality of the data by running FastQC on both datasets (forward and reverse) to obtain the following plots:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/abl1-f-qc.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/abl1-r-qc.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;A&lt;/strong&gt;. Forward&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;B&lt;/strong&gt;. Reverse&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;One can see that these data are of excellent quality and no additional processing is required before we can start the actual analysis.&lt;/p&gt;

&lt;h2 id=&#34;generating-duplex-consensus-sequences-dcs&#34;&gt;Generating Duplex Consensus Sequences (DCS)&lt;/h2&gt;

&lt;p&gt;From tool section &lt;strong&gt;NGS: Du Novo&lt;/strong&gt; we ran:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;Make families&lt;/strong&gt; (&lt;code&gt;Tag length = 12&lt;/code&gt;; &lt;code&gt;Invariant sequence length = 5&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Align families&lt;/strong&gt; (This is &lt;strong&gt;the most&lt;/strong&gt; time consuming step of the workflow. It may take multiple days to run. The &lt;em&gt;ABL1&lt;/em&gt; example took 34 hours and 7 minutes to finish. )&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Make consensus reads&lt;/strong&gt; (&lt;code&gt;Minimum reads per family = 3&lt;/code&gt;; &lt;code&gt;Minimum base quality = 20&lt;/code&gt;; &lt;code&gt;FASTQ format = Sanger&lt;/code&gt; ; &lt;code&gt;Output single-strand consensus sequences = Yes&lt;/code&gt; :point_left: This is particularly important as explained below; also see the following image)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This is the exact image of the &lt;strong&gt;Make consensus reads&lt;/strong&gt; interface:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/makeCons.png&#34; alt=&#34;Make consesni&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Making DCS and SSCS. &lt;strong&gt;Note&lt;/strong&gt; that &lt;strong&gt;Output single-strand consensus sequences&lt;/strong&gt; is set to &lt;code&gt;Yes&lt;/code&gt;. &lt;a href=&#34;#background&#34;&gt;Above&lt;/a&gt; we explained why single-strand consensus sequences (SSCS) may be important in some applications. &lt;a href=&#34;#analysis-of-single-strand-consensus-data&#34;&gt;Below&lt;/a&gt; we show how they can be used.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;filtering-consensuses&#34;&gt;Filtering consensuses&lt;/h2&gt;

&lt;p&gt;The &lt;em&gt;Du Novo&lt;/em&gt; algorithm occasionally inserts&lt;code&gt;N&lt;/code&gt;and/or &lt;a href=&#34;https://en.wikipedia.org/wiki/Nucleic_acid_notation&#34;&gt;IUPAC notations&lt;/a&gt; at sites where a definive base cannot be identified according to the major rule consensus. We however do not want such bases when we call variants. The tool &lt;strong&gt;Sequence Content Trimmer&lt;/strong&gt; will help with filtering these out. Here are the parameters we used:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/contentTrimmer.png&#34; alt=&#34;ContentTrimmer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sequence Content Trimmer settings . Where:&lt;br&gt;- &lt;code&gt;Paired reads = Paired&lt;/code&gt; (because DCSs are reported as forward and reverse)&lt;br&gt;- &lt;code&gt;Bases to filter on = NRYSWKMBDHV&lt;/code&gt; (all ambiguous nucleotides)&lt;br&gt;- &lt;code&gt;Frequency threshold = 0.2&lt;/code&gt; (A window /see the next parameter below/ cannot have more than 20% of ambiguous bases)&lt;br&gt;- &lt;code&gt;Size of the window = 10&lt;/code&gt; (Size of the window)&lt;br&gt;- &lt;code&gt;Invert filter bases = No&lt;/code&gt;&lt;br&gt;- &lt;code&gt;Set a minimum read length = 50&lt;/code&gt; (We do not want &lt;em&gt;very&lt;/em&gt; short reads)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;generating-fastq&#34;&gt;Generating fastq&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;#filtering-consensuses&#34;&gt;The previous step&lt;/a&gt; filters forward and reverse DCSs and reports them in &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTA_format&#34;&gt;FASTA&lt;/a&gt; format. Yet the downstream tools require &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;fastq&lt;/a&gt; format. To address this we convert FASTA into fastq using &lt;strong&gt;Combine FASTA and QUAL&lt;/strong&gt; from tool section &lt;strong&gt;NGS: QC and manipulation&lt;/strong&gt;. In this case the quality values are filled in with the maximum allowed value of 93 (essentially we fake them here), which is fine as we will not rely on quality scores in the rest of the analysis.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/combineFandQ.png&#34; alt=&#34;ContentTrimmer&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Combine FASTA and QUAL. &lt;strong&gt;Note&lt;/strong&gt; that here two datasets (#8 and #9) are selected simultaneously because we clicked the multiple datasets button the left of the &lt;strong&gt;FASTA File&lt;/strong&gt; dropdown:&lt;br&gt; &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/multiDataset.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;calling-variants&#34;&gt;Calling variants&lt;/h2&gt;

&lt;p&gt;At this point we have trimmed DCSs in fastq format. We can now proceed to calling variants. This involves the following steps:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;#align-against-genome-with-bwa-and-bwa-mem&#34;&gt;Align against reference genome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#merging&#34;&gt;Merge results of multiple mappers&lt;/a&gt; :point_left: This step is only useful if one uses multiple mappers (which we do here to show concordance. But this is not strictly necessary.)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#left-aligning-indels&#34;&gt;Left aligning indels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tabulating-the-differences&#34;&gt;Tabulate the differences&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;align-against-genome-with-bwa-and-bwa-mem&#34;&gt;Align against genome with &lt;strong&gt;BWA&lt;/strong&gt; and &lt;strong&gt;BWA-MEM&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;Here we use two mappers for added reliability (this is not necessary in most situations as long as you use the right mapper for input data). To differentiate between results produced by each mapper we assign readgroups (this is done by clicking on &lt;strong&gt;Set read groups information&lt;/strong&gt; dropdown). For example, for &lt;strong&gt;BWA-MEM&lt;/strong&gt; you would set parameters like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/bwa-mem.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running BWA-MEM. &lt;strong&gt;Note&lt;/strong&gt; that we are comparing DCSs against human genome version &lt;code&gt;hg38&lt;/code&gt;, use forward and reverse DCSs are the &lt;code&gt;first&lt;/code&gt; and &lt;code&gt;second&lt;/code&gt; set of reads. Readgroup &lt;strong&gt;SM&lt;/strong&gt; and &lt;strong&gt;ID&lt;/strong&gt; tags are set &lt;code&gt;bwa-mem&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We then repeat essentially the same with &lt;strong&gt;BWA&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/bwa.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running BWA. &lt;strong&gt;Note&lt;/strong&gt; here we use &lt;code&gt;bwa&lt;/code&gt; as the readgroup &lt;strong&gt;ID&lt;/strong&gt; and &lt;strong&gt;SM&lt;/strong&gt; tags.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;merging&#34;&gt;Merging&lt;/h3&gt;

&lt;p&gt;Since we have used two mappers - we have two BAM datasets. Yet because we have set readgroups we can now merge them into a single BAM dataset. This is because the individual reads will be labelled with readgroups (you will see how it will help later). To merge we use &lt;strong&gt;MergeSamFiles&lt;/strong&gt; from tool section &lt;strong&gt;NGS: Picard&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mergeSamFiles.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Merging BAM datasets.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;left-aligning-indels&#34;&gt;Left Aligning indels&lt;/h3&gt;

&lt;p&gt;To normalize the positional distribution of indels we use &lt;strong&gt;Left Align&lt;/strong&gt; utility (&lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt;) from &lt;a href=&#34;https://github.com/ekg/freebayes#indels&#34;&gt;FreeBayes&lt;/a&gt; package. This is necessary to avoid erroneous polymorphisms flanking regions with indels (e.g., in low complexity loci):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/leftAlign.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Left aligning indels. &lt;strong&gt;Note&lt;/strong&gt; here we use &lt;code&gt;hg38&lt;/code&gt; as well. Obviously, one must use the same genome built you have aligned against with &lt;strong&gt;BWA-MEM&lt;/strong&gt; and &lt;strong&gt;BWA&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;tabulating-the-differences&#34;&gt;Tabulating the differences&lt;/h3&gt;

&lt;p&gt;To identify sites containing variants we use &lt;strong&gt;Naive Variant Caller (NVC)&lt;/strong&gt; (tool section &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt;) which produces a simple count of differences given coverage and base quality per site (remember that our qualities were &amp;ldquo;faked&amp;rdquo; during the conversion from FASTA to fastq and cannot be used here). So in the case of &lt;em&gt;ABL1&lt;/em&gt; we set parameters as follow:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/nvc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finding variants with NVC. Here:&lt;br&gt;- &lt;code&gt;Using reference genome = hg38&lt;/code&gt; (As mentioned above, needs to be set to the same genome one have mapped against.)&lt;br&gt;- &lt;code&gt;Restrict to regions: Chromosome = chr9&lt;/code&gt; (&lt;em&gt;ABL1&lt;/em&gt; is on chromosome 9. We set this to prevent &lt;strong&gt;NVC&lt;/strong&gt; from wandering across the genome to save time.)&lt;br&gt;- &lt;code&gt;Minimum number of reads needed to consider a REF/ALT = 0&lt;/code&gt; (Trying to maximize the number of sites. We can filter later.)&lt;br&gt;- &lt;code&gt;Minimum base quality = 20&lt;/code&gt; (This default and is irrelevant because of &amp;ldquo;faking&amp;rdquo; quality scores during the conversion from FASTA to fastq).&lt;br&gt;- &lt;code&gt;Minimum mapping quality = 20&lt;/code&gt; (This is helpful because it prevents reads mapping to multiple locations from being included in the tabulation. Such reads will have mapping quality of 0.)&lt;br&gt;- &lt;code&gt;Ploidy = 1&lt;/code&gt; (Ploidy is irrelevant here as it is a mixture of multiple genomes)&lt;br&gt;- &lt;code&gt;Only write out positions with possible alternate alleles = No&lt;/code&gt; (We can filter later)&lt;br&gt;- &lt;code&gt;Report counts by strand = Yes&lt;/code&gt; (This will be helpful to gauge the strand bias).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The &lt;strong&gt;NVC&lt;/strong&gt; generates a &lt;a href=&#34;https://en.wikipedia.org/wiki/Variant_Call_Format&#34;&gt;VCF&lt;/a&gt; file that can be viewed at genome browsers such as &lt;a href=&#34;https://www.broadinstitute.org/igv/&#34;&gt;IGV&lt;/a&gt;. Yet one rarely finds variants by looking at genome browsers. The next step is to generate a tab-delimited dataset of nucleotide counts using &lt;strong&gt;Variant Annotator&lt;/strong&gt; from tool section &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt;. We ran it with the following parameters:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/va.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Annotating variable sites. Here &lt;code&gt;Coverage threshold = 10&lt;/code&gt; (To reduce noise) and &lt;code&gt;Output stranded base counts = Yes&lt;/code&gt; (to see strand bias)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;There are 3,264 lines in the output, which is clearly too much. Using &lt;strong&gt;Filter&lt;/strong&gt; tool (tool section &lt;strong&gt;Filter and Sort&lt;/strong&gt;) with expression &lt;code&gt;c16 &amp;gt;= 0.01&lt;/code&gt;(because column 16 contains minor allele frequency - MAF - and we are interested in those sites where MAF &amp;gt;= 1%):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/filter.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Filtering variable sites.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;will get that number to only 4 (showing just some of the columns):&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Mapper&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Position (chr9)&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Major allele&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Minor allele&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;MAF&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;bwa&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130,872,141&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;bwa-mem&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130,872,141&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.013&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;bwa&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130,880,141&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.479&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;bwa-mem&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130,880,141&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;A&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;G&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.479&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;We can see that results of both mappers agree very well. The reason we see these numbers grouped by mappers is because we have set the readgroups while &lt;a href=&#34;#align-against-genome-with-bwa-and-bwa-mem&#34;&gt;mapping&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;The polymorphism we are interested in (and the one reported by &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n5/full/nmeth.3351.html&#34;&gt;Schmitt:2015&lt;/a&gt;) is at the position 130,872,141 and has a frequency of 1.3%. The other site (position 130,880,141) is a known common variant &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/snp_ref.cgi?type=rs&amp;amp;rs=rs2227985&#34;&gt;rs2227985&lt;/a&gt;, which is heterozygous in this sample.&lt;/p&gt;

&lt;h1 id=&#34;analysis-of-single-strand-consensus-data&#34;&gt;Analysis of single strand consensus data&lt;/h1&gt;

&lt;p&gt;SSCSs are generated when the &lt;strong&gt;Output single-strand consensus sequences&lt;/strong&gt; option of &lt;strong&gt;Du Novo: Make consensus reads&lt;/strong&gt; tool is set to &lt;code&gt;Yes&lt;/code&gt; (see &lt;a href=&#34;#generating-duplex-consensus-sequences-dcs&#34;&gt;here&lt;/a&gt;). Analysis of SSCS data follows almost exactly the same trajectory. The only difference is that these &lt;strong&gt;do not&lt;/strong&gt; come as forward and reverse. Instead &lt;em&gt;Du Novo&lt;/em&gt; generates a single dataset. With this dataset we go through all the same steps:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#filtering-consensi&#34;&gt;Filtering consensi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#generating-fastq&#34;&gt;Generating fastq&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#calling-variants&#34;&gt;Calling variants&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;#align-against-genome-with-bwa-and-bwa-mem&#34;&gt;Aligning against genome&lt;/a&gt; (here the difference is that one needs to choose a single end option and use a single dataset as input)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#merging&#34;&gt;Merging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#left-aligning-indels&#34;&gt;Left aligning indels&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#tabulating-the-differences&#34;&gt;Tabulating the differences&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;repeating-this-analysis-using-workflows&#34;&gt;Repeating this analysis using workflows&lt;/h2&gt;

&lt;p&gt;The analysis described above can be rerun using a workflow. Workflow combined all steps into a single entity that only needs to be executed once. We provide two workflows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Du Novo&lt;/em&gt; analysis from reads (import from &lt;a href=&#34;https://usegalaxy.org/u/aun1/w/duplex-analysis-from-reads&#34;&gt;here&lt;/a&gt;). This workflow uses fastq reads as input. It should be used if you analyze data for first time.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Du Novo&lt;/em&gt; analysis from aligned families (import from &lt;a href=&#34;https://usegalaxy.org/u/aun1/w/copy-of-duplex-analysis-from-reads&#34;&gt;here&lt;/a&gt;). This workflow starts with aligned families. It should be used for re-analysis of already generated DCS and SSCS data.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://galaxyproject.org/duplex/fromReads.png&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/fromReads.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Starting from Reads&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://galaxyproject.org/duplex/fromDCS.png&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/fromDCS.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Starting from DCS/SSCS data&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;if-things-don-t-work&#34;&gt;If things don&amp;rsquo;t work&amp;hellip;&lt;/h2&gt;

&lt;p&gt;&amp;hellip;you need to complain. Use &lt;a href=&#34;https://usegalaxy.org/biostar/biostar_redirect&#34;&gt;Galaxy&amp;rsquo;s BioStar Channel&lt;/a&gt; to do this.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Non-diploid variant calling</title>
      <link>http://nekrut.github.io/BMMB554/post/topic9/</link>
      <pubDate>Mon, 31 Oct 2016 10:11:10 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic9/</guid>
      <description>

&lt;p&gt;The majority of life on Earth is non-diploid and represented by prokaryotes, viruses and their derivatives such as our own mitochondria or plant&amp;rsquo;s chloroplasts. In non-diploid systems allele frequencies can range anywhere between 0 and 100% and there could be multiple (not just two) alleles per locus. The main challenge associated with non-diploid variant calling is the difficulty in distinguishing between sequencing noise (abundant in all NGS platforms) and true low frequency variants. Some of the early attempts to do this well have been accomplished on human mitochondrial DNA although the same approaches will work equally good on viral and bacterial genomes:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.pnas.org/content/111/43/15474.abstract&#34;&gt;Maternal age effect and severe germ-line bottleneck in the inheritance of human mitochondrial DNA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://www.pnas.org/content/112/8/2491.abstract&#34;&gt;Extensive tissue-related and allele-related mtDNA heteroplasmy suggests positive selection for somatic mutations&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As an example of non-diploid system we will be using human mitochondrial genome as an example. However, this approach will also work for most bacterial and viral genomes as well.&lt;/p&gt;

&lt;h1 id=&#34;mapping-and-pre-processing&#34;&gt;Mapping and pre-processing&lt;/h1&gt;

&lt;p&gt;There are two ways one can call variants:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;By comparing reads against an existing genome assembly&lt;/li&gt;
&lt;li&gt;By assembling genome first and then mapping against that assembly&lt;/li&gt;
&lt;/ol&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/ref_vs_assembly.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This figure from a manuscript by &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4493402/&#34;&gt;Olson:2015&lt;/a&gt; contrasts the two approaches.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this tutorials we will take the &lt;em&gt;first&lt;/em&gt; path is which we map reads against an existing assembly. Later in the course (after we learn about assembly approaches) we will try the second approach as well.&lt;/p&gt;

&lt;h2 id=&#34;finding-variants-in-human-mitochondria&#34;&gt;Finding variants in human mitochondria&lt;/h2&gt;

&lt;p&gt;The goal of this example is to detect heteroplasmies (variants within mitochondrial DNA). Mitochondria is transmitted maternally and heteroplasmy frequencies may change dramatically and unpredictably during the transmission, due to a germ-line bottleneck &lt;a href=&#34;http://www.nature.com/ng/journal/v40/n2/abs/ng.2007.63.html&#34;&gt;Cree:2008&lt;/a&gt;. As we mentioned above the procedure for finding variants in bacterial or viral genomes will be essentially the same.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/Fe4842bd0c37b03a7&#34;&gt;A Galaxy Library&lt;/a&gt; contains datasets representing a child and a mother. These datasets are obtained by paired-end Illumina sequencing of human genomic DNA enriched for mitochondria. The enrichment was performed using long-range PCR with two primer pairs that amplify the entire mitochondrial genome. This means that these samples still contain a lot of DNA from the nuclear genome, which, in this case, is a contaminant.&lt;/p&gt;

&lt;p&gt;But first lets import data into Galaxy:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_lib.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select four datasets from &lt;a href=&#34;https://usegalaxy.org/library/list#folders/Fe4842bd0c37b03a7&#34;&gt;a library&lt;/a&gt; and click &lt;strong&gt;to History&lt;/strong&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s QC the datasets first by running  &lt;strong&gt;NGS: QC and manipulation &amp;#8594; FastQC&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_qc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;QC&amp;rsquo;ing reads using &lt;a href=&#34;http://www.bioinformatics.babraham.ac.uk/projects/fastqc/&#34;&gt;FastQC&lt;/a&gt;. Note that we selected all four datasets at once by pressing the middle button &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_middle_button.png&#34; alt=&#34;&#34; /&gt; adjacent to the &lt;strong&gt;Short read data from your current history&lt;/strong&gt; widget.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The data have generally high quality in this example:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_qc_plot.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;FastQC plot for one of the mitochondrial datasets shows that qualities are acceptable for 250 bp reads (mostly in the green, which is at or above &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_scorescore&#34;&gt;phred score&lt;/a&gt; of 30).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;mapping-the-reads&#34;&gt;Mapping the reads&lt;/h2&gt;

&lt;p&gt;Our reads are long (250 bp) and as a result we will be using &lt;a href=&#34;https://arxiv.org/pdf/1303.3997v2.pdf&#34;&gt;bwa mem&lt;/a&gt; to align them against the reference genome as it has good mapping performance for longer reads (100bp and up).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_bwa_mem.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Running &lt;code&gt;bwa mem&lt;/code&gt; on our datasets. Look &lt;strong&gt;carefully&lt;/strong&gt; at parameter settings:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We select &lt;code&gt;hg38&lt;/code&gt; version of the human genome as the reference&lt;/li&gt;
&lt;li&gt;By using the middle button again &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_middle_button.png&#34; alt=&#34;&#34; /&gt; we select datasets 1 and 3 as &lt;strong&gt;Select the first set of reads&lt;/strong&gt; and datasets 2 and 4 as &lt;strong&gt;Select the second set of reads&lt;/strong&gt;. Galaxy will automatically launch two bwa-mem jobs using datasets 1,2 and 3,4 generating two resulting BAM files.&lt;/li&gt;
&lt;li&gt;By setting &lt;strong&gt;Set read groups information&lt;/strong&gt; to `Set read groups (SAM/BAM specifications) and clicking &lt;strong&gt;Auto-assign&lt;/strong&gt; we will ensure that the reads in the resulting BAM dataset are properly set.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;hr color=&#34;red&#34;&gt;

&lt;h3 id=&#34;font-color-red-9888-reminder-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;&amp;#9888; Reminder&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;We already learned about read groups. Read again &lt;a href=&#34;http://nekrut.github.io/BMMB554/BMMB554/post/topic7/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;hr color=&#34;red&#34;&gt;

&lt;h2 id=&#34;merging-bam-datasets&#34;&gt;Merging BAM datasets&lt;/h2&gt;

&lt;p&gt;Because we have set read groups, we can now merge the two BAM dataset into one. This is because read groups label each read as belonging to either &lt;em&gt;mother&lt;/em&gt; or &lt;em&gt;child&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;We can BAM dataset using &lt;strong&gt;NGS: Picard&lt;/strong&gt; &amp;#8594; &lt;strong&gt;MergeSAMFiles&lt;/strong&gt; tool:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_bam_merging.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Merging two BAM datasets into one. Note that two inputs are highlighted.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;removing-duplicates&#34;&gt;Removing duplicates&lt;/h2&gt;

&lt;p&gt;Recall from our &lt;a href=&#34;http://nekrut.github.io/BMMB554/BMMB554/post/topic7/&#34;&gt;earlier material&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Preparation of sequencing libraries (at least at the time of writing) for technologies such as Illumina (used in this example) involves PCR amplification. It is required to generate sufficient number of sequencing templates so that a reliable detection can be performed by base callers. Yet PCR has it&amp;rsquo;s biases, which are especially profound in cases of multitemplate PCR used for construction of sequencing libraries (Kanagawa et al. &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;dopt=Abstract&amp;amp;list_uids=16233530&#34;&gt;2003&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Duplicates can be identified based on their outer alignment coordinates or using sequence-based clustering. One of the common ways for identification of duplicate reads is the &lt;code&gt;MarkDuplicates&lt;/code&gt; utility from &lt;a href=&#34;https://broadinstitute.github.io/picard/command-line-overview.html&#34;&gt;Picard&lt;/a&gt; package. It is designed to identify both PCR and optical duplicates:&lt;/p&gt;

&lt;p&gt;Duplicates are identified as read pairs having identical 5&amp;rsquo; positions (coordinate and strand) for both reads in a mate pair (and optionally, matching unique molecular identifier reads; see BARCODE_TAG option). Optical, or more broadly Sequencing, duplicates are duplicates that appear clustered together spatially during sequencing and can arise from optical/imagine-processing artifacts or from bio-chemical processes during clonal amplification and sequencing; they are identified using the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options. The tool&amp;rsquo;s main output is a new SAM or BAM file in which duplicates have been identified in the SAM flags field, or optionally removed (see REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES), and optionally marked with a duplicate type in the &amp;lsquo;DT&amp;rsquo; optional attribute. In addition, it also outputs a metrics file containing the numbers of READ_PAIRS_EXAMINED, UNMAPPED_READS, UNPAIRED_READS, UNPAIRED_READ DUPLICATES, READ_PAIR_DUPLICATES, and READ_PAIR_OPTICAL_DUPLICATES. Usage example: java -jar picard.jar MarkDuplicates I=input.bam \ O=marked_duplicates.bam M=marked_dup_metrics.txt.`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s use &lt;strong&gt;NGS: Picard&lt;/strong&gt; &amp;#8594; &lt;strong&gt;MarkDuplicates&lt;/strong&gt; tool:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_dedup.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;De-duplicating the merged BAM dataset&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;MarkDuplicates&lt;/strong&gt; produces a BAM dataset with duplicates removed and also a metrics file. Let&amp;rsquo;s take a look at the metrics data:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;raw_child-ds-	55	27551	55	50	1658	0	0.061026	219628
raw_mother-ds-	96	54972	96	90	4712	0	0.086459	302063
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where columns are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;LIBRARY (read group in our case)&lt;/li&gt;
&lt;li&gt;UNPAIRED_READS_EXAMINED&lt;/li&gt;
&lt;li&gt;READ_PAIRS_EXAMINED-&lt;/li&gt;
&lt;li&gt;UNMAPPED_READS&lt;/li&gt;
&lt;li&gt;UNPAIRED_READ_DUPLICATES&lt;/li&gt;
&lt;li&gt;READ_PAIR_DUPLICATES&lt;/li&gt;
&lt;li&gt;READ_PAIR_OPTICAL_DUPLICATES&lt;/li&gt;
&lt;li&gt;PERCENT_DUPLICATION&lt;/li&gt;
&lt;li&gt;ESTIMATED_LIBRARY_SIZE&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In other words the two datasets had ~6% and ~9% duplicates, respectively.&lt;/p&gt;

&lt;h2 id=&#34;left-aligning-indels&#34;&gt;Left-aligning indels&lt;/h2&gt;

&lt;p&gt;Left aligning of indels (a variant of re-aligning) is extremely important for obtaining accurate variant calls. This concept, while not difficult, requires some explanation. For illustrating how left-aligning works we expanded on an example provided by &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/31/13/2202.abstract&#34;&gt;Tan:2015&lt;/a&gt;. Suppose you have a reference sequence and a sequencing read:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Reference GGGCACACACAGGG
Read      GGGCACACAGGG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you look carefully you will see that the read is simply missing a &lt;code&gt;CA&lt;/code&gt; repeat. But it is not apparent to a mapper, so some of possible alignments and corresponding variant calls include:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Alignment                 Variant Call

GGGCACACACAGGG            Ref: CAC
GGGCAC--ACAGGG            Alt: C

GGGCACACACAGGG            Ref: ACA
GGGCA--CACAGGG            Alt: A

GGGCACACACAGGG            Ref: GCA
GGG--CACACAGGG            Alt: G
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The last of these is &lt;em&gt;left-aligned&lt;/em&gt;. In this case gaps (dashes) as moved as far left as possible (for a formal definition of left-alignment and variant normalization see &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/31/13/2202.abstract&#34;&gt;Tan:2015&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s perform left alignment using &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; &amp;#8594; &lt;strong&gt;BamLeftAlign&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_left_align.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Left-aligning a de-duplicated BAM dataset&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;filtering-reads&#34;&gt;Filtering reads&lt;/h2&gt;

&lt;p&gt;Remember that we are trying to call variants in mitochondrial genome. Let focus only on the reads derived from the mitochondrial genome by filtering everything else out. For this we will use &lt;strong&gt;NGS: BamTools&lt;/strong&gt; &amp;#8594; &lt;strong&gt;Filter&lt;/strong&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_filtering.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Filtering reads. There are several important point to note here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;mapQuality&lt;/strong&gt; is set to &amp;#8925; 20 Mapping quality reflects the probability that the read is placed &lt;em&gt;incorrectly&lt;/em&gt;. It uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_scorescore&#34;&gt;phred scale&lt;/a&gt;. Thus 20 is &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;100&lt;/sub&gt; or 1% chance that the read is incorrectly mapped. By setting this parameter to &amp;#8925; 20 we will keep all reads that have 1% or less probability of being mapped incorrectly.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;isPaired&lt;/em&gt; will eliminate singleton (unpaired) reads (make sure &lt;strong&gt;Yes&lt;/strong&gt; is clicked on)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;isProperPair&lt;/em&gt; will only keep reads that map to the same chromosome and are properly placed (again, make sure &lt;strong&gt;Yes&lt;/strong&gt; is clicked)&lt;/li&gt;
&lt;li&gt;&lt;em&gt;reference&lt;/em&gt; is set to &lt;em&gt;chrM&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;calling-non-diploid-variants-with-freebayes&#34;&gt;Calling non-diploid variants with FreeBayes&lt;/h1&gt;

&lt;p&gt;FreeBayes is widely used for calling variants in diploid systems. However, it can also be used for calling variants in pooled samples where the number of samples is not known. This is the exact scenario we have here: in our sample we have multiple mitochondrial (or bacterial or viral) genomes but we do not know exactly how many. Thus we will use the &lt;code&gt;--pooled-continuous&lt;/code&gt; option of FreeBayes to generate &lt;em&gt;frequency-based&lt;/em&gt; variant calls as well as some other options highlighted below (the tool is in &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; &amp;#8594; &lt;strong&gt;FreeBayes&lt;/strong&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_genome.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Set genome to &lt;code&gt;hg38&lt;/code&gt; (the latest version)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_regions.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Set regions to &lt;code&gt;chrM&lt;/code&gt; from &lt;code&gt;1&lt;/code&gt; to &lt;code&gt;16000&lt;/code&gt;. This will simply save us time since we are only interested in mitochondrial variants anyway&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_alloptions.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Choose &lt;code&gt;Complete list of all samples&lt;/code&gt; from &lt;strong&gt;Choose parameter selection level&lt;/strong&gt; drop down.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_popmodel.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is one of the most important parameter choices one needs to make when calling variants in non-diploid systems. Here set &lt;strong&gt;Set population model&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and then:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Set &lt;strong&gt;ploidy&lt;/strong&gt; to &lt;code&gt;1&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;strong&gt;Assume that samples result from pooled sequencing&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Set &lt;strong&gt;Output all alleles which pass input filters, regardless of genotyping outcome or model&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_allelic_scope.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We will also set &lt;strong&gt;Allelic scope&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and restrict variant types to single nucleotide polymorphisms only by:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Keeping &lt;strong&gt;Ignore SNP alleles&lt;/strong&gt; and &lt;strong&gt;Ignore indels alleles&lt;/strong&gt; set to &lt;code&gt;No&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Setting &lt;strong&gt;Ignore MNPs&lt;/strong&gt; and &lt;strong&gt;Ignore complex events&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Mitochondria has a number of low complexity regions (mononucleotide repeats). Setting these parameters as described above will decrease noise from these regions.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_freebayes_inputfilters.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally, let&amp;rsquo;s set &lt;strong&gt;Input filters&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt; and set:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Exclude alignments from analysis if they have a mapping quality less than&lt;/strong&gt; to &lt;code&gt;20&lt;/code&gt; (phred score of 20). This will make FreeBayes to only consider reliably aligned reads.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Exclude alleles from analysis if their supporting base quality less than&lt;/strong&gt; to &lt;code&gt;30&lt;/code&gt; (phred score of 30). This will make FreeBayes to only consider high quality bases.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will produce a &lt;a href=&#34;https://samtools.github.io/hts-specs/VCFv4.2.pdf&#34;&gt;VCF dataset&lt;/a&gt; shows below (you may need to scroll sideways to see it in full). It lists 30 sites of interest (everything starting with &lt;code&gt;#&lt;/code&gt; is a comment):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
Chrom	Pos	ID	Ref	Alt	Qual	Filter	Info	Format	data
##fileformat=VCFv4.1
##fileDate=20161108
##source=freeBayes v0.9.20
##reference=/galaxy/data/hg38/sam_index/hg38.fa
##phasing=none
##commandline=&amp;quot;freebayes --bam localbam_0.bam --fasta-reference /galaxy/data/hg38/sam_index/hg38.fa --vcf /galaxy-repl/main/files/017/782/dataset_17782376.dat --region chrM:1..16000&amp;quot;
##INFO=&amp;lt;ID=NS,Number=1,Type=Integer,Description=&amp;quot;Number of samples with data&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Total read depth at the locus&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DPB,Number=1,Type=Float,Description=&amp;quot;Total read depth per bp at the locus; bases in reads overlapping / bases in haplotype&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AC,Number=A,Type=Integer,Description=&amp;quot;Total number of alternate alleles in called genotypes&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AN,Number=1,Type=Integer,Description=&amp;quot;Total number of alleles in called genotypes&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AF,Number=A,Type=Float,Description=&amp;quot;Estimated allele frequency in the range (0,1]&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RO,Number=1,Type=Integer,Description=&amp;quot;Reference allele observation count, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AO,Number=A,Type=Integer,Description=&amp;quot;Alternate allele observations, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PRO,Number=1,Type=Float,Description=&amp;quot;Reference allele observation count, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAO,Number=A,Type=Float,Description=&amp;quot;Alternate allele observations, with partial observations recorded fractionally&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=QR,Number=1,Type=Integer,Description=&amp;quot;Reference allele quality sum in phred&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=QA,Number=A,Type=Integer,Description=&amp;quot;Alternate allele quality sum in phred&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PQR,Number=1,Type=Float,Description=&amp;quot;Reference allele quality sum in phred for partial observations&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PQA,Number=A,Type=Float,Description=&amp;quot;Alternate allele quality sum in phred for partial observations&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRF,Number=1,Type=Integer,Description=&amp;quot;Number of reference observations on the forward strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRR,Number=1,Type=Integer,Description=&amp;quot;Number of reference observations on the reverse strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAF,Number=A,Type=Integer,Description=&amp;quot;Number of alternate observations on the forward strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAR,Number=A,Type=Integer,Description=&amp;quot;Number of alternate observations on the reverse strand&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SRP,Number=1,Type=Float,Description=&amp;quot;Strand balance probability for the reference allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SRF and SRR given E(SRF/SRR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=SAP,Number=A,Type=Float,Description=&amp;quot;Strand balance probability for the alternate allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SAF and SAR given E(SAF/SAR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=AB,Number=A,Type=Float,Description=&amp;quot;Allele balance at heterozygous sites: a number between 0 and 1 representing the ratio of reads showing the reference allele to all reads, considering only reads from individuals called as heterozygous&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=ABP,Number=A,Type=Float,Description=&amp;quot;Allele balance probability at heterozygous sites: Phred-scaled upper-bounds estimate of the probability of observing the deviation between ABR and ABA given E(ABR/ABA) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RUN,Number=A,Type=Integer,Description=&amp;quot;Run length: the number of consecutive repeats of the alternate allele in the reference genome&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPP,Number=A,Type=Float,Description=&amp;quot;Read Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPPR,Number=1,Type=Float,Description=&amp;quot;Read Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between RPL and RPR given E(RPL/RPR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPL,Number=A,Type=Float,Description=&amp;quot;Reads Placed Left: number of reads supporting the alternate balanced to the left (5&#39;) of the alternate allele&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=RPR,Number=A,Type=Float,Description=&amp;quot;Reads Placed Right: number of reads supporting the alternate balanced to the right (3&#39;) of the alternate allele&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=EPP,Number=A,Type=Float,Description=&amp;quot;End Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=EPPR,Number=1,Type=Float,Description=&amp;quot;End Placement Probability for reference observations: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=DPRA,Number=A,Type=Float,Description=&amp;quot;Alternate allele depth ratio. Ratio between depth in samples with each called alternate allele and those without.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=ODDS,Number=1,Type=Float,Description=&amp;quot;The log odds ratio of the best genotype combination to the second-best.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=GTI,Number=1,Type=Integer,Description=&amp;quot;Number of genotyping iterations required to reach convergence or bailout.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=TYPE,Number=A,Type=String,Description=&amp;quot;The type of allele, either snp, mnp, ins, del, or complex.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=CIGAR,Number=A,Type=String,Description=&amp;quot;The extended CIGAR representation of each alternate allele, with the exception that &#39;=&#39; is replaced by &#39;M&#39; to ease VCF parsing. Note that INDEL alleles do not have the first matched base (which is provided by default, per the spec) referred to by the CIGAR.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=NUMALT,Number=1,Type=Integer,Description=&amp;quot;Number of unique non-reference alleles in called genotypes at this position.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MEANALT,Number=A,Type=Float,Description=&amp;quot;Mean number of unique non-reference allele observations per sample with the corresponding alternate alleles.&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=LEN,Number=A,Type=Integer,Description=&amp;quot;allele length&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MQM,Number=A,Type=Float,Description=&amp;quot;Mean mapping quality of observed alternate alleles&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=MQMR,Number=1,Type=Float,Description=&amp;quot;Mean mapping quality of observed reference alleles&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAIRED,Number=A,Type=Float,Description=&amp;quot;Proportion of observed alternate alleles which are supported by properly paired read fragments&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=PAIREDR,Number=1,Type=Float,Description=&amp;quot;Proportion of observed reference alleles which are supported by properly paired read fragments&amp;quot;&amp;gt;
##INFO=&amp;lt;ID=technology.ILLUMINA,Number=A,Type=Float,Description=&amp;quot;Fraction of observations supporting the alternate observed in reads from ILLUMINA&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GT,Number=1,Type=String,Description=&amp;quot;Genotype&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GQ,Number=1,Type=Float,Description=&amp;quot;Genotype Quality, the Phred-scaled marginal (or unconditional) probability of the called genotype&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=GL,Number=G,Type=Float,Description=&amp;quot;Genotype Likelihood, log10-scaled likelihoods of the data given the called genotype for each possible genotype generated from the reference and alternate alleles given the sample ploidy&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Read Depth&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=RO,Number=1,Type=Integer,Description=&amp;quot;Reference allele observation count&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=QR,Number=1,Type=Integer,Description=&amp;quot;Sum of quality of the reference observations&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=AO,Number=A,Type=Integer,Description=&amp;quot;Alternate allele observation count&amp;quot;&amp;gt;
##FORMAT=&amp;lt;ID=QA,Number=A,Type=Integer,Description=&amp;quot;Sum of quality of the alternate observations&amp;quot;&amp;gt;
#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	raw_child-ds-	raw_mother-ds-
chrM	73	.	A	G	33368.5	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1095;CIGAR=1X;DP=1098;DPB=1098;DPRA=0;EPP=107.005;EPPR=5.18177;GTI=0;LEN=1;MEANALT=1.5;MQM=55.7744;MQMR=60;NS=2;NUMALT=1;ODDS=509.945;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=37602;QR=37;RO=1;RPL=359;RPP=284.863;RPPR=5.18177;RPR=736;RUN=1;SAF=507;SAP=16.0213;SAR=588;SRF=0;SRP=5.18177;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:273:0:0:273:9187:-827.167,-82.1812,0	1/1:825:1:37:822:28415:-2554.14,-241.429,0
chrM	263	.	A	G	13774.9	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=508;CIGAR=1X;DP=524;DPB=524;DPRA=0;EPP=39.1901;EPPR=0;GTI=0;LEN=1;MEANALT=2.5;MQM=60;MQMR=0;NS=2;NUMALT=1;ODDS=255.818;PAIRED=1;PAIREDR=0;PAO=0;PQA=0;PQR=0;PRO=0;QA=15693;QR=0;RO=0;RPL=373;RPP=245.138;RPPR=0;RPR=135;RUN=1;SAF=219;SAP=23.9556;SAR=289;SRF=0;SRP=0;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:154:0:0:150:4661:-419.661,-45.1545,0	1/1:370:0:0:358:11032:-993.047,-107.769,0
chrM	309	.	CT	CCTC,CC	4399.1	.	AB=0.56535,0.285714;ABP=15.2141,134.229;AC=2,2;AF=0.5,0.5;AN=4;AO=186,94;CIGAR=1M2I1X,1M1X;DP=329;DPB=555.5;DPRA=0,0;EPP=23.6043,97.6311;EPPR=31.9633;GTI=0;LEN=3,1;MEANALT=6,6;MQM=60,59.8085;MQMR=60;NS=2;NUMALT=2;ODDS=89.3381;PAIRED=1,1;PAIREDR=1;PAO=13.3333,13.3333;PQA=339,339;PQR=290;PRO=11.3333;QA=4084,2577;QR=686;RO=30;RPL=114,78;RPP=23.6043,91.8097;RPPR=38.0434;RPR=72,16;RUN=1,1;SAF=0,63;SAP=406.904,26.6655;SAR=186,31;SRF=21;SRP=13.4334;SRR=9;TYPE=complex,snp;technology.ILLUMINA=1,1	GT:DP:RO:QR:AO:QA:GL	1/2:93:6:123:59,23:1308,638:-159.543,-53.5005,-52.9104,-105.161,0,-113.176	1/2:236:24:563:127,71:2776,1939:-368.987,-136.961,-169.835,-200.763,0,-245.13
chrM	513	.	GCACACACACAC	GCACACACACACAC	3522.72	.	AB=0.647399;ABP=35.6577;AC=3;AF=0.75;AN=4;AO=156;CIGAR=1M2I11M;DP=231;DPB=321.083;DPRA=0;EPP=75.17;EPPR=5.48477;GTI=1;LEN=2;MEANALT=13.5;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=3.87694;PAIRED=1;PAIREDR=1;PAO=46.5;PQA=1383.5;PQR=1383.5;PRO=46.5;QA=4585;QR=1403;RO=43;RPL=39;RPP=87.6977;RPPR=3.0608;RPR=117;RUN=1;SAF=111;SAP=63.6445;SAR=45;SRF=26;SRP=7.10075;SRR=17;TYPE=ins;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:58:7:225:44:1251:-105.403,0,-13.0389	0/1:173:36:1178:112:3334:-290.141,0,-96.0932
chrM	750	.	A	G	51447.4	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1722;CIGAR=1X;DP=1736;DPB=1736;DPRA=0;EPP=3.03048;EPPR=20.3821;GTI=0;LEN=1;MEANALT=3;MQM=59.8868;MQMR=60;NS=2;NUMALT=1;ODDS=753.623;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=57871;QR=122;RO=8;RPL=720;RPP=103.291;RPPR=12.7819;RPR=1002;RUN=1;SAF=1151;SAP=427.217;SAR=571;SRF=1;SRP=12.7819;SRR=7;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:436:4:53:429:13615:-1220.76,-116.422,0	1/1:1300:4:69:1293:44256:-3977.02,-373.134,0
chrM	1438	.	A	G	79172.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2474;CIGAR=1X;DP=2480;DPB=2480;DPRA=0;EPP=7.56039;EPPR=3.44459;GTI=0;LEN=1;MEANALT=1.5;MQM=59.8319;MQMR=58;NS=2;NUMALT=1;ODDS=1085.01;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=88621;QR=102;RO=5;RPL=1546;RPP=338.232;RPPR=3.44459;RPR=928;RUN=1;SAF=1055;SAP=119.304;SAR=1419;SRF=3;SRP=3.44459;SRR=2;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:551:1:16:550:19482:-1752.13,-161.526,0	1/1:1929:4:86:1924:69139:-6214.93,-560.827,0
chrM	2487	.	A	C	4432.57	.	AB=0.278634;ABP=775.959;AC=1;AF=0.25;AN=4;AO=621;CIGAR=1X;DP=2340;DPB=2340;DPRA=0;EPP=15.1824;EPPR=99.2128;GTI=1;LEN=1;MEANALT=2.5;MQM=59.3285;MQMR=59.9115;NS=2;NUMALT=1;ODDS=63.7254;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=9402;QR=56614;RO=1707;RPL=281;RPP=15.1824;RPPR=127.637;RPR=340;RUN=1;SAF=0;SAP=1351.49;SAR=621;SRF=1352;SRP=1267.49;SRR=355;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:524:405:13274:115:1754:-119.206,0,-1156.18	0/1:1816:1302:43340:506:7648:-607.816,0,-3820.28
chrM	2706	.	A	G	49482.2	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1889;CIGAR=1X;DP=1969;DPB=1969;DPRA=0;EPP=11.3157;EPPR=6.95112;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9645;MQMR=59.5926;NS=2;NUMALT=1;ODDS=759.158;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=55923;QR=722;RO=27;RPL=810;RPP=86.1918;RPPR=5.02092;RPR=1079;RUN=1;SAF=802;SAP=96.3813;SAR=1087;SRF=18;SRP=9.52472;SRR=9;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:408:5:99:391:11529:-1028.82,-99.3894,0	1/1:1561:22:623:1498:44394:-3939.48,-352.569,0
chrM	3197	.	T	C	135699	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=4208;CIGAR=1X;DP=4241;DPB=4241;DPRA=0;EPP=168.325;EPPR=3.13803;GTI=0;LEN=1;MEANALT=3;MQM=59.9943;MQMR=60;NS=2;NUMALT=1;ODDS=2145.76;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=152221;QR=558;RO=17;RPL=2378;RPP=157.977;RPPR=6.20364;RPR=1830;RUN=1;SAF=1641;SAP=445.497;SAR=2567;SRF=8;SRP=3.13803;SRR=9;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:1499:6:179:1486:53236:-4775.26,-416.785,0	1/1:2742:11:379:2722:98985:-8874.65,-758.304,0
chrM	3243	.	A	G	46067	.	AB=0.612338;ABP=290.859;AC=2;AF=0.5;AN=4;AO=1608;CIGAR=1X;DP=2626;DPB=2626;DPRA=0;EPP=31.0126;EPPR=64.3549;GTI=0;LEN=1;MEANALT=2;MQM=59.9627;MQMR=59.815;NS=2;NUMALT=1;ODDS=1288.98;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=53165;QR=35336;RO=1011;RPL=974;RPP=159.119;RPPR=763.402;RPR=634;RUN=1;SAF=558;SAP=329.898;SAR=1050;SRF=383;SRP=131.935;SRR=628;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:1068:221:7574:841:27395:-2380.4,0,-596.524	0/1:1558:790:27762:767:25770:-2317.69,0,-2496.98
chrM	3483	.	G	C	685.467	.	AB=0.254386;ABP=182.214;AC=1;AF=0.25;AN=4;AO=127;CIGAR=1X;DP=550;DPB=550;DPRA=0;EPP=37.6342;EPPR=22.2028;GTI=1;LEN=1;MEANALT=1.5;MQM=59.4646;MQMR=59.8504;NS=2;NUMALT=1;ODDS=25.0865;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2032;QR=13200;RO=421;RPL=87;RPP=40.7802;RPPR=245.89;RPR=40;RUN=1;SAF=1;SAP=270.17;SAR=126;SRF=321;SRP=254.927;SRR=100;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:208:166:5264:40:608:-35.5966,0,-454.8	0/1:342:255:7936:87:1424:-108.297,0,-694.524
chrM	3488	.	T	A	682.097	.	AB=0.264706;ABP=166.509;AC=1;AF=0.25;AN=4;AO=130;CIGAR=1X;DP=546;DPB=546;DPRA=0;EPP=44.7694;EPPR=34.7681;GTI=1;LEN=1;MEANALT=1;MQM=59.4231;MQMR=59.7139;NS=2;NUMALT=1;ODDS=17.5994;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2069;QR=13578;RO=416;RPL=90;RPP=44.7694;RPPR=211.806;RPR=40;RUN=1;SAF=0;SAP=285.302;SAR=130;SRF=315;SRP=242.06;SRR=101;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:206:166:5535:40:650:-39.5324,0,-479.353	0/1:340:250:8043:90:1419:-109.544,0,-705.868
chrM	3511	.	A	C	434.289	.	AB=0.260394;ABP=230.901;AC=1;AF=0.25;AN=4;AO=185;CIGAR=1X;DP=752;DPB=752;DPRA=0;EPP=322.569;EPPR=29.1769;GTI=1;LEN=1;MEANALT=3;MQM=59.7838;MQMR=59.7348;NS=2;NUMALT=1;ODDS=57.1305;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2698;QR=16673;RO=558;RPL=11;RPP=314.869;RPPR=115.475;RPR=174;RUN=1;SAF=1;SAP=396.094;SAR=184;SRF=292;SRP=5.64097;SRR=266;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:295:226:6735:66:923:-61.5611,0,-584.793	0/1:457:332:9938:119:1775:-135.644,0,-870.462
chrM	4769	.	A	G	54711.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1746;CIGAR=1X;DP=1752;DPB=1752;DPRA=0;EPP=85.7949;EPPR=5.18177;GTI=0;LEN=1;MEANALT=2.5;MQM=51.2801;MQMR=58;NS=2;NUMALT=1;ODDS=911.774;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=61628;QR=15;RO=1;RPL=549;RPP=525.238;RPPR=5.18177;RPR=1197;RUN=1;SAF=1003;SAP=87.0833;SAR=743;SRF=1;SRP=5.18177;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:604:1:15:601:20766:-1867.77,-177.095,0	1/1:1148:0:0:1145:40862:-3677.79,-344.679,0
chrM	5539	.	A	G	11837	.	AB=0.479167;ABP=6.26751;AC=2;AF=0.5;AN=4;AO=414;CIGAR=1X;DP=864;DPB=864;DPRA=0;EPP=192.358;EPPR=179.441;GTI=0;LEN=1;MEANALT=1.5;MQM=54.1957;MQMR=53.5924;NS=2;NUMALT=1;ODDS=622.768;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=14380;QR=15965;RO=449;RPL=85;RPP=315.283;RPPR=358.189;RPR=329;RUN=1;SAF=309;SAP=221.29;SAR=105;SRF=337;SRP=247.845;SRR=112;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:338:249:8721:89:3010:-252.807,0,-766.809	0/1:526:200:7244:325:11370:-1015.56,0,-644.23
chrM	7028	.	C	T	76141.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2473;CIGAR=1X;DP=2499;DPB=2499;DPRA=0;EPP=3.74876;EPPR=34.9902;GTI=0;LEN=1;MEANALT=2.5;MQM=55.905;MQMR=57.6364;NS=2;NUMALT=1;ODDS=1210.59;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=85103;QR=439;RO=22;RPL=1260;RPP=4.94996;RPPR=4.58955;RPR=1213;RUN=1;SAF=1102;SAP=66.5485;SAR=1371;SRF=9;SRP=4.58955;SRR=13;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:827:6:107:820:28371:-2543.94,-224.334,0	1/1:1672:16:332:1653:56732:-5076.14,-434.286,0
chrM	7269	.	G	A	62196.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1937;CIGAR=1X;DP=1947;DPB=1947;DPRA=0;EPP=54.8308;EPPR=5.18177;GTI=0;LEN=1;MEANALT=3;MQM=58.2685;MQMR=60;NS=2;NUMALT=1;ODDS=1033.49;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=69240;QR=16;RO=1;RPL=1011;RPP=11.1099;RPPR=5.18177;RPR=926;RUN=1;SAF=933;SAP=8.66151;SAR=1004;SRF=0;SRP=5.18177;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:704:1:16:698:24364:-2191.49,-206.139,0	1/1:1243:0:0:1239:44876:-4039.06,-372.976,0
chrM	8557	.	G	C	2590.97	.	AB=0.267066;ABP=790.051;AC=2;AF=0.5;AN=4;AO=446;CIGAR=1X;DP=1670;DPB=1670;DPRA=0;EPP=44.2196;EPPR=97.7883;GTI=0;LEN=1;MEANALT=3;MQM=57.6951;MQMR=59.5256;NS=2;NUMALT=1;ODDS=125.064;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=6303;QR=38747;RO=1212;RPL=177;RPP=44.2196;RPPR=385.426;RPR=269;RUN=1;SAF=2;SAP=954.193;SAR=444;SRF=906;SRP=648.002;SRR=306;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:724:538:17225:181:2490:-182.373,0,-1508.7	0/1:946:674:21522:265:3813:-301.57,0,-1895.55
chrM	8860	.	A	G	55525	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1846;CIGAR=1X;DP=1861;DPB=1861;DPRA=0;EPP=5.72052;EPPR=6.91895;GTI=0;LEN=1;MEANALT=3;MQM=47.1728;MQMR=58.6;NS=2;NUMALT=1;ODDS=1039.99;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=61929;QR=160;RO=5;RPL=984;RPP=20.5185;RPPR=6.91895;RPR=862;RUN=1;SAF=987;SAP=22.283;SAR=859;SRF=2;SRP=3.44459;SRR=3;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:729:0:0:726:24114:-2170.46,-218.548,0	1/1:1132:5:160:1120:37815:-3389.07,-311.012,0
chrM	9477	.	G	A	34109.5	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1099;CIGAR=1X;DP=1104;DPB=1104;DPRA=0;EPP=9.42988;EPPR=3.0103;GTI=0;LEN=1;MEANALT=2;MQM=59.3794;MQMR=60;NS=2;NUMALT=1;ODDS=565.855;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=38032;QR=67;RO=2;RPL=598;RPP=21.6012;RPPR=7.35324;RPR=501;RUN=1;SAF=542;SAP=3.45487;SAR=557;SRF=1;SRP=3.0103;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:401:2:67:398:13308:-1191.76,-109.337,0	1/1:703:0:0:701:24724:-2225.39,-211.022,0
chrM	9548	.	G	A	26846.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=942;CIGAR=1X;DP=970;DPB=970;DPRA=0;EPP=3.04718;EPPR=3.73412;GTI=0;LEN=1;MEANALT=3;MQM=59.6921;MQMR=60;NS=2;NUMALT=1;ODDS=502.835;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=29956;QR=66;RO=3;RPL=524;RPP=28.9112;RPPR=3.73412;RPR=418;RUN=1;SAF=487;SAP=5.3708;SAR=455;SRF=3;SRP=9.52472;SRR=0;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:364:1:38:350:10822:-970.712,-99.6786,0	1/1:606:2:28:592:19134:-1719.73,-171.045,0
chrM	11467	.	A	G	164822	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=5200;CIGAR=1X;DP=5225;DPB=5225;DPRA=0;EPP=350.339;EPPR=4.78696;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9342;MQMR=53.6364;NS=2;NUMALT=1;ODDS=2859.91;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=187277;QR=283;RO=11;RPL=3887;RPP=2769.75;RPPR=3.20771;RPR=1313;RUN=1;SAF=2257;SAP=199.527;SAR=2943;SRF=6;SRP=3.20771;SRR=5;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:2016:2:46:2008:71984:-6474.61,-594.606,0	1/1:3209:9:237:3192:115293:-10355.2,-916.222,0
chrM	11719	.	G	A	95624.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=3302;CIGAR=1X;DP=3356;DPB=3356;DPRA=0;EPP=179.466;EPPR=18.4661;GTI=0;LEN=1;MEANALT=2;MQM=59.5924;MQMR=58.2353;NS=2;NUMALT=1;ODDS=1506.69;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=106982;QR=483;RO=17;RPL=1766;RPP=37.7986;RPPR=6.20364;RPR=1536;RUN=1;SAF=1728;SAP=18.6065;SAR=1574;SRF=3;SRP=18.4661;SRR=14;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:911:4:122:891:28560:-2559.58,-247.982,0	1/1:2445:13:361:2411:78422:-7025.63,-662.959,0
chrM	12308	.	A	G	67204.7	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2144;CIGAR=1X;DP=2161;DPB=2161;DPRA=0;EPP=8.55647;EPPR=3.87889;GTI=0;LEN=1;MEANALT=2;MQM=59.9664;MQMR=59.7;NS=2;NUMALT=1;ODDS=949.477;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=75192;QR=257;RO=10;RPL=1284;RPP=185.09;RPPR=3.87889;RPR=860;RUN=1;SAF=1005;SAP=21.1964;SAR=1139;SRF=4;SRP=3.87889;SRR=6;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:635:7:216:628:21603:-1924.87,-155.503,0	1/1:1526:3:41:1516:53589:-4819.52,-444.815,0
chrM	12372	.	G	A	62064	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1984;CIGAR=1X;DP=1992;DPB=1992;DPRA=0;EPP=10.3697;EPPR=4.45795;GTI=0;LEN=1;MEANALT=2;MQM=59.9919;MQMR=60;NS=2;NUMALT=1;ODDS=933.299;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=69281;QR=192;RO=6;RPL=861;RPP=78.1406;RPPR=4.45795;RPR=1123;RUN=1;SAF=1010;SAP=4.42876;SAR=974;SRF=4;SRP=4.45795;SRR=2;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:634:5:155:628:21590:-1929.21,-164.556,0	1/1:1358:1:37:1356:47691:-4288.95,-401.925,0
chrM	13617	.	T	C	28593.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=901;CIGAR=1X;DP=906;DPB=906;DPRA=0;EPP=251.346;EPPR=3.73412;GTI=0;LEN=1;MEANALT=2;MQM=59.9034;MQMR=60;NS=2;NUMALT=1;ODDS=462.343;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=32868;QR=92;RO=3;RPL=674;RPP=484.564;RPPR=9.52472;RPR=227;RUN=1;SAF=339;SAP=122.861;SAR=562;SRF=2;SRP=3.73412;SRR=1;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:303:1:14:301:10938:-983.358,-87.1961,0	1/1:603:2:78:600:21930:-1966.72,-168.809,0
chrM	14766	.	C	T	60668.6	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2022;CIGAR=1X;DP=2039;DPB=2039;DPRA=0;EPP=13.3243;EPPR=19.0002;GTI=0;LEN=1;MEANALT=2.5;MQM=59.9782;MQMR=60;NS=2;NUMALT=1;ODDS=954.02;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=67719;QR=140;RO=11;RPL=989;RPP=5.08941;RPPR=12.6832;RPR=1033;RUN=1;SAF=1199;SAP=154.837;SAR=823;SRF=1;SRP=19.0002;SRR=10;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:637:6:78:628:20191:-1810.35,-169.906,0	1/1:1402:5:62:1394:47528:-4272.15,-401.924,0
chrM	14793	.	A	G	58080	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=1967;CIGAR=1X;DP=1998;DPB=1998;DPRA=0;EPP=8.57532;EPPR=5.80219;GTI=0;LEN=1;MEANALT=3;MQM=59.9736;MQMR=59.2857;NS=2;NUMALT=1;ODDS=930.516;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=64876;QR=104;RO=7;RPL=1133;RPP=101.705;RPPR=3.32051;RPR=834;RUN=1;SAF=1124;SAP=90.1794;SAR=843;SRF=1;SRP=10.7656;SRR=6;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:600:4:62:589:19341:-1735.29,-163.219,0	1/1:1398:3:42:1378:45535:-4094.54,-403.304,0
chrM	15301	.	G	A	76440.4	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2590;CIGAR=1X;DP=2644;DPB=2644;DPRA=0;EPP=3.76487;EPPR=7.94546;GTI=0;LEN=1;MEANALT=3;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=1170.15;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=85385;QR=292;RO=11;RPL=1134;RPP=89.9396;RPPR=4.78696;RPR=1456;RUN=1;SAF=1194;SAP=37.2206;SAR=1396;SRF=3;SRP=7.94546;SRR=8;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:726:5:116:709:23434:-2098.78,-192.286,0	1/1:1918:6:176:1881:61951:-5559.91,-535.386,0
chrM	15326	.	A	G	79542.1	.	AB=0;ABP=0;AC=4;AF=1;AN=4;AO=2574;CIGAR=1X;DP=2586;DPB=2586;DPRA=0;EPP=3.76956;EPPR=5.18177;GTI=0;LEN=1;MEANALT=3;MQM=60;MQMR=60;NS=2;NUMALT=1;ODDS=1207.35;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=88636;QR=86;RO=4;RPL=1116;RPP=101.683;RPPR=5.18177;RPR=1458;RUN=1;SAF=1198;SAP=29.7395;SAR=1376;SRF=0;SRP=11.6962;SRR=4;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	1/1:715:2:50:710:24322:-2184.63,-204.389,0	1/1:1871:2:36:1864:64314:-5785.22,-552.228,0

&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;filtering-vcf-data&#34;&gt;Filtering VCF data&lt;/h2&gt;

&lt;p&gt;Even though we selected somewhat stringent input parameters (restricting base quality to a minimum of 30 and mapping quality to a minimum of 20) there is still a lot of just in our data. &lt;a href=&#34;https://github.com/ekg&#34;&gt;Erik Garrison&lt;/a&gt; has a beautiful illustration of various biases potentially affecting called variants (and making a locus sequence-able):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_biases.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here you can see that in an ideal case (indicated with a green star) a variant is evenly represent by different areas of sequencing reads (cycle and placement biases) and is balanced across the two strands (strand bias). Allele imbalance is not applicable in our case as it reflects significant deviation from the diploid (&lt;sup&gt;50&lt;/sup&gt;&amp;frasl;&lt;sub&gt;50&lt;/sub&gt;) expectation (see &lt;a href=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/freebayes.pdf&#34;&gt;here&lt;/a&gt; for more details).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;A robust tool set for processing VCF data is provided by &lt;a href=&#34;https://github.com/vcflib/vcflib&#34;&gt;vcflib&lt;/a&gt; developed by Erik Garrison, the author of FreeBayes. One way to filter VCF is using &lt;code&gt;INFO&lt;/code&gt; fields of the VCF dataset. If you look at the VCF dataset shown above you will see all comment lines beginning with &lt;code&gt;##INFO&lt;/code&gt;.  These are &lt;code&gt;INFO&lt;/code&gt; fields. Each VCF record contains a list of &lt;code&gt;INFO&lt;/code&gt; tags describing a wide range of properties for each VCF record. You will see that FreeBayes and NVC differ significantly in the number and types of &lt;code&gt;INFO&lt;/code&gt; fields each of these caller generates. This why the two require different filtering strategies.&lt;/p&gt;

&lt;p&gt;Among numerous types of data generated by FreeBayes let&amp;rsquo;s consider the following variant properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=DP,Number=1,Type=Integer,Description=&amp;quot;Total read depth at the locus&amp;quot;&amp;gt;&lt;/code&gt; This is simply the number of reads covering a given site.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=SRP,Number=1,Type=Float,Description=&amp;quot;Strand balance probability for the reference allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SRF and SRR given E(SRF/SRR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this quantity the better the site as it diminishes the chances of the sites having significant strand bias.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=SAP,Number=A,Type=Float,Description=&amp;quot;Strand balance probability for the alternate allele: Phred-scaled upper-bounds estimate of the probability of observing the deviation between SAF and SAR given E(SAF/SAR) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this quantity the better the site as it diminishes the chances of the sites having significant strand bias  (also see &lt;a href=&#34;https://groups.google.com/forum/#!topic/freebayes/fX4TOAqXJrA&#34;&gt;here&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;&lt;code&gt;##INFO=&amp;lt;ID=EPP,Number=A,Type=Float,Description=&amp;quot;End Placement Probability: Phred-scaled upper-bounds estimate of the probability of observing the deviation between EL and ER given E(EL/ER) ~ 0.5, derived using Hoeffding&#39;s inequality&amp;quot;&amp;gt;&lt;/code&gt; The higher this number the lower the chance of having significant placement bias.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;QUAL&lt;/code&gt; - phred scaled variant quality.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To perform filtering we will use &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;VCFfilter&lt;/strong&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcffilter.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Filtering FreeBayes VCF for strand bias (&lt;code&gt;SPR&lt;/code&gt; and &lt;code&gt;SAP&lt;/code&gt;), placement bias (&lt;code&gt;EPP&lt;/code&gt;), variant quality (&lt;code&gt;QUAL&lt;/code&gt;), and depth of coverage (&lt;code&gt;DP&lt;/code&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The resulting VCF only contains five variants (most comments fields are omitted here):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	raw_child-ds-	raw_mother-ds-
chrM	3243	.	A	G	46067	.	AB=0.612338;ABP=290.859;AC=2;AF=0.5;AN=4;AO=1608;CIGAR=1X;DP=2626;DPB=2626;DPRA=0;EPP=31.0126;EPPR=64.3549;GTI=0;LEN=1;MEANALT=2;MQM=59.9627;MQMR=59.815;NS=2;NUMALT=1;ODDS=1288.98;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=53165;QR=35336;RO=1011;RPL=974;RPP=159.119;RPPR=763.402;RPR=634;RUN=1;SAF=558;SAP=329.898;SAR=1050;SRF=383;SRP=131.935;SRR=628;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:1068:221:7574:841:27395:-2380.4,0,-596.524	0/1:1558:790:27762:767:25770:-2317.69,0,-2496.98
chrM	3483	.	G	C	685.467	.	AB=0.254386;ABP=182.214;AC=1;AF=0.25;AN=4;AO=127;CIGAR=1X;DP=550;DPB=550;DPRA=0;EPP=37.6342;EPPR=22.2028;GTI=1;LEN=1;MEANALT=1.5;MQM=59.4646;MQMR=59.8504;NS=2;NUMALT=1;ODDS=25.0865;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2032;QR=13200;RO=421;RPL=87;RPP=40.7802;RPPR=245.89;RPR=40;RUN=1;SAF=1;SAP=270.17;SAR=126;SRF=321;SRP=254.927;SRR=100;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:208:166:5264:40:608:-35.5966,0,-454.8	0/1:342:255:7936:87:1424:-108.297,0,-694.524
chrM	3488	.	T	A	682.097	.	AB=0.264706;ABP=166.509;AC=1;AF=0.25;AN=4;AO=130;CIGAR=1X;DP=546;DPB=546;DPRA=0;EPP=44.7694;EPPR=34.7681;GTI=1;LEN=1;MEANALT=1;MQM=59.4231;MQMR=59.7139;NS=2;NUMALT=1;ODDS=17.5994;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=2069;QR=13578;RO=416;RPL=90;RPP=44.7694;RPPR=211.806;RPR=40;RUN=1;SAF=0;SAP=285.302;SAR=130;SRF=315;SRP=242.06;SRR=101;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/0:206:166:5535:40:650:-39.5324,0,-479.353	0/1:340:250:8043:90:1419:-109.544,0,-705.868
chrM	5539	.	A	G	11837	.	AB=0.479167;ABP=6.26751;AC=2;AF=0.5;AN=4;AO=414;CIGAR=1X;DP=864;DPB=864;DPRA=0;EPP=192.358;EPPR=179.441;GTI=0;LEN=1;MEANALT=1.5;MQM=54.1957;MQMR=53.5924;NS=2;NUMALT=1;ODDS=622.768;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=14380;QR=15965;RO=449;RPL=85;RPP=315.283;RPPR=358.189;RPR=329;RUN=1;SAF=309;SAP=221.29;SAR=105;SRF=337;SRP=247.845;SRR=112;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:338:249:8721:89:3010:-252.807,0,-766.809	0/1:526:200:7244:325:11370:-1015.56,0,-644.23
chrM	8557	.	G	C	2590.97	.	AB=0.267066;ABP=790.051;AC=2;AF=0.5;AN=4;AO=446;CIGAR=1X;DP=1670;DPB=1670;DPRA=0;EPP=44.2196;EPPR=97.7883;GTI=0;LEN=1;MEANALT=3;MQM=57.6951;MQMR=59.5256;NS=2;NUMALT=1;ODDS=125.064;PAIRED=1;PAIREDR=1;PAO=0;PQA=0;PQR=0;PRO=0;QA=6303;QR=38747;RO=1212;RPL=177;RPP=44.2196;RPPR=385.426;RPR=269;RUN=1;SAF=2;SAP=954.193;SAR=444;SRF=906;SRP=648.002;SRR=306;TYPE=snp;technology.ILLUMINA=1	GT:DP:RO:QR:AO:QA:GL	0/1:724:538:17225:181:2490:-182.373,0,-1508.7	0/1:946:674:21522:265:3813:-301.57,0,-1895.55
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;looking-at-the-data&#34;&gt;Looking at the data&lt;/h2&gt;

&lt;p&gt;For visalizaning VCFs Galaxy relies on the two external tools.  The first is called &lt;a href=&#34;http://vcf.iobio.io/&#34;&gt;VCF.IOBIO&lt;/a&gt; and is developed by &lt;a href=&#34;http://marthlab.org/&#34;&gt;Gabor Marth&amp;rsquo;s group&lt;/a&gt; at the University of Utah. The second is called &lt;a href=&#34;http://software.broadinstitute.org/software/igv/&#34;&gt;IGV&lt;/a&gt; developed by Broad Institute.&lt;/p&gt;

&lt;h3 id=&#34;vcf-iobio&#34;&gt;VCF.IOBIO&lt;/h3&gt;

&lt;p&gt;VCF.IOBIO can be invoked by expanding a VCF dataset in Galaxy&amp;rsquo;s history by clicking on it:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_collapsed.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking on the dataset above will expand it as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_expanded.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At the bottom there is a link &amp;ldquo;display at vcf.iobio&amp;rdquo;
Clicking on this link will start indexing of VCF datasets, which is required to display them. After indexing VCF.IOBIO will open:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcfiobio.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Of course there are not that many variants to look at in this example. Nevertheless there are helpful statistics such as Transition/Transversion (Ts/Tn) ratio.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;igv&#34;&gt;IGV&lt;/h3&gt;

&lt;p&gt;Similarly to VCF.BIOIO expanding a history item representing a VCF dataset will reveal an IGV link:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcf_dataset_expanded.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;At the bottom there is a link &amp;ldquo;display at IGV: local Human hg38&amp;rdquo;
The difference between &amp;ldquo;local&amp;rdquo; and &amp;ldquo;Human hg38&amp;rdquo; links is explained in the following video:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123414437&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Visualizing our FreeBayes dataset will produce this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_igv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here we focus on one particular variant at position 3,243 for reasons that will become apparent in the next section.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&#34;digging-into-the-data&#34;&gt;Digging into the data&lt;/h2&gt;

&lt;p&gt;Visualizing VCF dataset may be a good way to get an overall idea of the data, but it does not tell a lot of details. For example, above we have visualized site 3,243 using IGV. It is interesting but we need to find out more. One thing we can do is to convert VCF dataset into a tab-delimited representation and play a bit more with it.&lt;/p&gt;

&lt;p&gt;Using &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;VCFtoTab-delimited&lt;/strong&gt; on the filtered VCF dataset:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_vcfToTab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Make sure &lt;strong&gt;Report data per sample&lt;/strong&gt; is set to &lt;code&gt;Yes&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will produce a dataset with &lt;em&gt;very&lt;/em&gt; many columns:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_tab.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;There are 53 columns in this dataset (not all are shown here).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The columns in this dataset represent INFO and Genotype fields on the original VCF dataset. Let&amp;rsquo;s restrict ourselves to just a few:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2 &lt;code&gt;POS&lt;/code&gt; - position along mitochondrial genome&lt;/li&gt;
&lt;li&gt;4 &lt;code&gt;REF&lt;/code&gt; - reference allele&lt;/li&gt;
&lt;li&gt;5 &lt;code&gt;ALT&lt;/code&gt; - alternative allele&lt;/li&gt;
&lt;li&gt;50 &lt;code&gt;SAMPLE&lt;/code&gt; - name of the sample&lt;/li&gt;
&lt;li&gt;51 &lt;code&gt;AO&lt;/code&gt; - number of alternative observations (how many times do we see the alternative allele at this position in this sample)&lt;/li&gt;
&lt;li&gt;52 &lt;code&gt;DP&lt;/code&gt; - depth of coverage at this site for this sample&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To cut these columns out we will use &lt;strong&gt;Text Manipulation&lt;/strong&gt; &amp;#8594; &lt;strong&gt;Cut&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/mt_cut.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that column names are pre-ceded with &lt;code&gt;c&lt;/code&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This will generate the following dataset:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;POS  REF ALT     SAMPLE       AO    DP
--------------------------------------
3243  A   G   raw_child-ds-  841  1068
3243  A   G   raw_mother-ds- 767  1558
3483  G   C   raw_child-ds-   40   208
3483  G   C   raw_mother-ds-  87   342
3488  T   A   raw_child-ds-   40   206
3488  T   A   raw_mother-ds-  90   340
5539  A   G   raw_child-ds-   89   338
5539  A   G   raw_mother-ds- 325   526
8557  G   C   raw_child-ds-  181   724
8557  G   C   raw_mother-ds- 265   946

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s look at site 4,243. At this site Mother has 841 &lt;code&gt;G&lt;/code&gt;s (since &lt;code&gt;G&lt;/code&gt; is an alternative allele) and 1,068-841=227 &lt;code&gt;A&lt;/code&gt;s. This child has 767 &lt;code&gt;G&lt;/code&gt;s and 1,558-767=791 &lt;code&gt;A&lt;/code&gt;s:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Allele     A     G
-------------------
Mother   227   841
Child    791   767
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Thus the &lt;em&gt;major&lt;/em&gt; allele in mother (&lt;code&gt;G&lt;/code&gt;) becomes the &lt;em&gt;minor&lt;/em&gt; allele in child &amp;ndash; a remarkable frequency change due to mitochondrial bottleneck!&lt;/p&gt;

&lt;h1 id=&#34;take-a-look-at-the-whole-thing&#34;&gt;Take a look at the whole thing&lt;/h1&gt;

&lt;p&gt;This entire analysis is available as a &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/non-diploid-freebayes&#34;&gt;Galaxy history&lt;/a&gt; that you can import into your Galaxy account and play with.&lt;/p&gt;

&lt;p&gt;Now you know how to call variants in non-diploid system, so try it on bacteria, viruses etc&amp;hellip;&lt;/p&gt;

&lt;h1 id=&#34;exercise&#34;&gt;Exercise&lt;/h1&gt;

&lt;p&gt;Suppose you obtained a virus from some source and you would like to see how it is different from its published reference sequence. You have sequenced the virus and obtained two Illumina files (these files are large, so don&amp;rsquo;t open them. Rather copy their addresses (right click) and use them to upload into Galaxy as explained in &lt;em&gt;Hints&lt;/em&gt; section below):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/f.fq.gz&#34;&gt;Forward reads&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/r.fq.gz&#34;&gt;Reverse reads&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Analyze these files using Galaxy as was explained in this lesson by mapping them against &lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/bmmb554/hw4/phix.fa&#34;&gt;this reference genome&lt;/a&gt; (again right click to copy the address); see &lt;em&gt;Hints&lt;/em&gt;).&lt;/p&gt;

&lt;p&gt;Use &lt;a href=&#34;https://goo.gl/forms/744Z7LovztR36kj22&#34;&gt;this form&lt;/a&gt; to submit your answer. In your answer describe the site(s) you have found.&lt;/p&gt;

&lt;h4 id=&#34;hints&#34;&gt;Hints&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;You need to upload reads and the reference genome into Galaxy (&lt;a href=&#34;http://usegalaxy.org&#34;&gt;http://usegalaxy.org&lt;/a&gt;) as shown in &lt;a href=&#34;https://vimeo.com/120973708&#34;&gt;this video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;You will be mapping reads against an uploaded reference genome as shown in &lt;a href=&#34;https://vimeo.com/123108417&#34;&gt;this video&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Diploid variant calling</title>
      <link>http://nekrut.github.io/BMMB554/post/topic8/</link>
      <pubDate>Wed, 26 Oct 2016 11:42:45 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic8/</guid>
      <description>

&lt;p&gt;Today we hear a lot about personalized medicine. Yet the &lt;em&gt;personalization&lt;/em&gt; is defined by the genetic make up of the individual. Today we will discuss how this information can be uncovered from the genomic sequencing data. The figure above shows distribution of rare and common variants in 1,092 human genomes described by the &lt;a href=&#34;http://www.nature.com/nature/journal/v491/n7422/abs/nature11632.html&#34;&gt;1000 Genome Consortium&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&#34;calling-variants&#34;&gt;Calling variants&lt;/h1&gt;

&lt;p&gt;Variant calling is a complex field that was significantly propelled by advances in DNA sequencing and efforts of large scientific consortia such as the &lt;a href=&#34;http://www.1000genomes.org&#34;&gt;1000 Genomes&lt;/a&gt;. Here we summarize basic ideas central to Genotype and Variant calling. First, let&amp;rsquo;s contrast the two things although they often go together:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Variant calling&lt;/strong&gt; - identification of positions where the sequenced sample is different from the reference sequence (or &lt;a href=&#34;https://github.com/vgteam/vg&#34;&gt;reference genome graph&lt;/a&gt;);&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Genotype calling&lt;/strong&gt; - identifying individual&amp;rsquo;s genotype at variable sites.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A typical workflow for variation discovery involves the following steps (e.g., see Nielsen et al. &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;2011&lt;/a&gt;):&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Mapping reads against the reference genome&lt;/li&gt;
&lt;li&gt;Thresholding BAM datasets by, for example, retaining paired, properly mapped reads&lt;/li&gt;
&lt;li&gt;Performing quality score recalibration&lt;/li&gt;
&lt;li&gt;Performing realignment&lt;/li&gt;
&lt;li&gt;Performing variant calling/genotype assignment&lt;/li&gt;
&lt;li&gt;Performing filtering and genotype quality score recalibration&lt;/li&gt;
&lt;li&gt;Annotating variants and performing downstream analyses&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;However, continuing evolution of variant detection methods has made some of these steps obsolete. For instance, omitting quality score recalibration and re-alignment (steps 3 and 4 above) when using haplotype-aware variant callers such as &lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;FreeBayes&lt;/a&gt; does not have an effect on the resulting calls (see Brad Chapman&amp;rsquo;s methodological comparisons at &lt;a href=&#34;http://bit.ly/1S9kFJN&#34;&gt;bcbio&lt;/a&gt;). Before going forward with an actual genotype calling in Galaxy let&amp;rsquo;s take a look as some basic ideas behind modern variant callers.&lt;/p&gt;

&lt;h3 id=&#34;how-does-snp-calling-and-genotyping-work&#34;&gt;How does SNP calling and genotyping work?&lt;/h3&gt;

&lt;p&gt;Consider a set of sequencing reads derived from a diploid individual:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;REFERENCE: atcatgacggcaGtagcatat
--------------------------------
READ1:     atcatgacggcaGtagcatat
READ2:         tgacggcaGtagcatat
READ3:     atcatgacggcaAtagca
READ4:            cggcaGtagcatat
READ5:     atcatgacggcaGtagc
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The capitalized position contains a G &amp;#8594; A &lt;a href=&#34;https://en.wikipedia.org/wiki/Transition_(genetics)&#34;&gt;transition&lt;/a&gt;. So, in principle this can be a heterozygous site with two alleles &lt;strong&gt;G&lt;/strong&gt; and &lt;strong&gt;A&lt;/strong&gt;. A commonly used naïve procedure would define a site as &lt;em&gt;heterozygous&lt;/em&gt; if there is a non-reference allele with frequency between 20% and 80%. In this case &lt;strong&gt;A&lt;/strong&gt; is present in &lt;sup&gt;1&lt;/sup&gt;&amp;frasl;&lt;sub&gt;5&lt;/sub&gt; or 20% of the cases, so we can say that this is a heterozygous site. Yet it is only represented by a single read and thus is hardly reliable. Here are some of the possibilities that would explain this &lt;em&gt;variant&lt;/em&gt;. It can be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;A true variant&lt;/li&gt;
&lt;li&gt;Experimental artifact: A library preparation error (e.g., PCR-derived)&lt;/li&gt;
&lt;li&gt;Base calling error&lt;/li&gt;
&lt;li&gt;Analysis error: A misalignment (though unlikely in the above example)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The modern variant callers attempt to assign a reliability estimate for each genotype call. This is done using Bayes reasoning (for a great visual explanation see &lt;a href=&#34;https://oscarbonilla.com/2009/05/visualizing-bayes-theorem/&#34;&gt;blog&lt;/a&gt; by Oscar Bonilla). Here we present a SNP-relevant &amp;ldquo;translation&amp;rdquo; on this explanation (with inspiration from &lt;a href=&#34;https://github.com/ekg&#34;&gt;Erik Garrison&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;Suppose in a population you have $A$ individuals (not to be confused with nucleotide &lt;strong&gt;A&lt;/strong&gt;; in this case $A$ is a number of individuals) with a variant. You are performing re-sequencing and observe a variant in $B$ (again, a number) of your sequencing reads. We want to estimate the probability of having the real polymorphism in th epopulation given our observations in sequencing reads. The logic is as follows:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The probability of having polymorphism &lt;strong&gt;A&lt;/strong&gt; in the population is $P(A) = |A|/|U|$&lt;/li&gt;
&lt;li&gt;The probability of seeing a variant given our identification approach (i.e., sequencing) is $P(B) = |B|/|U|$&lt;/li&gt;
&lt;li&gt;Now, the probability of having a variant and it being observed in our sequencing data is the overlap between $A$ and $B$ sets $P(AB) = |AB|/|U|$. This is presented graphically below:&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pA.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pB.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pAB.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;$P(A)$ Polymorphisms&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$P(B)$ &lt;br&gt; Variant calls&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;$P(AB)$ Polymorphisms + Varinat calls&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now we can ask the following question: &lt;em&gt;What is the probability of a having a real polymorphism&lt;/em&gt; $A$ &lt;em&gt;given our observation of variants in reads&lt;/em&gt; $B$? In other words &lt;em&gt;what is the probability of&lt;/em&gt; $A$ &lt;em&gt;given&lt;/em&gt; $B$? Or, as stated in the original &lt;a href=&#34;https://oscarbonilla.com/2009/05/visualizing-bayes-theorem/&#34;&gt;blog&lt;/a&gt;: &amp;ldquo;&lt;em&gt;given that we are in region $B$ what is the probability that we are in the region $AB$&lt;/em&gt;?&amp;rdquo;:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$P(A|B) = \frac{|AB|}{|B|}$&lt;/li&gt;
&lt;li&gt;Dividing by $|U|$: $P(A|B) = \frac{\frac{|AB|}{|U|}}{\frac{|B|}{|U|}}$&lt;/li&gt;
&lt;li&gt;Because we know that $P(AB) = \frac{|AB|}{|U|}$ and $P(B) = \frac{|B|}{|U|}$ we can rewrite the equation in the previous bullet point as $P(A|B) = \frac{P(AB)}{P(B)}$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now, let&amp;rsquo;s ask an opposite question. Given a true polymorphism $A$ what are the chances that we do detect it (i.e., find ourselves in $AB$)? It will be:&lt;/p&gt;

&lt;p&gt;[
    P(B|A) = \frac{P(AB)}{P(A)}
]&lt;/p&gt;

&lt;p&gt;So, because we know that $P(A|B) = \frac{P(AB)}{P(B)}$ and we just reasoned that $P(B|A) = \frac{P(AB)}{P(A)}$, we can say that $P(A|B)P(B) = P(B|A)P(A)$ leading us to the &lt;a href=&#34;http://www.math.cornell.edu/~mec/2008-2009/TianyiZheng/Bayes.html&#34;&gt;Bayes formula&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;[
    P(A|B) = \frac{P(B|A)P(A)}{P(B)}
]&lt;/p&gt;

&lt;p&gt;Translating this into &amp;ldquo;genomics terms&amp;rdquo; the probability of having a genotype $G$ given sequencing reads $S$ is: $P(G|S) = \frac{P(S|G)P(G)}{P(S)}$. Because in a given calculation of $P(G|S)$ reads are fixed we can re-write the Bayes formula in the following way:&lt;/p&gt;

&lt;p&gt;$P(G|S) \approx P(S|G)P(G)$&lt;/p&gt;

&lt;p&gt;with $P(S)$ becoming a constant. This leaves us with the need to estimate two things:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;$P(S|G)$, the data likelihood&lt;/li&gt;
&lt;li&gt;$P(G)$, the prior probability for the variant&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;In the simplest case we can estimate these as follows:&lt;/p&gt;

&lt;h3 id=&#34;p-s-g&#34;&gt;$P(S|G)$&lt;/h3&gt;

&lt;p&gt;Suppose $S_i$ is a base in read $i$ corresponding to a genome position with genotype $G$. The probability of seeing $S_i$ given $G$, or $P(S_i|G)$, is given by the quality score of $S_i$ (the quality scores are given by base calling software and reported as &lt;a href=&#34;https://en.wikipedia.org/wiki/Phred_quality_score&#34;&gt;phred scores&lt;/a&gt;). Thus the genotype likelihood $P(S|G)$ is the product of $P(S_i|G)$ over all $i$. In reality however there are many other sources of uncertainty (in addition to base qualities) that are incorporated in the calculation of data likelihoods including NGS technology-related issues, dependency of error rates on substitution type (e.g., transitions versus transversions), sequencing context etc&amp;hellip;&lt;/p&gt;

&lt;h3 id=&#34;p-g-a-single-sample-case&#34;&gt;$P(G)$ - a single sample case&lt;/h3&gt;

&lt;p&gt;One can assign an equal probability to all possible genotypes, or to source this information based on previously obtained knowledge containing in a database, such as &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/SNP/&#34;&gt;dbSNP&lt;/a&gt;. In this case (as exemplified in &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;Nielsen et al. 2011&lt;/a&gt;) we may, for instance, have a site with a &lt;strong&gt;G/T&lt;/strong&gt; polymorphism and genotypes &lt;strong&gt;GG&lt;/strong&gt;, &lt;strong&gt;TT&lt;/strong&gt;, and &lt;strong&gt;GT&lt;/strong&gt; having frequencies of 0.45, 0.45, 0.09, respectively. We will use these values as priors.&lt;/p&gt;

&lt;h3 id=&#34;p-g-a-multi-sample-case&#34;&gt;$P(G)$ - a multi-sample case&lt;/h3&gt;

&lt;p&gt;Genotype calling reliability can be significantly improved when analyzing multiple samples jointly. In this case genotype frequencies can be inferred from allele frequencies using Hardy-Weinberg equilibrium (&lt;a href=&#34;https://en.wikipedia.org/wiki/Hardy%E2%80%93Weinberg_principle&#34;&gt;HWE&lt;/a&gt;). The following example (again from &lt;a href=&#34;http://www.nature.com/nrg/journal/v12/n6/full/nrg2986.html&#34;&gt;Nielsen et al. 2011&lt;/a&gt;) illustrates this idea: suppose you are calling genotypes for a single individual using a combination of multiple samples. There are two genotypes, &lt;strong&gt;AT&lt;/strong&gt; and &lt;strong&gt;AA&lt;/strong&gt;, with equally large genotype likelihoods. If, however, in our collection of multiple samples the frequency of &lt;strong&gt;A&lt;/strong&gt; is 1% ($p = 0.01$; $q = 1 - p = 0.99$), then from the HWE we have:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0.0001&lt;/td&gt;
&lt;td&gt;0.0198&lt;/td&gt;
&lt;td&gt;0.9801&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;AA&lt;/strong&gt; ($p^2$)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;AT&lt;/strong&gt; ($2pq$)&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;TT&lt;/strong&gt; ($q^2$)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;This makes it highly unlikely that &lt;strong&gt;AA&lt;/strong&gt; is a true genotype of this individual.&lt;/p&gt;

&lt;h2 id=&#34;calling-with-freebayes&#34;&gt;Calling with FreeBayes&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;FreeBayes&lt;/a&gt; is an open source variant caller that has been battle-tested by the 1000 Genomes community and is extensively used today (also see &lt;a href=&#34;https://bcbio.wordpress.com/&#34;&gt;bcbio&lt;/a&gt;). It has a number of features that simplify variant discovery workflows. These include (from FreeBayes github page):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Indel realignment is accomplished internally&lt;/strong&gt; using a read-independent method, and issues resulting from discordant alignments are dramatically reducedy through the direct detection of haplotypes;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The need for base quality recalibration is avoided&lt;/strong&gt; through the direct detection of haplotypes. Sequencing platform errors tend to cluster (e.g. at the ends of reads), and generate unique, non-repeating haplotypes at a given locus;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Variant quality recalibration is avoided&lt;/strong&gt; by incorporating a number of metrics, such as read placement bias and allele balance, directly into the Bayesian model;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Ability to incorporate non-diploid cases&lt;/strong&gt; such as pooled datasets or data from polyploid samples.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Freebayes is a &lt;em&gt;haplotype-based&lt;/em&gt; variant caller. This implies that instead of looking at an individual positions within an alignment of reads to the reference genome, it looks at a haplotype window, length of which is dynamically determined (see section 3.2. in &lt;a href=&#34;http://arxiv.org/pdf/1207.3907v2.pdf&#34;&gt;FreeBayes manuscript&lt;/a&gt;):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/freebayes.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looking at a haplotype window makes misalignments tolerable. In this case a low complexity poly(A) stretch is misaligned. As a result looking at individual positions will result in calling multiple spurious varians. In the case of FreeBayes looking at a haplotype identifies two alleles (this is a diploid example) &lt;code&gt;A(7)&lt;/code&gt; and &lt;code&gt;A(6)&lt;/code&gt;, while &lt;code&gt;A(8)&lt;/code&gt; is likely an error. Image by &lt;a href=&#34;https://github.com/ekg/freebayes&#34;&gt;Erik Garrison&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&#34;let-s-try-it&#34;&gt;Let&amp;rsquo;s try it&lt;/h1&gt;

&lt;h2 id=&#34;the-data&#34;&gt;The data&lt;/h2&gt;

&lt;p&gt;In this example we will perform variant calling and annotation using &lt;a href=&#34;http://jimb.stanford.edu/giab/&#34;&gt;genome in the bottle data&lt;/a&gt;. Specifically, we will use Ashkenazim Father-Mother-Son trio data from the Personal Genome Project:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;HG002 - NA24385 - huAA53E0 (son)&lt;/li&gt;
&lt;li&gt;HG003 - NA24149 - hu6E4515 (father)&lt;/li&gt;
&lt;li&gt;HG004 - NA24143 - hu8E87A9 (mother)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Yet for a quick tutorial these datasets are way too big, so we created a downsampled (watered down) dataset. This dataset was produced by mapping the trio reads against the &lt;code&gt;hg19&lt;/code&gt; version of the human genome, merging the resulting bam files together (we use readgroups to label individual reads so they can be traced to each of the original individuals), and restricting alignments to a small portion of chromosome 19 containing the &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/gene?cmd=Retrieve&amp;amp;dopt=Graphics&amp;amp;list_uids=5442&#34;&gt;&lt;em&gt;POLRMT&lt;/em&gt;&lt;/a&gt; gene.&lt;/p&gt;

&lt;p&gt;Here is what to do to load the data:&lt;/p&gt;

&lt;h2 id=&#34;loading-the-data&#34;&gt;Loading the data&lt;/h2&gt;

&lt;p&gt;Go to the &lt;a href=&#34;https://usegalaxy.org/library/list#folders/F9ff2d127cd7ed6bc&#34;&gt;data library&lt;/a&gt; and select both BAM and PED datasets. Then Click &lt;strong&gt;to History&lt;/strong&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/library_import.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Galaxy will ask you if you want to import these data into a new history, which you might want (in the case below I called this history &lt;code&gt;genotyping try&lt;/code&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/history_import.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The datasets will appear in your history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/library_import_complete.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;generating-and-post-processing-freebayes-calls&#34;&gt;Generating and post-processing FreeBayes calls&lt;/h2&gt;

&lt;p&gt;Select &lt;strong&gt;FreeBayes&lt;/strong&gt; from &lt;strong&gt;NGS: Variant Analysis&lt;/strong&gt; section of the tool menu (left pane of Galaxy&amp;rsquo;s interface).&lt;/p&gt;

&lt;h3 id=&#34;running-freebayes&#34;&gt;Running FreeBayes&lt;/h3&gt;

&lt;p&gt;Make sure the top part of the interface looks like shown below. Here we selected &lt;code&gt;GIAB-Ashkenazim-Trio-hg19&lt;/code&gt; as input and set &lt;strong&gt;Using reference genome&lt;/strong&gt; to &lt;code&gt;hg19&lt;/code&gt; and &lt;strong&gt;Choose parameter selection level&lt;/strong&gt; to &lt;code&gt;5&lt;/code&gt;. The interface should look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/FreeBayes_settings.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Scrolling down to &lt;strong&gt;Tweak algorithmic features?&lt;/strong&gt; click &lt;code&gt;Yes&lt;/code&gt; and set &lt;strong&gt;Calculate the marginal probability of genotypes and report as GQ in each sample field in the VCF output&lt;/strong&gt; to &lt;code&gt;Yes&lt;/code&gt;. This would help us evaluating the quality of genotype calls.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/nekrut/galaxy/wiki/images/freebayes_gq.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Depending on how busy Galaxy is this may take a little bit of time (coffee break?). Eventially this will produce a dataset in &lt;a href=&#34;http://www.1000genomes.org/wiki/Analysis/variant-call-format&#34;&gt;VCF&lt;/a&gt; format containing 35 putative variants. Before we can continue we need to post-process this dataset by breaking compound variants into multiple independent variants with &lt;strong&gt;VcfAllelicPrimitives&lt;/strong&gt; tool found within &lt;strong&gt;NGS: VCF Manipulation&lt;/strong&gt; section. This is necessary for ensuring the smooth sailing through downstream analyses:&lt;/p&gt;

&lt;h3 id=&#34;simplifying-variant-representation&#34;&gt;Simplifying variant representation&lt;/h3&gt;

&lt;p&gt;Select FreeBayes output as the input for this tool and make sure &lt;strong&gt;Maintain site and allele-level annotations when decomposing&lt;/strong&gt; and &lt;strong&gt;Maintain genotype-level annotations when decomposing&lt;/strong&gt; are set to &lt;code&gt;Yes&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/vcfallelicprimitives.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VCFAllelicPrimities&lt;/strong&gt; generated a VCF files containing 37 records (the input VCF only contained 35). This is because a multiple nucleotide polymorphism (&lt;code&gt;TAGG|CAGA&lt;/code&gt;) at position 618851 have been converted to two:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Before:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr19 618851 . TAGG CAGA 81.7546
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;After:&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr19 618851 . T C 81.7546
chr19 618854 . G A 81.7546
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;annotating-variants-with-snpeff&#34;&gt;Annotating variants with SnpEff&lt;/h3&gt;

&lt;p&gt;At this point we are ready to begin annotating variants using &lt;a href=&#34;http://snpeff.sourceforge.net/SnpEff.html&#34;&gt;SnpEff&lt;/a&gt;. SnpEff, a project maintained by &lt;a href=&#34;https://www.linkedin.com/in/pablocingolani&#34;&gt;Pablo Cingolani&lt;/a&gt; &amp;ldquo;&lt;em&gt;&amp;hellip;annotates and predicts the effects of variants on genes (such as amino acid changes)&amp;hellip;&lt;/em&gt;&amp;rdquo; and so is critical for functional interpretation of variation data.&lt;/p&gt;

&lt;p&gt;Select the latest version of annotation database matching genome version against which reads were mapped and VCF produced. In this case it is &lt;code&gt;GRCh37.75: hg19&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/snpeff.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;SnpEff will generate two outputs: (1) an annotated VCF file and (2) an HTML report. The report contains a number of useful metrics such as distribution of variants across gene features:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/snpeff_chart.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;or changes to codons:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/snpeff_codons.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;manipulating-variation-data-with-gemini&#34;&gt;Manipulating variation data with GEMINI&lt;/h3&gt;

&lt;p&gt;Now that we have an annotated VCF file it is time to peek inside our variation data. &lt;a href=&#34;http://quinlanlab.org/&#34;&gt;Aaron Quinlan&lt;/a&gt;, creator of &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/index.html&#34;&gt;GEMINI&lt;/a&gt;, calls it &lt;em&gt;Detective work&lt;/em&gt;.&lt;/p&gt;

&lt;h4 id=&#34;loading-data-into-gemini&#34;&gt;Loading data into GEMINI&lt;/h4&gt;

&lt;p&gt;The first step is to convert a VCF file we would like to analyze into a GEMINI database. For this we will use &lt;strong&gt;GEMINI Load&lt;/strong&gt; tool from &lt;strong&gt;NGS: GEMINI&lt;/strong&gt; section. GEMINI takes as input a VCF file and a &lt;a href=&#34;http://pngu.mgh.harvard.edu/~purcell/plink/data.shtml&#34;&gt;PED&lt;/a&gt; file describing the relationship between samples. In the case of our dataset the PED file looks like this (accessible from &lt;a href=&#34;https://usegalaxy.org/library/list#folders/F9ff2d127cd7ed6bc/datasets/418b2500e809568b&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#family_id sample_id            paternal_id          maternal_id         sex phenotype ethnicity
family1    HG004_NA24143_mother -9                   -9                   2  1         CEU
family1	   HG003_NA24149_father -9                   -9                   1  1         CEU
family1	   HG002_NA24385_son	HG003_NA24149_father HG004_NA24143_mother 1  2         CEU
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;So let&amp;rsquo;s load data into GEMINI. Set VCF and PED inputs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/gemini_load.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This creates a sqlite database. To see the content of the database use &lt;strong&gt;GEMINI_db_info&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/gemini_db_info.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This produce a list of &lt;a href=&#34;https://github.com/nekrut/galaxy/wiki/datasets/gemini_tables.txt&#34;&gt;all tables and fields&lt;/a&gt; in the database.&lt;/p&gt;

&lt;h4 id=&#34;querying-gemini-database&#34;&gt;Querying GEMINI database&lt;/h4&gt;

&lt;p&gt;GEMINI database is queried using the versatile SQL language (more on SQL &lt;a href=&#34;http://swcarpentry.github.io/sql-novice-survey&#34;&gt;here&lt;/a&gt;). In Galaxy&amp;rsquo;s version of GEMINI this is done using &lt;strong&gt;GEMINI_query&lt;/strong&gt; tool. Within this tool SQL commands are typed directly into the &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; text box. Let&amp;rsquo;s begin getting information from some of the tables we discovered with &lt;strong&gt;GEMINI_db_info&lt;/strong&gt; tool above.
&amp;gt;
The examples below are taken from &amp;ldquo;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Intro-To-Gemini.pdf&#34;&gt;Intro to Gemini&lt;/a&gt;&amp;rdquo; tutorial. For extensive documentation see &amp;ldquo;&lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/querying.html&#34;&gt;Querying GEMINI&lt;/a&gt;&amp;rdquo;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;are-there-novel-varinats-that-are-not-annotated-in-dbsnp-database&#34;&gt;&lt;em&gt;Are there &amp;ldquo;novel&amp;rdquo; varinats that are not annotated in dbSNP database?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this question we will type the following query:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT count(*) FROM variants WHERE in_dbsnp == 0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; field of the interface:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/gemini_query1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;As we can see from &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b51bb37b9032761321/display/?preview=True&#34;&gt;output (Click this link to see it)&lt;/a&gt; there are 21 variants that are not annotated in dbSNP.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;which-variants-are-fount-within-polrmt-gene&#34;&gt;&lt;em&gt;Which variants are fount within POLRMT gene?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * FROM variants WHERE filter is NULL and gene = &#39;POLRMT&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The above query will produce &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5a0bb5b2cc0695697/display/?preview=True&#34;&gt;output&lt;/a&gt; with very large number of columns. To restrict the number of columns to a manageable set let&amp;rsquo;s use this command (you may need to scroll sideways):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT rs_ids, aaf_esp_ea, impact, clinvar_disease_name, clinvar_sig FROM variants WHERE filter is NULL and gene = &#39;POLRMT&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;(column definitions can be found &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/database_schema.html&#34;&gt;here&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b540d65297cd1d26bb/display/?preview=True&#34;&gt;Output&lt;/a&gt; shows varinats found within the &lt;em&gt;POLRMT&lt;/em&gt; gene.&lt;/p&gt;

&lt;h4 id=&#34;querying-genotypes&#34;&gt;Querying genotypes&lt;/h4&gt;

&lt;p&gt;GEMINI provides access to genotype, sequencing depth, genotype quality, and genotype likelihoods for each individual (&lt;code&gt;subjectID&lt;/code&gt;):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;gt_types.subjectID&lt;/code&gt; - three types of genotype types: &lt;code&gt;HOM_REF&lt;/code&gt;, &lt;code&gt;HET&lt;/code&gt;, &amp;lsquo;HOM_ALT`;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_quals.subjectID&lt;/code&gt; - genotype quality&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_depths.subjectID&lt;/code&gt; - total number of reads in this subject at position&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_ref_depths.subjectID&lt;/code&gt; -  number of reference allele reads in this subject at position&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gt_alt_depths.subjectID&lt;/code&gt; - number of alternate allele reads in this subject at position&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-how-many-sites-does-child-in-our-trio-have-a-non-reference-allele&#34;&gt;&lt;em&gt;At how many sites does child in our trio have a non-reference allele?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this we will use two fields of &lt;strong&gt;GEMINI_query&lt;/strong&gt; interface. In the &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; we will type:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and in the field &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt; we will enter:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/gemini_query2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This produce &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b560921700703d0255/display/?preview=True&#34;&gt;a list of sites&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-how-many-sites-both-father-and-son-have-non-reference-alleles&#34;&gt;&lt;em&gt;At how many sites both father and son have non reference alleles?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;To answer this we will type the same expression&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT * from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; field and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; (gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF AND gt_types.HG003_NA24149_father &amp;lt;&amp;gt; HOM_REF)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This will produce the following &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5aab445b3cd632ba7/display/?preview=True&#34;&gt;output&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;list-genotypes-for-father-and-son-where-they-have-non-reference-alleles&#34;&gt;&lt;em&gt;List genotypes for father and son where they have non-reference alleles.&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;Type the following:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT gts.HG002_NA24385_son, gts.HG003_NA24149_father from variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gt_types.HG002_NA24385_son &amp;lt;&amp;gt; HOM_REF AND gt_types.HG003_NA24149_father &amp;lt;&amp;gt; HOM_REF)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;. Output will look like &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b543c67f80be21ed02/display/?preview=True&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;using-wildcards&#34;&gt;Using wildcards&lt;/h4&gt;

&lt;p&gt;Wilcards simply writing SQL expressions when searching across multiple terms. The syntax for genotype filter wilcards is&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(COLUMN).(SAMPLE_WILDCARD).(SAMPLE_WILDCARD_RULE).(RULE_ENFORCEMENT)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let&amp;rsquo;s try a few examples.&lt;/p&gt;

&lt;blockquote&gt;
&lt;h4 id=&#34;at-which-variants-are-every-sample-heterozygous&#34;&gt;&lt;em&gt;At which variants are every sample heterozygous?&lt;/em&gt;&lt;/h4&gt;
&lt;/blockquote&gt;

&lt;p&gt;Type&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;SELECT chrom, start, end, ref, alt, gene, impact, (gts).(*) FROM variants
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;The query to be issued to the database&lt;/strong&gt; and&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;(gt_types).(*).(==HET).(all)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;into &lt;strong&gt;Restrictions to apply to genotype values&lt;/strong&gt;. Here we use wildcards for the query&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(gts.*)&lt;/code&gt; = get genotypes for &lt;strong&gt;all&lt;/strong&gt; samples&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;and genotype filtering&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;(gt_types).(*).(==HET).(all)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;the &lt;a href=&#34;http://gemini.readthedocs.org/en/latest/content/querying.html#the-all-operator&#34;&gt;all operator&lt;/a&gt; implies that want results for &lt;strong&gt;all&lt;/strong&gt; afftected individuals). Output will look like &lt;a href=&#34;https://usegalaxy.org/datasets/bbd44e69cb8906b5819e1404b5e127d1/display/?preview=True&#34;&gt;this&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;going-further&#34;&gt;Going further&lt;/h3&gt;

&lt;p&gt;This short tutorial should give you an overall idea on how generate variant data in Galaxy and process it with GEMINI. Yet there is much more to learn. Below we list GEMINI tutorials and links to Galaxy libraries with relevant data:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Introduction&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Intro-To-Gemini.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F0283ca691a41c352&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-introduction&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying &lt;em&gt;de novo&lt;/em&gt; mutations underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-DeNovo-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F775008f45cbbf010&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-de-novo-mutations&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying autosomal recessive variants underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-Recessive-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F35b262f5ac8aa63a&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-autosomal-recessive&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Identifying autosomal dominant variants underlying Mendelian disease&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://s3.amazonaws.com/gemini-tutorials/Gemini-Dominant-Tutorial.pdf&#34;&gt; PDF &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/library/list#folders/F1c4722ad56892a31&#34;&gt; Sample Data &lt;/a&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;a href=&#34;https://usegalaxy.org/u/aun1/h/gemini-autosomal-dominant&#34;&gt; Galaxy history &lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;how-to-use-these-tutorials&#34;&gt;How to use these tutorials?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Right click on the &lt;strong&gt;PDF&lt;/strong&gt; link and open tutorial in a new browser tab&lt;/li&gt;
&lt;li&gt;Right click on &lt;strong&gt;Galaxy history&lt;/strong&gt; link and open Galaxy history in another new browser tab&lt;/li&gt;
&lt;li&gt;When Galaxy history interface opens you will need to click &lt;strong&gt;Import history&lt;/strong&gt; link highlighted within a red outline in the following figure:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/nekrut/galaxy/wiki/images/import_history.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If you have a wide screen arrange browsers tabs side by side:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/side-by-side.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Proceed with tutorial. For example, to repeat the following command from GEMINI tutorial:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/gemini_command.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Use Galaxy&amp;rsquo;s &lt;strong&gt;GEMINI_load&lt;/strong&gt; tool:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/galaxy_command.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;and so on&amp;hellip;.&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>NGS data: Practicalities</title>
      <link>http://nekrut.github.io/BMMB554/post/topic7/</link>
      <pubDate>Mon, 10 Oct 2016 11:26:49 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic7/</guid>
      <description>

&lt;p&gt;In this section we will look at practical aspects of manipulation of next-generation sequencing data. We will start with Fastq format produced by most sequencing machines and will finish with SAM/BAM format representing mapped reads. The cover image above shows a screen dump of a SAM dataset.&lt;/p&gt;

&lt;h1 id=&#34;getting-ngs-data-in&#34;&gt;Getting NGS data in&lt;/h1&gt;

&lt;p&gt;You can data in Galaxy using one of five ways:&lt;/p&gt;

&lt;h2 id=&#34;from-your-computer&#34;&gt;From your computer&lt;/h2&gt;

&lt;p&gt;This works well for small files because web browser do not like lengthy file transfers:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120901536&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;using-ftp&#34;&gt;Using FTP&lt;/h2&gt;

&lt;p&gt;FTP (&lt;a href=&#34;https://en.wikipedia.org/wiki/File_Transfer_Protocol&#34;&gt;file transfer protocol&lt;/a&gt;) allows transferring large collection of files:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120972739&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-the-web&#34;&gt;From the Web&lt;/h2&gt;

&lt;p&gt;Upload from the web works when URL (addresses) of data files are known:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120973708&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-ebi-short-read-archive&#34;&gt;From EBI short read archive&lt;/h2&gt;

&lt;p&gt;This is the best way to upload published datasets deposited to EBI SRA. The problem is that not all datasets are available from EBI. Next option (below) explain how to deal with NCBI SRA datasets:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121187220&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;from-ncbi-short-read-archive&#34;&gt;From NCBI short read archive&lt;/h2&gt;

&lt;p&gt;Finally, datasets can be uploaded directly from NCBI&amp;rsquo;s short read archive:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121190377&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-9888-try-it-yourself-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;&amp;#9888; Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Create a new Galaxy history at &lt;a href=&#34;http://usegalaxy.org&#34;&gt;http://usegalaxy.org&lt;/a&gt; (don&amp;rsquo;t forget to log in).&lt;/li&gt;
&lt;li&gt;Import the following two datasets (for help see the above video &amp;ldquo;&lt;em&gt;From the Web&lt;/em&gt;&amp;rdquo;):&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-1.fq.gz&#34;&gt;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-1.fq.gz&lt;/a&gt;
&lt;a href=&#34;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-2.fq.gz&#34;&gt;http://www.bx.psu.edu/~anton/share/ng_test_data/var/raw_mother-ds-2.fq.gz&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;These are paired end data (see below for explanation of what paired-end is) for a single Illumina run.&lt;/p&gt;

&lt;p&gt;Keep Galaxy history for later. We will need it again in a few minutes.&lt;/p&gt;

&lt;h1 id=&#34;fastq-manipulation-and-quality-control&#34;&gt;Fastq manipulation and quality control&lt;/h1&gt;

&lt;h2 id=&#34;what-is-fastq&#34;&gt;What is Fastq?&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;FastQ&lt;/a&gt; is not a very well defined format. In the beginning various manufacturers of sequencing instruments were free to interpret fastq as they saw fit, resulting in a multitude of fastq flavors. This variation stemmed primarily from different ways of encoding quality values as described &lt;a href=&#34;http://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;here&lt;/a&gt; (below you will explanation of quality scores and their meaning). Today, &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/20015970&#34;&gt;fastq Sanger&lt;/a&gt; version of the format is considered to be the standard form of fastq. Galaxy is using fastq sanger as the only legitimate input for downstream processing tools and provides &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/20562416&#34;&gt;a number of utilities for converting fastq files&lt;/a&gt; into this form (see &lt;strong&gt;NGS: QC and manipulation&lt;/strong&gt; section of Galaxy tools).&lt;/p&gt;

&lt;p&gt;Fastq format looks like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;
@M02286:19:000000000-AA549:1:1101:12677:1273 1:N:0:23
CCTACGGGTGGCAGCAGTGAGGAATATTGGTCAATGGACGGAAGTCTGAACCAGCCAAGTAGCGTGCAG
+
ABC8C,:@F:CE8,B-,C,-6-9-C,CE9-CC--C-&amp;lt;-C++,,+;CE&amp;lt;,,CD,CEFC,@E9&amp;lt;FCFCF?9
@M02286:19:000000000-AA549:1:1101:15048:1299 1:N:0:23
CCTACGGGTGGCTGCAGTGAGGAATATTGGACAATGGTCGGAAGACTGATCCAGCCATGCCGCGTGCAG
+
ABC@CC77CFCEG;F9&amp;lt;F89&amp;lt;9--C,CE,--C-6C-,CE:++7:,CF&amp;lt;,CEF,CFGGD8FFCFCFEGCF
@M02286:19:000000000-AA549:1:1101:11116:1322 1:N:0:23
CCTACGGGAGGCAGCAGTAGGGAATCTTCGGCAATGGACGGAAGTCTGACCGAGCAACGCCGCGTGAGT
+
AAC&amp;lt;CCF+@@&amp;gt;CC,C9,F9C9@9-CFFFE@7@:+CC8-C@:7,@EFE,6CF:+8F7EFEEF@EGGGEEE

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Each sequencing read is represented by four lines:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;@ followed by read ID and optional information about sequencing run&lt;/li&gt;
&lt;li&gt;sequenced bases&lt;/li&gt;
&lt;li&gt;+ (optionally followed by the read ID and some additional info)&lt;/li&gt;
&lt;li&gt;quality scores for each base of the sequence encoded as &lt;a href=&#34;https://en.wikipedia.org/wiki/ASCII&#34;&gt;ASCII symbols&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;paired-end-data&#34;&gt;Paired end data&lt;/h2&gt;

&lt;p&gt;It is common to prepare pair-end and mate-pair sequencing libraries. This is highly beneficial for a number of applications discussed in subsequent topics. For now let&amp;rsquo;s just briefly discuss what these are and how they manifest themselves in fastq form.&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pe_mp.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;&lt;strong&gt;Paired-end and mate-pair reads&lt;/strong&gt;. In paired end sequencing (left) the actual ends of rather short DNA molecules (&amp;lt;1kb) are determined, while for mate pair sequencing (right) the ends of long molecules are joined and prepared in special sequencing libraries. In these mate pair protocols, the ends of long, size-selected molecules are connected with an internal adapter sequence (i.e. linker, yellow) in a circularization reaction. The circular molecule is then processed using restriction enzymes or fragmentation. Fragments are enriched for the linker and outer library adapters are added around the two combined molecule ends. The internal adapter can then be used as a second priming site for an additional sequencing reaction in the same orientation or sequencing can be performed from the second adapter, from the reverse strand. (From Ph.D. dissertation by &lt;a href=&#34;https://core.ac.uk/download/pdf/35186947.pdf&#34;&gt;Martin Kircher&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Thus in both cases (paired-end and mate-pair) a single physical piece of DNA (or RNA in the case of RNA-seq) is sequenced from two ends and so generates two reads. These can be represented as separate files (two fastq files with first and second reads) or a single file were reads for each end are interleaved. Here are examples:&lt;/p&gt;

&lt;h4 id=&#34;two-single-files&#34;&gt;Two single files&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;File 1&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; @M02286:19:000000000-AA549:1:1101:12677:1273 1:N:0:23
 CCTACGGGTGGCAGCAGTGAGGAATATTGGTCAATGGACGGAAGTCT
 +
 ABC8C,:@F:CE8,B-,C,-6-9-C,CE9-CC--C-&amp;lt;-C++,,+;CE
 @M02286:19:000000000-AA549:1:1101:15048:1299 1:N:0:23
 CCTACGGGTGGCTGCAGTGAGGAATATTGGACAATGGTCGGAAGACT
 +
 ABC@CC77CFCEG;F9&amp;lt;F89&amp;lt;9--C,CE,--C-6C-,CE:++7:,CF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;strong&gt;File 2&lt;/strong&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@M02286:19:000000000-AA549:1:1101:12677:1273 2:N:0:23
CACTACCCGTGTATCTAATCCTGTTTGATACCCGCACCTTCGAGCTTA
+
--8A,CCE+,,;,&amp;lt;CC,,&amp;lt;CE@,CFD,,C,CFF+@+@CCEF,,,B+C,
@M02286:19:000000000-AA549:1:1101:15048:1299 2:N:0:23
CACTACCGGGGTATCTAATCCTGTTCGCTCCCCACGCTTTCGTCCATC
+
-6AC,EE@::CF7CFF&amp;lt;&amp;lt;FFGGDFFF,@FGGGG?F7FEGGGDEFF&amp;gt;FF
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Note that read ID are &lt;strong&gt;identical&lt;/strong&gt; in two files and they are listed in &lt;strong&gt;the same&lt;/strong&gt; order. In some cases read IDs in the first and second file may be appended with &lt;code&gt;/1&lt;/code&gt; and &lt;code&gt;/2&lt;/code&gt; tags, respectively.&lt;/p&gt;

&lt;h4 id=&#34;interleaved-file&#34;&gt;Interleaved file&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;@1/1
AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA
+
EGGEGGGDFGEEEAEECGDEGGFEEGEFGBEEDDECFEFDD@CDD&amp;lt;ED
@1/2
CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC
+
GHHHDFDFGFGEGFBGEGGEGEGGGHGFGHFHFHHHHHHHEF?EFEFF
@2/1
AGGGATGTGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTAGGGTTA
+
HHHHHHEGFHEEFEEHEEHHGGEGGGGEFGFGGGGHHHHFBEEEEEFG
@2/2
CCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAACCCTAAC
+
HHHHHHHHHHHHHGHHHHHHGHHHHHHHHHHHFHHHFHHHHHHHHHHH
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Here the first and the second reads are identified with &lt;code&gt;/1&lt;/code&gt; and &lt;code&gt;/2&lt;/code&gt; tags.&lt;/p&gt;

&lt;p&gt;&lt;font color=&#34;red&#34;&gt;&amp;#10148;&lt;/font&gt; &lt;strong&gt;Note&lt;/strong&gt;: Fastq format is not strictly defined and its variations will always cause headache for you. See &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/books/NBK242622/&#34;&gt;this page&lt;/a&gt; for more information.&lt;/p&gt;

&lt;h2 id=&#34;what-are-base-qualities&#34;&gt;What are base qualities?&lt;/h2&gt;

&lt;p&gt;As we&amp;rsquo;ve seen above, fastq datasets contain two types of information:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;em&gt;sequence of the read&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;base qualities&lt;/em&gt; for each nucleotide in the read.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The base qualities allow us to judge how trustworthy each base in a sequencing read is. The following excerpt from an excellent &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf&#34;&gt;tutorial&lt;/a&gt; by Friederike D&amp;uuml;ndar, Luce Skrabanek, Paul Zumbo explains what base qualities are:&lt;/p&gt;

&lt;p&gt;Illumina sequencing is based on identifying the individual nucleotides by the fluorescence signal emitted upon their incorporation into the growing sequencing read. Once the fluorescence intensities are extracted and translated into the four letter code. The deduction of nucleotide sequences from the images acquired during sequencing is commonly referred to as base calling. Due to the imperfect nature of the sequencing process and limitations of the optical instruments, base calling will always have inherent uncertainty. This is the reason why FASTQ files store the DNA sequence of each read together with a position-specific quality score that represents the error probability, i.e., how likely it is that an individual base call may be incorrect. The score is called &lt;a href=&#34;http://www.phrap.com/phred/&#34;&gt;Phred score&lt;/a&gt;, $Q$, which is proportional to the probability $p$ that a base call is incorrect, where $Q = −10lg(p)$. For example, a Phred score of 10 corresponds to one error in every ten base calls ($Q = −10lg(0.1)$), or 90% accuracy; a Phred score of 20 corresponds to one error in every 100 base calls, or 99% accuracy. A higher Phred score thus reflects higher confidence in the reported base. To assign each base a unique score identifier (instead of numbers of varying character length), Phred scores are typically represented as ASCII characters. At &lt;a href=&#34;http://ascii-code.com/&#34;&gt;http://ascii-code.com/&lt;/a&gt; you can see which characters are assigned to what number. For raw reads, the range of scores will depend on the sequencing technology and the base caller used (Illumina, for example, used a tool called Bustard, or, more recently, RTA). Unfortunately, Illumina has been anything but consistent in how they a) calculated and b) ASCII-encoded the Phred score (see below)! In addition, Illumina now allows Phred scores for base calls with as high as 45, while 41 used to be the maximum score until the HiSeq X. This may cause issues with downstream sapplications that expect an upper limit of 41.&lt;/p&gt;

&lt;hr /&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/illumina_qs.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Base call quality scores are represented with the Phred range. Different Illumina (formerly Solexa) versions
used different scores and ASCII offsets. Starting with Illumina format 1.8, the score now represents the standard
Sanger/Phred format that is also used by other sequencing platforms and the sequencing archives.&lt;/p&gt;

&lt;hr /&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/fastq_qs.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;The ASCII interpretation and ranges of the different Phred score notations used by Illumina and the original
Sanger interpretation. Although the Sanger format allows a theoretical score of 93, raw sequencing
reads typically do not exceed a Phred score of 60. In fact, most Illumina-based sequencing will result in maximum
scores of 41 to 45 (image from &lt;a href=&#34;https://en.wikipedia.org/wiki/FASTQ_format&#34;&gt;Wikipedia&lt;/a&gt;).&lt;/p&gt;

&lt;h2 id=&#34;assessing-data-quality&#34;&gt;Assessing data quality&lt;/h2&gt;

&lt;p&gt;One of the first steps in the analysis of NGS data is seeing how good the data actually is. &lt;a href=&#34;http://www.bioinformatics.babraham.ac.uk/projects/fastqc/&#34;&gt;FastqQC&lt;/a&gt; is a fantastic tool allowing you to gauge the quality of fastq datasets (and deciding whether to blame or not to blame whoever has done sequencing for you).&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://galaxyproject.org/ngs101/good_fq.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://galaxyproject.org/ngs101/bad_fq.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;A.&lt;/strong&gt; Excellent quality&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;B.&lt;/strong&gt; Hmmm&amp;hellip;OK&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Here you can see FastQC base quality reports (the tools gives you many other types of data) for two datasets: &lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;B&lt;/strong&gt;. The &lt;strong&gt;A&lt;/strong&gt; dataset has long reads (250 bp) and very good quality profile with no qualities dropping below &lt;a href=&#34;http://www.phrap.com/phred/&#34;&gt;phred score&lt;/a&gt; of 30. The &lt;strong&gt;B&lt;/strong&gt; dataset is significantly worse with ends of the reads dipping below phred score of 20. The &lt;strong&gt;B&lt;/strong&gt; reads may need to be trimmed for further processing.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123453134&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;QC datasets you have uploaded before.&lt;/p&gt;

&lt;h2 id=&#34;mapping-your-data&#34;&gt;Mapping your data&lt;/h2&gt;

&lt;p&gt;Mapping of NGS reads against reference sequences is one of the key steps of the analysis. In &lt;a href=&#34;http://nekrut.github.io/BMMB554/post/topic5/&#34;&gt;Topic 5&lt;/a&gt; we covered basic principles behind mapping of sequencing reads against large genomes. Now it is time to see how this is done in practice. Below is a list of key publications highlighting popular mapping tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2009 Bowtie 1 - &lt;a href=&#34;http://genomebiology.com/content/10/3/R25&#34;&gt;Langmead et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 Bowtie 2 - &lt;a href=&#34;http://www.nature.com/nmeth/journal/v9/n4/full/nmeth.1923.htm&#34;&gt;Langmead and Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/14/1754.long&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/5/589&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2013 BWA-MEM - &lt;a href=&#34;http://arxiv.org/abs/1303.3997&#34;&gt;Li&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;mapping-against-a-pre-computed-genome-index&#34;&gt;Mapping against a pre-computed genome index&lt;/h3&gt;

&lt;p&gt;Mappers usually compare reads against a reference sequence that has been transformed into a highly accessible data structure called genome index. Such indexes should be generated before mapping begins. Galaxy instances typically store indexes for a number of publicly available genome builds.&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/cached_genome.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Mapping against a pre-computed index in Galaxy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For example, the image above shows indexes for &lt;code&gt;hg38&lt;/code&gt; version of the human genome. You can see that there are actually three choices: (1) &lt;code&gt;hg38&lt;/code&gt;, (2) &lt;code&gt;hg38 canonical&lt;/code&gt; and (3) &lt;code&gt;hg38 canonical female&lt;/code&gt;. The &lt;code&gt;hg38&lt;/code&gt; contains all chromosomes as well as all unplaced contigs. The &lt;code&gt;hg38 canonical&lt;/code&gt; does not contain unplaced sequences and only consists of chromosomes 1 through 22, X, Y, and mitochondria. The
&lt;code&gt;hg38 canonical female&lt;/code&gt; contains everything from the canonical set with the exception of chromosome Y.&lt;/p&gt;

&lt;p&gt;The following video show mapping using BWA:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123102338&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font-1&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Map datasets uploaded before using BWA against &lt;code&gt;hg38&lt;/code&gt; version of the human genome.&lt;/p&gt;

&lt;h3 id=&#34;what-if-pre-computed-index-does-not-exist&#34;&gt;What if pre-computed index does not exist?&lt;/h3&gt;

&lt;p&gt;If Galaxy does not have a genome you need to map against, you can upload your genome sequence as a FASTA file and use it in the mapper directly as shown below (&lt;strong&gt;Load reference genome&lt;/strong&gt; is set to &lt;code&gt;History&lt;/code&gt;).&lt;/p&gt;

&lt;blockquote&gt;

&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/uploaded_genome.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Mapping against a pre-computed index in Galaxy&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In this case Galaxy will first create an index from this dataset and then run mapping analysis against it. The following video shows how this works in practice:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123108417&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;sam-bam-datasets&#34;&gt;SAM/BAM datasets&lt;/h2&gt;

&lt;p&gt;The &lt;a href=&#34;https://samtools.github.io/hts-specs/SAMv1.pdf&#34;&gt;SAM/BAM&lt;/a&gt; format is an accepted standard for storing aligned reads (it can also store unaligned reads and some mappers such as BWA are accepting unaligned BAM as input). The binary form of the format (BAM) is compact and can be rapidly searched (if indexed). In Galaxy BAM datasets are always indexed (accompanies by a .bai file) and sorted in coordinate order. In the following duscussion I once again rely on &lt;a href=&#34;http://chagall.med.cornell.edu/RNASEQcourse/Intro2RNAseq.pdf&#34;&gt;tutorial&lt;/a&gt; by Friederike D&amp;uuml;ndar, Luce Skrabanek, and Paul Zumbo.&lt;/p&gt;

&lt;p&gt;The output option of STAR already indicates that the results of the alignment will be stored in a SAM or BAM file. The Sequence Alignment/Map (SAM) format is, in fact, a generic nucleotide alignment format that describes the alignment of sequencing reads (or query sequences) to a reference. The human readable, TABdelimited SAM files can be compressed into the Binary Alignment/Map format. These BAM files are bigger than simply gzipped SAM files, because they have been optimized for fast random access rather than size reduction. Position-sorted BAM files can be indexed so that all reads aligning to a locus can be efficiently retrieved without loading the entire file into memory.&lt;/p&gt;

&lt;p&gt;As shown below, SAM files typically contain a short header section and a very long alignment section where each row represents a single read alignment. The following sections will explain the SAM format in a bit more detail. For the most comprehensive and updated information go to &lt;a href=&#34;https://github.com/samtools/hts-specs&#34;&gt;https://github.com/samtools/hts-specs&lt;/a&gt;.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/bam_structure.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Schematic representation of a SAM file. Each line of the optional header section starts with “@”, followed by the appropriate abbreviation (e.g., SQ for sequence dictionary which lists all chromosomes names (SN) and their lengths (LN)). The vast majority of lines within a SAM file typically correspond to read alignments where each read is described by the 11 mandatory entries (black font) and a variable number of optional fields (grey font).&lt;/p&gt;

&lt;h3 id=&#34;sam-header&#34;&gt;SAM Header&lt;/h3&gt;

&lt;p&gt;The header section includes information about how the alignment was generated and stored. All lines in the header section are tab-delimited and begin with the “@” character, followed by tag:value pairs, where tag is a two-letter string that defines the content and the format of value. For example, the “@SQ” line in the header section contains the information about the names and lengths of the *reference sequences to which the reads were aligned. For a hypothetical organism with three chromosomes of length 1,000 bp, the SAM header should contain the following three lines:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;@SQ SN:chr1 LN:1000
@SQ SN:chr2 LN:1000
@SQ SN:chr3 LN:1000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;sam-alignment-section&#34;&gt;SAM alignment section&lt;/h3&gt;

&lt;p&gt;The optional header section is followed by the alignment section where each line corresponds to one sequenced read. For each read, there are 11 mandatory fields that always appear in the same order:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;QNAME&amp;gt; &amp;lt;FLAG&amp;gt; &amp;lt;RNAME&amp;gt; &amp;lt;POS&amp;gt; &amp;lt;MAPQ&amp;gt; &amp;lt;CIGAR&amp;gt; &amp;lt;MRNM&amp;gt; &amp;lt;MPOS&amp;gt; &amp;lt;ISIZE&amp;gt; &amp;lt;SEQ&amp;gt; &amp;lt;QUAL&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If the corresponding information is unavailable or irrelevant, field values can be ‘0’ or ‘*’ (depending on the field, see below), but they cannot be missing! After the 11 mandatory fields, a variable number of optional fields can be present. Here’s an example of one single line of a real-life SAM file (you may need to scroll sideways):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ERR458493 .552967 16 chrI 140 255 12 M61232N37M2S * 0 0 CCACTCGTTCACCAGGGCCGGCGGGCTGATCACTTTATCGTGCATCTTGGC BB?HHJJIGHHJIGIIJJIJGIJIJJIIIGHBJJJJJJHHHHFFDDDA1+B NH:i:1 HI:i:1 AS:i:41 nM:i:2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following table explains the format and content of each field. The &lt;code&gt;FLAG&lt;/code&gt;, &lt;code&gt;CIGAR&lt;/code&gt;, and the optional fields (marked in blue) are explained in more detail below. The number of optional fields can vary widely between different SAM files and even between reads within in the same file. The field types marked in blue are explained in more detail in the main text below.&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/sam_fields.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h4 id=&#34;flag-field&#34;&gt;&lt;code&gt;FLAG&lt;/code&gt; field&lt;/h4&gt;

&lt;p&gt;The FLAG field encodes various pieces of information about the individual read, which is particularly important for PE reads. It contains an integer that is generated from a sequence of Boolean bits (0, 1). This way, answers to multiple binary (Yes/No) questions can be compactly stored as a series of bits, where each of the single bits can be addressed and assigned separately.&lt;/p&gt;

&lt;p&gt;The following table gives an overview of the different properties that can be encoded in the FLAG field. The developers of the SAM format and samtools tend to use the hexadecimal encoding as a means to refer to the different bits in their documentation. The value of the FLAG field in a given SAM file, however, will always be the decimal representation of the sum of the underlying binary values (as shown in Table below, row 2).&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/sam_flag.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;The &lt;code&gt;FLAG&lt;/code&gt; field of SAM files stores information about the respective read alignment in one single decimal number. The decimal number is the sum of all the answers to the Yes/No questions associated with each binary bit. The hexadecimal representation is used to refer to the individual bits (questions). A bit is set if the corresponding state is true. For example, if a read is paired, &lt;code&gt;0x1&lt;/code&gt; will be set, returning the decimal value of 1. Therefore, all &lt;code&gt;FLAG&lt;/code&gt; values associated with paired reads must be uneven decimal numbers. Conversely, if the &lt;code&gt;0x1&lt;/code&gt; bit is unset (= read is not paired), no assumptions can be made about &lt;code&gt;0x2&lt;/code&gt;, &lt;code&gt;0x8&lt;/code&gt;, &lt;code&gt;0x20&lt;/code&gt;, &lt;code&gt;0x40&lt;/code&gt; and &lt;code&gt;0x80&lt;/code&gt; because they refer to paired reads.&lt;/p&gt;

&lt;p&gt;In a run with single reads, the flags you most commonly see are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;0: This read has been mapped to the forward strand. (None of the bit-wise flags have been set.)&lt;/li&gt;
&lt;li&gt;4: The read is unmapped (&lt;code&gt;0x4&lt;/code&gt; is set).&lt;/li&gt;
&lt;li&gt;16: The read is mapped to the reverse strand (&lt;code&gt;0x10&lt;/code&gt; is set)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(&lt;code&gt;0x100&lt;/code&gt;, &lt;code&gt;0x200&lt;/code&gt; and &lt;code&gt;0x400&lt;/code&gt; are not used by most aligners/mappers, but could, in principle be set for single reads.) Some common &lt;code&gt;FLAG&lt;/code&gt; values that you may see in a PE experiment include:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;69&lt;/strong&gt; (= 1 + 4 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, is the first read in the pair, and is unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;77&lt;/strong&gt; (= 1 + 4 + 8 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, is the first read in the pair, both are unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;83&lt;/strong&gt; (= 1 + 2 + 16 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the first read in the pair, and it is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;99&lt;/strong&gt; (= 1 + 2 + 32 + 64)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the first read in the pair, and its mate is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;133&lt;/strong&gt; (= 1 + 4 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, and it is unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;137&lt;/strong&gt; (= 1 + 8 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, and it is mapped while its mate is not.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;141&lt;/strong&gt; (= 1 + 4 + 8 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, is the second read in the pair, but both are unmapped.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;147&lt;/strong&gt; (= 1 + 2 + 16 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the second read in the pair, and mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;163&lt;/strong&gt; (= 1 + 2 + 32 + 128)&lt;/td&gt;
&lt;td&gt;The read is paired, mapped in a proper pair, is the second read in the pair, and its mate is mapped to the reverse strand.&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;A useful website for quickly translating the FLAG integers into plain English explanations like the ones shown above is: &lt;a href=&#34;https://broadinstitute.github.io/picard/explain-flags.html&#34;&gt;https://broadinstitute.github.io/picard/explain-flags.html&lt;/a&gt;&lt;/p&gt;

&lt;h4 id=&#34;cigar-string&#34;&gt;&lt;code&gt;CIGAR&lt;/code&gt; string&lt;/h4&gt;

&lt;p&gt;&lt;code&gt;CIGAR&lt;/code&gt; stands for &lt;em&gt;Concise Idiosyncratic Gapped Alignment Report&lt;/em&gt;. This sixth field of a SAM file
contains a so-called CIGAR string indicating which operations were necessary to map the read to the reference sequence at that particular locus.&lt;/p&gt;

&lt;p&gt;The following operations are defined in CIGAR format (also see figure below):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt; - Alignment (can be a sequence match or mismatch!)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;I&lt;/strong&gt; - Insertion in the read compared to the reference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;D&lt;/strong&gt; - Deletion in the read compared to the reference&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;N&lt;/strong&gt; - Skipped region from the reference. For mRNA-to-genome alignments, an N operation represents an intron. For other types of alignments, the interpretation of N is not defined.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;S&lt;/strong&gt; - Soft clipping (clipped sequences are present in read); S may only have H operations between them and the ends of the string&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;H&lt;/strong&gt; - Hard clipping (clipped sequences are NOT present in the alignment record); can only be present as the first and/or last operation&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;P&lt;/strong&gt; - Padding (silent deletion from padded reference)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;=&lt;/strong&gt; - Sequence match (not widely used)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;X&lt;/strong&gt; - Sequence mismatch (not widely used)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The sum of lengths of the &lt;strong&gt;M&lt;/strong&gt;, &lt;strong&gt;I&lt;/strong&gt;, &lt;strong&gt;S&lt;/strong&gt;, &lt;strong&gt;=&lt;/strong&gt;, &lt;strong&gt;X&lt;/strong&gt; operations must equal the length of the read. Here are some examples:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/cigar.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;h4 id=&#34;optional-fields&#34;&gt;Optional fields&lt;/h4&gt;

&lt;p&gt;Following the eleven mandatory SAM file fields, the optional fields are presented as key-value
pairs in the format of &lt;code&gt;&amp;lt;TAG&amp;gt;:&amp;lt;TYPE&amp;gt;:&amp;lt;VALUE&amp;gt;&lt;/code&gt;, where &lt;code&gt;TYPE&lt;/code&gt; is one of:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;A&lt;/code&gt; - Character&lt;/li&gt;
&lt;li&gt;&lt;code&gt;i&lt;/code&gt; - Integer&lt;/li&gt;
&lt;li&gt;&lt;code&gt;f&lt;/code&gt; - Float number&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Z&lt;/code&gt; - String&lt;/li&gt;
&lt;li&gt;&lt;code&gt;H&lt;/code&gt; - Hex string&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The information stored in these optional fields will vary widely depending on the mapper and new tags can be added freely. In addition, reads within the same SAM file may have different numbers of optional fields, depending on the program that generated the SAM file. Commonly used optional tags include:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;AS:i&lt;/code&gt; - Alignment score&lt;/li&gt;
&lt;li&gt;&lt;code&gt;BC:Z&lt;/code&gt; - Barcode sequence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;HI:i&lt;/code&gt; - Match is i-th hit to the read&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NH:i&lt;/code&gt; - Number of reported alignments for the query sequence&lt;/li&gt;
&lt;li&gt;&lt;code&gt;NM:i&lt;/code&gt; - Edit distance of the query to the reference&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MD:Z&lt;/code&gt; - String that contains the exact positions of mismatches (should complement the CIGAR string)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;RG:Z&lt;/code&gt; - Read group (should match the entry after ID if @RG is present in the header.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Thus, for example, we can use the NM:i:0 tag to select only those reads which map perfectly to the reference(i.e., have no mismatches). While the optional fields listed above are fairly standardized, tags that begin with &lt;code&gt;X&lt;/code&gt;, &lt;code&gt;Y&lt;/code&gt;, and &lt;code&gt;Z&lt;/code&gt; are reserved for particularly free usage and will never be part of the official SAM file format specifications. &lt;code&gt;XS&lt;/code&gt;, for example, is used by TopHat (an RNA-seq analysis tool we will discuss later) to encode the strand information (e.g., &lt;code&gt;XS:A:+&lt;/code&gt;) while Bowtie2 and BWA use &lt;code&gt;XS:i:&lt;/code&gt; for reads with multiple alignments to store the alignment score for the next-best-scoring alignment (e.g., &lt;code&gt;XS:i:30&lt;/code&gt;).&lt;/p&gt;

&lt;h3 id=&#34;read-groups&#34;&gt;Read Groups&lt;/h3&gt;

&lt;p&gt;One of the key features of SAM/BAM format is the ability to label individual reads with readgroup tags. This allows pooling results of multiple experiments into a single BAM dataset. This significantly simplifies downstream logistics: instead of dealing with multiple datasets one can handle just one. Many downstream analysis tools such as variant callers are designed to recognize readgroup data and output results on per-readgroup basis.&lt;/p&gt;

&lt;p&gt;One of the best descriptions of BAM readgroups is on &lt;a href=&#34;http://gatkforums.broadinstitute.org/discussion/1317/collected-faqs-about-bam-files&#34;&gt;GATK support site&lt;/a&gt;. We have gratefully stolen two tables describing the most important readgroup tags - &lt;code&gt;ID&lt;/code&gt;, &lt;code&gt;SM&lt;/code&gt;, &lt;code&gt;LB&lt;/code&gt;, and &lt;code&gt;PL&lt;/code&gt; - from GATK forum and provide them here:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/rg.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;As further described in the GATK forum:&amp;rdquo;&lt;em&gt;A concrete example may be instructive. Suppose I have a trio of samples: MOM, DAD, and KID. Each has two DNA libraries prepared, one with 400 bp inserts and another with 200 bp inserts. Each of these libraries is run on two lanes of an Illumina machine, requiring 3 x 2 x 2 = 12 lanes of data. When the data come off the sequencer, I would create 12 bam files, with the following @RG fields in the header&lt;/em&gt;&amp;ldquo;:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/rg_example.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;p&gt;Too see an example of read group manipulation in Galaxy see the following &lt;a href=&#34;https://player.vimeo.com/video/123102338#t=1:40&#34;&gt;clip&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;manipulating-sam-bam-datasets&#34;&gt;Manipulating SAM/BAM datasets&lt;/h2&gt;

&lt;p&gt;We support four major toolsets for processing of SAM/BAM datasets:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://deeptools.github.io/&#34;&gt;DeepTools&lt;/a&gt; - a suite of user-friendly tools for the visualization, quality control and normalization of data from deep-sequencing DNA sequencing experiments.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;[http://www.htslib.org/&#34;&gt;SAMtools&lt;/a&gt; - various utilities for manipulating alignments in the SAM/BAM format, including sorting, merging, indexing and generating alignments in a per-position format.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/pezmaster31/bamtools/wiki/Tutorial_Toolkit_BamTools-1.0.pdf&#34;&gt;BAMtools&lt;/a&gt; - a toolkit for reading, writing, and manipulating BAM (genome alignment) files.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://broadinstitute.github.io/picard/&#34;&gt;Picard&lt;/a&gt; - a set of Java tools for manipulating high-throughput sequencing data (HTS) data and formats.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The following video highlights de-duplication, filtering, and cleaning of a BAM dataset using BAMtools and Picard tools:&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/123113197&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;font-color-red-try-it-yourself-font-2&#34;&gt;&lt;font color=&#34;red&#34;&gt;Try it yourself&lt;/font&gt;&lt;/h3&gt;

&lt;p&gt;Perform a similar analyses with your own data.&lt;/p&gt;

&lt;h2 id=&#34;the-challenge-of-read-duplicates&#34;&gt;The challenge of read duplicates&lt;/h2&gt;

&lt;h3 id=&#34;pcr-duplicates&#34;&gt;PCR duplicates&lt;/h3&gt;

&lt;p&gt;Preparation of sequencing libraries (at least at the time of writing) for technologies such as Illumina (used in this examples) involves PCR amplification. It is required to generate sufficient number of sequencing templates so that a reliable detection can be performed by base callers. Yet PCR has it&amp;rsquo;s biases, which are especially profound in cases of multitemplate PCR used for construction of sequencing libraries (Kanagawa et al. &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;amp;db=PubMed&amp;amp;dopt=Abstract&amp;amp;list_uids=16233530&#34;&gt;2003&lt;/a&gt;).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/pcr-duplicates.png&#34; /&gt;
    
    
&lt;/figure&gt;

Analyzing molecules aligning with the same outer coordinates, a mapping quality of at least 30 and a length of at least 30nt, resulted in an average coverage of 12.9 per PCR duplicate and an empirical coverage distribution similar to an exponential/power law distribution (left upper panel). This indicates that many molecules are only observed for deeper sequencing while other molecules are available at higher frequencies. Analyzing length (left middle panel) and GC content (left lower panel) patterns as well as the combination (right panel) shows higher PCR duplicate counts for a GC content between 30% to 70% as well as for shorter molecules compared to longer molecules. This effect may be due to an amplification bias from the polymerase or the cluster generation process necessary for Illumina sequencing. From Ph.D. dissertation of &lt;a href=&#34;http://www.qucosa.de/fileadmin/data/qucosa/documents/7110/pflichtexemplar_final.pdf&#34;&gt;Martin Kircher&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Duplicates can be identified based on their outer alignment coordinates or using sequence-based clustering. One of the common ways for identification of duplicate reads is the &lt;code&gt;MarkDuplicates&lt;/code&gt; utility from &lt;a href=&#34;https://broadinstitute.github.io/picard/command-line-overview.html&#34;&gt;Picard&lt;/a&gt; package. It is designed to identify both PCR and optical duplicates:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Duplicates are identified as read pairs having identical 5&amp;rsquo; positions (coordinate and strand) for both reads in a mate pair (and optionally, matching unique molecular identifier reads; see BARCODE_TAG option). Optical, or more broadly Sequencing, duplicates are duplicates that appear clustered together spatially during sequencing and can arise from optical/imagine-processing artifacts or from bio-chemical processes during clonal amplification and sequencing; they are identified using the READ_NAME_REGEX and the OPTICAL_DUPLICATE_PIXEL_DISTANCE options. The tool&amp;rsquo;s main output is a new SAM or BAM file in which duplicates have been identified in the SAM flags field, or optionally removed (see REMOVE_DUPLICATE and REMOVE_SEQUENCING_DUPLICATES), and optionally marked with a duplicate type in the &amp;lsquo;DT&amp;rsquo; optional attribute. In addition, it also outputs a metrics file containing the numbers of READ_PAIRS_EXAMINED, UNMAPPED_READS, UNPAIRED_READS, UNPAIRED_READ DUPLICATES, READ_PAIR_DUPLICATES, and READ_PAIR_OPTICAL_DUPLICATES. Usage example: java -jar picard.jar MarkDuplicates I=input.bam \ O=marked_duplicates.bam M=marked_dup_metrics.txt.`&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;sampling-coincidence-duplicates&#34;&gt;Sampling coincidence duplicates&lt;/h3&gt;

&lt;p&gt;However, one has to be careful when removing duplicates in cases when the sequencing targets are small (e.g., sequencing of bacterial, viral, or organellar genomes as well as amplicons). This is because when sequencing target is small reads will have the same coordinates by chance and not because of PCR amplification issues. The figure below illustrates the fine balance between estimates allele frequency, coverage, and variation in insert size:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;http://nekrut.github.io/BMMB554/BMMB554/img/sampling-bias.png&#34; /&gt;
    
    
&lt;/figure&gt;

The Variant Allele Frequency (VAF) bias determined by coverage and insert size variance. Reads are paired-end and read length is 76. The insert size distribution is modeled as a Gaussian distribution with mean at 200 and standard deviation shown on the x-axis. The true VAF is 0.05. The darkness at each position indicates the magnitude of the bias in the VAF. (From Zhou et al. &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/30/8/1073&#34;&gt;2013&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Galaxy: Exons and Repeats</title>
      <link>http://nekrut.github.io/BMMB554/post/topic6/</link>
      <pubDate>Fri, 30 Sep 2016 10:39:09 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic6/</guid>
      <description>

&lt;h1 id=&#34;introduction-to-galaxy&#34;&gt;Introduction to Galaxy&lt;/h1&gt;

&lt;p&gt;In this lecture we will introduce you to bare basics of Galaxy:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Getting data from external databases such as UCSC&lt;/li&gt;
&lt;li&gt;Performing simple data manipulation&lt;/li&gt;
&lt;li&gt;Understanding Galaxy&amp;rsquo;s History system&lt;/li&gt;
&lt;li&gt;Creating a running a workflow&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;what-are-we-trying-to-do&#34;&gt;What are we trying to do?&lt;/h2&gt;

&lt;p&gt;Suppose you get the following question:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Mom (or Dad) &amp;hellip; Which coding exon has the highest number of single nucleotide polymorphisms on chromosome 22?&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;You think to yourself &amp;ldquo;Wow! This is a simple question &amp;hellip; I know exactly where the data is (at UCSC) but how do I actually compute this?&amp;rdquo; The truth is, there is really no straightforward way of answering this question in a time frame comparable to the attention span of a 7-year-old. Well &amp;hellip; actually there is and it is called Galaxy. So let&amp;rsquo;s try it&amp;hellip;&lt;/p&gt;

&lt;h2 id=&#34;0-organizing-your-windows-and-setting-up-galaxy-account&#34;&gt;0. Organizing your windows and setting up Galaxy account&lt;/h2&gt;

&lt;h3 id=&#34;0-0-getting-your-display-sorted-out&#34;&gt;0.0. Getting your display sorted out&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: Some screenshots shown here may appear slightly different from the ones you will see on your screen. Galaxy is quickly evolving and as a result some discrepancies are possible (and likely).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To get the most of this tutorial open two browser windows. One you already have (it is this page). To open the other, &lt;strong&gt;right&lt;/strong&gt; click &lt;a href=&#34;http://usegalaxy.org&#34;&gt;this link&lt;/a&gt; and choose &amp;ldquo;Open in a New Window&amp;rdquo; (or something similar depending on your operating system and browser):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/newWindow.png&#34; alt=&#34;open in a new window&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then organize your windows as something like this (depending on the size of your monitor you may or may not be able to organize things this way, but you get the idea):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://galaxyproject.org/galaxy101/twoScreens.png&#34; alt=&#34;Windows side by side&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;0-1-setting-up-galaxy-account&#34;&gt;0.1. Setting up Galaxy account&lt;/h3&gt;

&lt;p&gt;Go to the &lt;strong&gt;User&lt;/strong&gt; link at the top of Galaxy interface and choose &lt;strong&gt;Register&lt;/strong&gt; (unless of course you already have an account):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/register.png&#34; alt=&#34;register&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then enter your information and you&amp;rsquo;re in!&lt;/p&gt;

&lt;h2 id=&#34;1-getting-data-from-ucsc&#34;&gt;1. Getting data from UCSC&lt;/h2&gt;

&lt;h3 id=&#34;1-0-getting-coding-exons&#34;&gt;1.0. Getting coding exons&lt;/h3&gt;

&lt;p&gt;First thing we will do is to obtain data from UCSC by clicking &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getDataUCSC.png&#34; alt=&#34;get data from UCSC&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You will see UCSC Table Browser interface appearing in your browser window:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes.png&#34; alt=&#34;UCSC genes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Make sure that your settings are exactly the same as shown on the screen (in particular, &lt;strong&gt;position&lt;/strong&gt; should be set to &amp;ldquo;chr22&amp;rdquo;, &lt;strong&gt;output format&lt;/strong&gt; should be set to &amp;ldquo;BED - browser extensible data&amp;rdquo;, and &amp;ldquo;Galaxy&amp;rdquo; should be checked within the &lt;strong&gt;Send output to&lt;/strong&gt; option). Click &lt;strong&gt;get output&lt;/strong&gt; and you will see the next screen:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes2.png&#34; alt=&#34;UCSC ganes 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;here make sure &lt;strong&gt;Create one BED record per:&lt;/strong&gt; is set to &amp;ldquo;Coding Exons&amp;rdquo; and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt; button. After this you will see your first History Item in Galaxy&amp;rsquo;s right pane. It will go through gray (preparing) and yellow (running) states to become green:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/firstHistoryItem.png&#34; alt=&#34;First history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;1-1-getting-snps&#34;&gt;1.1. Getting SNPs&lt;/h3&gt;

&lt;p&gt;Now is the time to obtain SNP data (SNPs are &lt;a href=&#34;https://ghr.nlm.nih.gov/primer/genomicresearch/snp&#34;&gt;&lt;em&gt;single nucleotide polymorphisms&lt;/em&gt;&lt;/a&gt;). This is done almost exactly the same way. First thing we will do is to again click on &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getDataUCSC.png&#34; alt=&#34;get data from UCSC&#34; /&gt;&lt;/p&gt;

&lt;p&gt;but now change &lt;strong&gt;group&lt;/strong&gt; to &amp;ldquo;Variation&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/variation.png&#34; alt=&#34;Variation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;so that the whole page looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscSNPs.png&#34; alt=&#34;UCSC SNPs&#34; /&gt;&lt;/p&gt;

&lt;p&gt;click get output and you should see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscSNPs2.png&#34; alt=&#34;UCSC SNPs 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;where you need to make sure that &lt;strong&gt;Whole Gene&lt;/strong&gt; is selected (&amp;ldquo;Whole Gene&amp;rdquo; here really means &amp;ldquo;Whole Feature&amp;rdquo;) and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt; button. You will get your second item in the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/secondHistoryItem.png&#34; alt=&#34;Second history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Now we will rename the two history items to &amp;ldquo;Exons&amp;rdquo; and &amp;ldquo;SNPs&amp;rdquo; by clicking on the Pencil icon adjacent to each item. After changing the name scroll down and click &lt;strong&gt;Save&lt;/strong&gt;.  Also we will rename history to &amp;ldquo;my example&amp;rdquo; (or whatever you want) by clicking on &lt;strong&gt;Unnamed history&lt;/strong&gt; so everything looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/rename.png&#34; alt=&#34;Rename&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/185523444&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;2-finding-exons-with-the-highest-number-of-snps&#34;&gt;2. Finding Exons with the highest number of SNPs&lt;/h2&gt;

&lt;h3 id=&#34;2-0-joining-exons-with-snps&#34;&gt;2.0. Joining exons with SNPs&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s remind ourselves that our objective was to find which exon contains the most SNPs. This first step in answering this question will be joining exons with SNPs (a fancy word for printing exons and SNPs that overlap side by side). This is done using &lt;strong&gt;Operate on Genomics Intervals &amp;#8594; Join&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/join.png&#34; alt=&#34;Join&#34; /&gt;&lt;/p&gt;

&lt;p&gt;make sure your &lt;strong&gt;Exons&lt;/strong&gt; are first and &lt;strong&gt;SNPs&lt;/strong&gt; are second and click &lt;strong&gt;Execute&lt;/strong&gt;. You will get the third history item:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/thirdHistoryItem.png&#34; alt=&#34;Third history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-1-counting-the-number-of-snps-per-exon&#34;&gt;2.1. Counting the number of SNPs per exon&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s look at the data obtained from the join operation above (you can do it by clicking the &amp;ldquo;eye&amp;rdquo; icon adjacent to the dataset). Below is a subsample of rows from the joined datasets (you may need to scroll sideways to see the entire length of the rows below):&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;font color=&#34;red&#34;&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710880 15710881 rs568292779 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710947 15710948 rs544633418 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710906 15710907 rs548691624 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710920 15710921 rs530488686 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710932 15710933 rs563306354 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15711019 15711020 rs559431407 0 -
chr22 15710867 15711034 uc062bej.1_cds_9_0_chr22_15710868_f  0 + chr22 15710949 15710950 rs532940301 0 -
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;/font&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;                                                      ....
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chr22 15719659 15719777 uc062bej.1_cds_10_0_chr22_15719660_f 0 + chr22 15719668 15719669 rs200891952 0 -
chr22 15719659 15719777 uc062bej.1_cds_10_0_chr22_15719660_f 0 + chr22 15719751 15719752 rs556077431 0 -
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Look at the rows highlighted in red. They all correspond to the same exon (id = &lt;code&gt;uc062bej.1_cds_9_0_chr22_15710868_f&lt;/code&gt;) that overlaps seven distinct SNPs (ids: &lt;code&gt;rs568292779&lt;/code&gt;, &lt;code&gt;rs544633418&lt;/code&gt;, &lt;code&gt;rs548691624&lt;/code&gt;, &lt;code&gt;rs530488686&lt;/code&gt;, &lt;code&gt;rs563306354&lt;/code&gt;, &lt;code&gt;rs559431407&lt;/code&gt;, &lt;code&gt;rs532940301&lt;/code&gt;). In other words this means that this exon contains seven SNPs. Since our ultimate goal is to count the number of SNPs per exon we can simply do this by counting how many times an exon&amp;rsquo;s id appears in pur dataset. This can be easily done with the &lt;strong&gt;Join, Subtract, and Group &amp;#8594; Group&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/group1.png&#34; alt=&#34;Group&#34; /&gt;&lt;/p&gt;

&lt;p&gt;choose column 4 by selecting &amp;ldquo;Column: 4&amp;rdquo; in &lt;strong&gt;Group by&lt;/strong&gt; column. Then click on &lt;strong&gt;Insert Operation&lt;/strong&gt; and make sure the interface looks exactly as shown below:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/group2.png&#34; alt=&#34;Group2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;click &lt;strong&gt;Execute&lt;/strong&gt;. Your history will look like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/fourthHistoryItem.png&#34; alt=&#34;Fourth history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;if you look at the above image you will see that the result of grouping (dataset #4) contains two columns. This first contains the exon name while the second shows the number of times this name has been repeated in dataset #3.&lt;/p&gt;

&lt;h3 id=&#34;2-2-sorting-exons-by-snp-count&#34;&gt;2.2. Sorting exons by SNP count&lt;/h3&gt;

&lt;p&gt;To see which exon has the highest number of SNPs we can simply sort the dataset #4 on the second column in descending order. This is done with &lt;strong&gt;Filter and Sort &amp;#8594; Sort&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/sort.png&#34; alt=&#34;Sort&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This will generate the fifth history item:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/fifthHistoryItem.png&#34; alt=&#34;Fifth history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and you can now see that the highest number of SNPs per exon is 63.&lt;/p&gt;

&lt;h3 id=&#34;2-3-selecting-top-five&#34;&gt;2.3. Selecting top five&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s select top five exons with the highest number of SNPs. For this we will use &lt;strong&gt;Text Manipulation &amp;#8594; Select First&lt;/strong&gt; tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/selectFirst.png&#34; alt=&#34;Select first&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Clicking &lt;strong&gt;Execute&lt;/strong&gt; will produce the sixth history item that will contain just five lines:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/sixthHistoryItem.png&#34; alt=&#34;Sixth history item&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2-4-recovering-exon-info-and-displaying-data-in-genome-browsers&#34;&gt;2.4. Recovering exon info and displaying data in genome browsers&lt;/h3&gt;

&lt;p&gt;Now we know that in this dataset the five top exons contain between 26 and 63 SNPs. But what else can we learn about these? To know more we need to get back the positional information (coordinates) of these exons. This information was lost at the grouping step and now all we have is just two columns. To get coordinates back we will match the names of exons in dataset #6 (column 1) against names of the exons in the original dataset #1 (column 4). This can be done with &lt;strong&gt;Join, Subtract and Group &amp;#8594; Compare two Queries&lt;/strong&gt; tool (note the settings of the tool in the middle pane):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/compare.png&#34; alt=&#34;Compare&#34; /&gt;&lt;/p&gt;

&lt;p&gt;this adds the seventh dataset to the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/seventhHistoryItem.png&#34; alt=&#34;Seventh history item&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The best way to learn about these exons is to look at their genomic surrounding. There is really no better way to do this than using genome browsers. Because this analysis was performed on &amp;ldquo;standard&amp;rdquo; human genome (&lt;code&gt;hg38&lt;/code&gt; in this case), you have two choices - &lt;a href=&#34;http://genomes.ucsc.edu&#34;&gt;UCSC Genome Browser&lt;/a&gt; and &lt;a href=&#34;https://www.broadinstitute.org/igv/&#34;&gt;IGV&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/browsers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For example, clicking on &lt;strong&gt;display at UCSC main&lt;/strong&gt; will show something like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucsc.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;video-1&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/185538367&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;3-understanding-histories&#34;&gt;3. Understanding histories&lt;/h2&gt;

&lt;p&gt;In Galaxy your analysis steps are represented as a list called &lt;em&gt;History&lt;/em&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/seventhHistoryItem.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Histories can be very large, you can have as many histories as you want, and all history behavior is controlled by the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-refresh.png&#34; alt=&#34;refresh&#34; /&gt;, &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt;, and &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-columns.png&#34; alt=&#34;multi_history&#34; /&gt; buttons on the top of the History pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/historyDetail.png&#34; alt=&#34;History detail&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-refresh.png&#34; alt=&#34;refresh&#34; /&gt; simply refreshes the history. The &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; button gives you access to myriad of history-specific options:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyOptions.png&#34; alt=&#34;History options&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Many of the options here are self-explanatory. If you create a new history, your current history does not disappear. If you would like to list all of your histories just choose &lt;strong&gt;Saved Histories&lt;/strong&gt; and you will see a list of all your histories in the center pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyList.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yet there is a better way to look for all your histories. This is what the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-columns.png&#34; alt=&#34;refresh&#34; /&gt; button is for. It allows you to browse and move datasets across histories:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/multiHistoryView.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Here, the current history is on the left (&lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt;) and your (or mine in this case) other histories are displayed to the right of the current history. These can be ordered in a variety of ways by clicking the &lt;strong&gt;&amp;hellip;&lt;/strong&gt; button:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxyproject.org/galaxy101/orderingHistories.png&#34; alt=&#34;History list&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can also scroll sideways using trackpad gestures, move datasets across histories by simply clicking and dragging, and search for histories and individual datasets. This interface also allows you to switch to any existing history (i.e., making it current). Click &lt;strong&gt;Done&lt;/strong&gt; once you&amp;rsquo;re done.&lt;/p&gt;

&lt;p&gt;A comprehensive overview of Galaxy&amp;rsquo;s history functions is found &lt;a href=&#34;https://wiki.galaxyproject.org/Histories&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;4-creating-and-editing-a-workflow&#34;&gt;4. Creating and editing a workflow&lt;/h2&gt;

&lt;h3 id=&#34;4-0-extracting-a-workflow&#34;&gt;4.0. Extracting a workflow&lt;/h3&gt;

&lt;p&gt;Lets take a look at the history again:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/historyCollapsed.png&#34; alt=&#34;Collapsed history&#34; /&gt;&lt;/p&gt;

&lt;p&gt;You can see that this history contains all steps of our analysis. So by building this history we have actually created a complete record of our analysis with Galaxy preserving all parameter settings applied at every step. Wouldn&amp;rsquo;t it be nice to just convert this history into a workflow that we&amp;rsquo;ll be able to execute again and again? This can be done by clicking on the &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; button and selecting &lt;strong&gt;Extract Workflow&lt;/strong&gt; option:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/extractWorkflow.png&#34; alt=&#34;Extract workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The center pane will change as shown below and you will be able to choose which steps to include/exclude and how to name the newly created workflow. In this case I named it &lt;code&gt;galaxy101-2015&lt;/code&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/createWorkflow.png&#34; alt=&#34;Create workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;once you click &lt;strong&gt;Create Workflow&lt;/strong&gt; you will get the following message: &amp;ldquo;Workflow &amp;lsquo;galaxy101-2015&amp;rsquo; created from current history. You can &lt;strong&gt;edit&lt;/strong&gt; or &lt;strong&gt;run&lt;/strong&gt; the workflow&amp;rdquo;.&lt;/p&gt;

&lt;h3 id=&#34;4-1-opening-workflow-editor&#34;&gt;4.1. Opening workflow editor&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s click &lt;strong&gt;edit&lt;/strong&gt; (if you click something else and the message in the center page disappears, you can always access all your workflows including the one you just created using the &lt;strong&gt;Workflow&lt;/strong&gt; link on top of Galaxy interface). This will open Galaxy&amp;rsquo;s workflow editor (to get this view I clicked the arrow at the lower left corner of the screen, which collapsed the tool pane of the Galaxy interface). It will allow you to examine and change settings of this workflow as shown below. Note that the box corresponding to the &lt;strong&gt;Select First&lt;/strong&gt; tool is selected (highlighted with the blueish border) and you can see parameters of this tool on the right pane. This is how you can view and change parameters of all tools involved in the workflow:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/wfEditor.png&#34; alt=&#34;Workflow editor&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-2-hiding-intermediate-steps&#34;&gt;4.2. Hiding intermediate steps&lt;/h3&gt;

&lt;p&gt;Among multiple things you can do with workflows I will just mention one. When workflow is executed one is usually interested in the final product and not in the intermediate steps. These steps can be hidden by mousing over a small asterisk in the lower right corner of every tool:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/hideStep.png&#34; alt=&#34;Hide step&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Yet there is a catch. In a newly created workflow all steps are hidden by default and the default behavior of Galaxy is that if all steps of a given workflow are hidden, then nothing gets hidden in the history. This may be counterintuitive, but this is done to decrease the amount of clicking if you do want to hide some steps. So in our case if we want to hide all intermediate steps with the exception of the last one we will click that asterisk in last step of the workflow:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/lastStep.png&#34; alt=&#34;Last step&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Once you do this the representation of the workflow in the bottom right corner of the editor will change with the last step becoming orange. This means that this is the only step, which will generate a dataset visible in the history:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/workflowOverview.png&#34; alt=&#34;Workflow Overview&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-3-renaming-inputs&#34;&gt;4.3. Renaming inputs&lt;/h3&gt;

&lt;p&gt;Right now both inputs to the workflow look exactly the same. This is a problem as will be very confusing which input should be &lt;strong&gt;Exons&lt;/strong&gt; and which should be &lt;strong&gt;SNPs&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/namingInputs1.png&#34; alt=&#34;Naming inputs 1&#34; /&gt;&lt;/p&gt;

&lt;p&gt;One the image above you will see that the top input dataset (the one with the blue border) connects to the &lt;strong&gt;Join tool&lt;/strong&gt; first, so it must correspond to the exon data. If you click on this box (in the image above it is already clicked on because it is outlined with the blue border) you will be able to rename the dataset in the right pane:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/renameExons.png&#34; alt=&#34;Rename Exons&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Then click on the second input dataset and rename it &amp;ldquo;Features&amp;rdquo; (this would make this workflow a bit more generic, which will be useful later in this tutorial):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/renameFeatures.png&#34; alt=&#34;Rename features&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-4-renaming-outputs&#34;&gt;4.4. Renaming outputs&lt;/h3&gt;

&lt;p&gt;Finally let&amp;rsquo;s rename the workflow&amp;rsquo;s output. For this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;click on the last dataset (&lt;strong&gt;Compare two Queries&lt;/strong&gt;)&lt;/li&gt;
&lt;li&gt;scroll down the rightmost pane and click on &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/addAction.png&#34; alt=&#34;add action&#34; /&gt;&lt;/li&gt;
&lt;li&gt;Type &lt;code&gt;Top Exons&lt;/code&gt; in the &lt;strong&gt;Rename dataset&lt;/strong&gt; text box:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/topExons.png&#34; alt=&#34;Top exons&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;4-5-setting-parameters-at-runtime&#34;&gt;4.5. Setting parameters &amp;ldquo;at runtime&amp;rdquo;&lt;/h3&gt;

&lt;p&gt;What we are trying to do here is do design a generic workflow. This means that time to time you will need to change parameters within this workflow. For instance, in this tutorial we were selecting 5 exons containing the highest number of SNPs. But what if you need to select 10? Thus it makes sense to leave these types of parameters adjustable. To do this:&lt;/p&gt;

&lt;p&gt;First, select a tool in which you want to set parameters at runtime (&lt;code&gt;Select first&lt;/code&gt; in this case):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runtimeTool.png&#34; alt=&#34;runtime Tool Selection&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Next, select parameter you would like to set at runtime. To do this just hover over the &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/paramSymbol.png&#34; alt=&#34;paramSymbol&#34; /&gt; icon so it looks like this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runtimeParam.png&#34; alt=&#34;runtime Param Selection&#34; /&gt;&lt;/p&gt;

&lt;p&gt;and click! Your parameter will now be set at runtime.&lt;/p&gt;

&lt;h3 id=&#34;4-6-save-it-is-important&#34;&gt;4.6. Save! It is important&amp;hellip;&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s save the changes we&amp;rsquo;ve made by clicking &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; and selecting Save:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/wfSave.png&#34; alt=&#34;wfSave&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;5-run-workflow-on-whole-genome-data&#34;&gt;5. Run workflow on whole genome data&lt;/h2&gt;

&lt;p&gt;Now that we have a workflow, let&amp;rsquo;s do something grand like, for example, finding exons with the highest number of repetitive elements across the entire human genome.&lt;/p&gt;

&lt;h3 id=&#34;5-0-create-a-new-history&#34;&gt;5.0. Create a new history&lt;/h3&gt;

&lt;p&gt;First go back into analysis view by clicking &lt;strong&gt;Analyze Data&lt;/strong&gt; on top of the Galaxy&amp;rsquo;s interface. Now let&amp;rsquo;s create a new history by clicking &lt;img src=&#34;http://galaxyproject.org/galaxy101/fa-cog.png&#34; alt=&#34;cog&#34; /&gt; and selecting &lt;strong&gt;Create New&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/createNewHistory.png&#34; alt=&#34;Create new history&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-1-get-exons&#34;&gt;5.1. Get Exons&lt;/h3&gt;

&lt;p&gt;Now let&amp;rsquo;s get coding exons for the entire genome by going to &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt; and setting up parameters as shown below. Note that this time &lt;code&gt;region&lt;/code&gt; radio button is set to &lt;strong&gt;genome&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/getAllGenes.png&#34; alt=&#34;Get all genes&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Click &lt;strong&gt;get output&lt;/strong&gt; and you will get the next page (if it looks different from the image below, go back and make sure &lt;code&gt;output format&lt;/code&gt; is set to &lt;strong&gt;BED - browser extensible format&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/ucscGenes2.png&#34; alt=&#34;Get exons&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Choose &lt;strong&gt;Coding exons&lt;/strong&gt; and click &lt;strong&gt;Send query to Galaxy&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;5-2-get-repeats&#34;&gt;5.2. Get Repeats&lt;/h2&gt;

&lt;p&gt;Go again to &lt;strong&gt;Get Data &amp;#8594; UCSC Main&lt;/strong&gt; and make sure the following settings are selected (in particular &lt;code&gt;group&lt;/code&gt; = &lt;strong&gt;Repeats&lt;/strong&gt; and &lt;code&gt;track&lt;/code&gt; = &lt;strong&gt;RepeatMasker&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/allRepeats.png&#34; alt=&#34;All repeats&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Click &lt;strong&gt;get output&lt;/strong&gt; and you will get the next page (if it looks different from the image below, go back and make sure &lt;code&gt;output format&lt;/code&gt; is set to &lt;strong&gt;BED - browser extensible format&lt;/strong&gt;):&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/allRepeats2.png&#34; alt=&#34;All repeats 2&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Select &lt;strong&gt;Whole gene&lt;/strong&gt; and click &lt;strong&gt;Send Query to Galaxy&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&#34;5-3-start-the-workflow&#34;&gt;5.3. Start the Workflow&lt;/h3&gt;

&lt;p&gt;At this point you will have two items in your history - one with exons and one with repeats. These datasets are large (especially repeats) and it will take some time for them to become green. Luckily you do not have to wait as Galaxy will automatically start jobs once uploads have ended. So nothing stops us from starting the workflow we have created. First, click on the &lt;strong&gt;Workflow link&lt;/strong&gt; at the top of Galaxy interface, mouse over &lt;strong&gt;galaxy101-2015&lt;/strong&gt;, click, and select &lt;strong&gt;Run&lt;/strong&gt;. Center pane will change to allow you launching the workflow. Select appropriate datasets for &lt;code&gt;Repeats&lt;/code&gt; and &lt;code&gt;Exon&lt;/code&gt; inputs as shown below. Now scroll to &lt;strong&gt;Step 6&lt;/strong&gt; and will see that we can set up &lt;code&gt;Select first&lt;/code&gt; parameter at &lt;em&gt;Runtime&lt;/em&gt; (meaning Now!). So lets put &lt;code&gt;20&lt;/code&gt; in there (or anything else you want) and scroll further down to click &lt;img src=&#34;http://galaxy.psu.edu/galaxy101/runWorkflowButton.png&#34; alt=&#34;Run workflow&#34; /&gt; to see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/launchWorkflow.png&#34; alt=&#34;Launch workflow&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Once workflow has started you will initially be able to see all its steps. Note that you are joining all exons with all repeats, so naturally this will take some time:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/launchedWorkflow.png&#34; alt=&#34;Launched workflow&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;5-4-get-coffee&#34;&gt;5.4. Get coffee&lt;/h3&gt;

&lt;p&gt;As we mentioned above this will take some time, so go get coffee. At last you will see this:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/final.png&#34; alt=&#34;Final view&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;6-we-did-not-fake-this&#34;&gt;6. We did not fake this:&lt;/h2&gt;

&lt;p&gt;The two histories and the workflow described in this page are accessible directly from this page below:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;History &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/galaxy-101-2015&#34;&gt;&lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;History &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/exons-vs-repeats-2015-1&#34;&gt;&lt;strong&gt;Exons vs. Repeats&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Workflow &lt;a href=&#34;https://usegalaxy.org/u/aun1/w/galaxy101-2015-1&#34;&gt;&lt;strong&gt;Galaxy 101-2015&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From there you can import histories and workflows to make them your own. For example, to import &lt;strong&gt;Galaxy 101 (2015)&lt;/strong&gt; history simply click &lt;a href=&#34;https://usegalaxy.org/u/aun1/h/galaxy-101-2015&#34;&gt;this link&lt;/a&gt; and select &lt;code&gt;Import history&lt;/code&gt; link:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://galaxy.psu.edu/galaxy101/importHistory.png&#34; alt=&#34;Final view&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;next&#34;&gt;Next&lt;/h1&gt;

&lt;p&gt;We will start using Galaxy to process and map NGS data.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aligning many sequences quickly</title>
      <link>http://nekrut.github.io/BMMB554/post/topic5/</link>
      <pubDate>Mon, 26 Sep 2016 10:13:02 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic5/</guid>
      <description>

&lt;h1 id=&#34;speeding-things-up&#34;&gt;Speeding things up&lt;/h1&gt;

&lt;p&gt;The topics we discussed in the past lecture explain fundamental ideas behind analysis of biological sequences. They are essential for understanding how current high throughput approaches evolved. Today, we will be talking about advanced concepts implementation of which allows aligning billions of sequencing reads against reference genomes very quickly. Similarly to the previous lecture I have borrowed heavily from the &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image is from &lt;a href=&#34;https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform&#34;&gt;Wikpedia article&lt;/a&gt; on Burrows-Wheeler transform.&lt;/p&gt;

&lt;h2 id=&#34;the-challenge-of-really-large-datasets&#34;&gt;The challenge of really large datasets&lt;/h2&gt;

&lt;p&gt;In the previous lecture we have seen how dynamic programming helps aligning sequences. Unfortunately in reality this approach is not practical for aligning billion of sequencing reads that are routinely generated with NGS technologies.&lt;/p&gt;

&lt;p&gt;If you recall the previous lecture, we were finding alignments using the following approach:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;The performance of this approach expressed as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_O_notation&#34;&gt;big O notation&lt;/a&gt; is:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(mn)$&lt;/p&gt;

&lt;p&gt;where $n$ is the read length and $m$ is the genome length. The $m$ is large. For instance, in the case of human genome it is $3\times10^9$. On top of that we &lt;em&gt;very many&lt;/em&gt; reads. The latest Illumina HiSeq 2500 machine can produce as much as $6\times10^9$ 100 bp reads. Taking this into account our big O notation becomes:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(dmn)$&lt;/p&gt;

&lt;p&gt;where $d\times m\times n = 2\times10^{21}$ ($d$ stands for &lt;em&gt;depth&lt;/em&gt;). In other words to compute alignments between a genome and all these reads we need to perform $2\times10^{21}$ cell updates in the dynamic programming matrices even before we start the traceback. On a 1,000 CPU cluster with 3MHz processors this will take over &lt;strong&gt;2&lt;/strong&gt; years!&lt;/p&gt;

&lt;h2 id=&#34;mapping-versus-alignment&#34;&gt;Mapping versus alignment&lt;/h2&gt;

&lt;p&gt;One possible idea on how to speed things up will be to first find most likely locations for each read and them refine alignments as necessary. In other words reads should be &lt;em&gt;mapped&lt;/em&gt; by identifying regions of the genomes from which they most likely originate. The term &lt;em&gt;mapping&lt;/em&gt; is sometimes used interchangeably with the word &amp;ldquo;alignment&amp;rdquo;. Yet &lt;em&gt;mapping&lt;/em&gt; and &lt;em&gt;alignment&lt;/em&gt; are somewhat different concepts. &lt;a href=&#34;http://lh3lh3.users.sourceforge.net/&#34;&gt;Heng Li&lt;/a&gt; defines them this way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mapping&lt;/strong&gt;: assigning a sequencing read to a location within genome. Mapping is said to be correct and it overlaps the true region from which this read has originated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment&lt;/strong&gt;: detailed placement of every base within a read to a corresponding base within the genome. Alignment is said to be correct is every base if placed correctly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So let&amp;rsquo;s see how we can find potential read locations quickly. Below is a list of key publications highlighting basic principles of current mapping tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2009 | How to map billions of short reads onto genomes? - &lt;a href=&#34;http://www.nature.com/nbt/journal/v27/n5/full/nbt0509-455.html&#34;&gt;Trapnell &amp;amp; Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | Bowtie 1 - &lt;a href=&#34;http://genomebiology.com/content/10/3/R25&#34;&gt;Langmead et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | Bowtie 2 - &lt;a href=&#34;http://www.nature.com/nmeth/journal/v9/n4/full/nmeth.1923.htm&#34;&gt;Langmead and Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/14/1754.long&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/5/589&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2013 | BWA-MEM - &lt;a href=&#34;http://arxiv.org/abs/1303.3997&#34;&gt;Li&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Bioinformatics Algorithms - &lt;a href=&#34;http://bioinformaticsalgorithms.com&#34;&gt;Compeau and Pevzner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Johns Hopkins Computational Genomics Course - &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;Langmead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexing-and-substrings&#34;&gt;Indexing and substrings&lt;/h3&gt;

&lt;p&gt;Indexing is not a new idea. Most books have an index where a word is &lt;em&gt;mapped&lt;/em&gt; back to a page where it is found. This particular type of index is called &lt;em&gt;inverted index&lt;/em&gt;. The word &lt;em&gt;inverted&lt;/em&gt; implies that there is also a non-inverted or &lt;em&gt;forward&lt;/em&gt; index. The image below explain the distinction between the two:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/inverted_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Inverted index.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/forward_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Forward index. (From &lt;a href=&#34;https://en.wikipedia.org/wiki/Search_engine_indexing&#34;&gt;Wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For what we are interested in (searching for the best location of a read in the reference genome) we will use &lt;em&gt;inverted index&lt;/em&gt;. We will refer to it simply as &lt;em&gt;index&lt;/em&gt;. So to find a pattern in string using an index we first need to create that index. To create an index for a string &lt;em&gt;T&lt;/em&gt; (i.e., a genome) we will need to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings of length &lt;em&gt;L&lt;/em&gt; and record where these substrings occur;&lt;/li&gt;
&lt;li&gt;organize the list of substrings and their coordinates and an easily accessible data structure (a &lt;em&gt;map&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/create_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now that we&amp;rsquo;ve created an index for text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;CGTGCCTACTTACTTACAT&lt;/code&gt; we might as well search it. Suppose we now want to find whether a pattern &lt;code&gt;CTACTTAC&lt;/code&gt; (we will refer to pattern as to &lt;em&gt;P&lt;/em&gt;) is present in &lt;em&gt;T&lt;/em&gt;. To do this we need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings from &lt;em&gt;P&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;check the index to see if they are present;&lt;/li&gt;
&lt;li&gt;if they are present extend to see if the entire string is matching.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/search_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looking for &lt;em&gt;P&lt;/em&gt; in &lt;em&gt;T&lt;/em&gt;. The first three substrings don&amp;rsquo;t have a match. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the figure above you can see that trying various substrings from &lt;em&gt;P&lt;/em&gt; yields three failures and a success with two hits. Of course in our case the &lt;em&gt;T&lt;/em&gt; is very short and you can easily see that an index for a realistic fragment of DNA can be very large. For example, an index for human chromosome 1 (~249,000,000 nucleotides) will occupy over 12 GB of space. In these cases a practical solution may be skipping some of the substrings while making the index. For instance, including only every 4th substring (i.e., using interval of &lt;em&gt;4&lt;/em&gt;) in a human chromosome 1 index will reduce memory usage to a peak of ~8Gb.&lt;/p&gt;

&lt;p&gt;As one can see finding patterns in text using indexes requires finding values for parameters such as substring length and the interval (if we use skipping). These value have significant implications to the speed of the search, memory use, and , importantly, to specificity. The following table shows how choosing different values for substring length and interval affect speed, memory footprint, and specificity for finding pattern&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCGGG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;within human chromosome 1 (data from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Substring length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Interval&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Indexing time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Search time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Memory usage (Gb)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Specificity (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~7.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63.74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~5.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.26&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.52&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~3.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.11&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~2.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~1.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.72&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Specificity can be thought of as a proxy for the number of times an index hit can be extended to a true match between &lt;em&gt;T&lt;/em&gt; and &lt;em&gt;P&lt;/em&gt;. The figure below explain this idea:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/specificity.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Specificity. Matching &lt;code&gt;ord&lt;/code&gt; to &lt;code&gt;time_for_such_a_word&lt;/code&gt;. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;here we look for pattern &lt;code&gt;ord&lt;/code&gt; within text &lt;code&gt;time_for_such_a_word&lt;/code&gt;. The first index hit does not produce a match, while the second does. Decreasing the number of fruitless hits increases specificity and speeds up the search. Intuitively, this is achieved by increasing the substring length.&lt;/p&gt;

&lt;p&gt;In summary, we have seen that we can create an index (a map) containing coordinates of substrings from a text &lt;em&gt;T&lt;/em&gt;. We can then use this map to find occurrences (if they exist) of pattern &lt;em&gt;P&lt;/em&gt; within the &lt;em&gt;T&lt;/em&gt;. The map can be represented in variety of ways including sorted lists, hash tables, and trees:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sorted_list.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sorted list&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/hash.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hash&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Trie&lt;/p&gt;

&lt;p&gt;Sorted list (top), Hash (middle), and Trie (bottom). From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Trie#/media/File:Trie_example.svg&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What&amp;rsquo;s important here is that sorted lists and especially hash tables provide a quick way to find the initial hit, but they are limited by the choice of the substring size. We&amp;rsquo;ve seen before (the &lt;em&gt;Specificity&lt;/em&gt; table above) that the choice of substring size will have profound effects on the performance of the search. Would it be nice if we would not need to make that choice. For this we will continue to &lt;em&gt;Tries and Trees&lt;/em&gt; below.&lt;/p&gt;

&lt;h3 id=&#34;tries-and-trees&#34;&gt;Tries and trees&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s consider text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;gtccacctagtaccatttgt&lt;/code&gt;. Using the logic from previous section we can build an index using substrings of length 2 with interval 2 (skipping every other substring) that would look like this after sorting:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Substring&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Offset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ac&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ag&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;at&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ct&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ta&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;tt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Representing this sorted list as a &lt;em&gt;trie&lt;/em&gt; that would map substrings to their positions (offsets) will look like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/substring_trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A trie. Example from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that this &lt;em&gt;trie&lt;/em&gt; is the smallest tree (&lt;a href=&#34;http://stackoverflow.com/questions/4737904/difference-between-tries-and-trees&#34;&gt;&lt;em&gt;trie&lt;/em&gt; versus &lt;em&gt;tree&lt;/em&gt;&lt;/a&gt; is indeed a bit confusing) representing a collection of substrings that has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet (in this case &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt;, and &lt;code&gt;T&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each &lt;em&gt;key&lt;/em&gt; (substrings of length 2 in the above case) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While the above example shows how we can quickly find positions for a given substring, it still relies on a fixed substring length. To see how we can deal with this limitation let&amp;rsquo;s introduce the idea of indexing with &lt;em&gt;suffixes&lt;/em&gt; rather than with fixed substrings. Consider the following text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG&lt;/code&gt;. Let&amp;rsquo;s add a special symbol &lt;code&gt;$&lt;/code&gt; to the end of this text. For &lt;em&gt;T$&lt;/em&gt; a list of all substrings will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG$
 TTATAGCTGATCGCGGCGTAGCGG$
  TATAGCTGATCGCGGCGTAGCGG$
   ATAGCTGATCGCGGCGTAGCGG$
    TAGCTGATCGCGGCGTAGCGG$
     AGCTGATCGCGGCGTAGCGG$
      GCTGATCGCGGCGTAGCGG$
       CTGATCGCGGCGTAGCGG$
        TGATCGCGGCGTAGCGG$
         GATCGCGGCGTAGCGG$
          ATCGCGGCGTAGCGG$
           TCGCGGCGTAGCGG$
            CGCGGCGTAGCGG$
             GCGGCGTAGCGG$
              CGGCGTAGCGG$
               GGCGTAGCGG$
                GCGTAGCGG$
                 CGTAGCGG$
                  GTAGCGG$
                   TAGCGG$
                    AGCGG$
                     GCGG$
                      CGG$
                       GG$
                        G$
                         $
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Recall that a trie has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet;&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each substring (in this case a suffix) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s now use these rules to build a suffix trie for a much simpler text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;abaaba&lt;/code&gt;. It is much smaller than the text we used above and so it will be easier to get the point across. First, let&amp;rsquo;s add &lt;code&gt;$&lt;/code&gt; and create a list of all suffixes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
baaba$
aaba$
aba$
ba$
a$
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;now let&amp;rsquo;s create a trie:&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-trie&#34;&gt;Looking for substrings in a Trie&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The green path shows the longest suffix (the entire thing). The blue path is the shortest suffix containing only the terminal character.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie_no_end.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note, that the trie would look &lt;strong&gt;dramatically&lt;/strong&gt; different had we not added the &lt;code&gt;$&lt;/code&gt; at the end. The difference is that without the &lt;code&gt;$&lt;/code&gt; the trie will &lt;strong&gt;not&lt;/strong&gt; have every suffix to be represented by a path from &lt;code&gt;root&lt;/code&gt; to a leaf.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In suffix trie every edge is labeled with a single character and nodes have no labels in our representation. However, you can think of every node as being labelled with a string that spells out all characters occurring along a path from the root up to the that node. For example, the blue node &lt;code&gt;baa&lt;/code&gt; spells out characters &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;a&lt;/code&gt; along a path from the root.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Suffix trie is an ideal data stricture to quickly check if a pattern is or is not present in a text. The following three examples highlight how this can be done. Suppose we want to check if a substring &lt;code&gt;baa&lt;/code&gt; is present within text &lt;code&gt;abaaba&lt;/code&gt; represented as our suffix trie. We start at the root and take an edge labeled with &lt;code&gt;b&lt;/code&gt;. We next proceed through an edge labeled &lt;code&gt;a&lt;/code&gt;. At this point there are two outgoing edges: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt;. Since the last character in &lt;code&gt;baa&lt;/code&gt; is &lt;code&gt;a&lt;/code&gt; we take the edge labeled as &lt;code&gt;a&lt;/code&gt;. Because the entire substring &lt;code&gt;baa&lt;/code&gt; can be spelled out as a path from the root we conclude that &lt;code&gt;baa&lt;/code&gt; is indeed a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s do the same for &lt;code&gt;abaaba&lt;/code&gt;. Proceeding along the green path spells out all characters. Again, we conclude that &lt;code&gt;abaaba&lt;/code&gt; is valid substring. |&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But for &lt;code&gt;baabb&lt;/code&gt; things look different. We proceed successfully (red path) through &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt;. However, there is no edge labeled &lt;code&gt;b&lt;/code&gt; at &lt;code&gt;baab&lt;/code&gt; node. Thus we fall off and conclude that &lt;code&gt;baabb&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can also use suffix trie to check if a string is a suffix of a text. You can see that &lt;code&gt;baa&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a suffix. This is because although it is valid substring, which traces a path through the trie, such path does not with an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here &lt;code&gt;aba&lt;/code&gt; is a suffix because one of the outgoing edges from the final node is labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another useful feature of suffix trie is the ability to tell how many times a particular substring if found in a text. Here &lt;code&gt;aba&lt;/code&gt; is found twice as the last edge of a path spelling &lt;code&gt;aba&lt;/code&gt; leads to a node (&lt;code&gt;n&lt;/code&gt;) with two outgoing edges.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, similar logic allows to find the longest repeated substrings within a text. A deepest (furthest from the root) node with multiple outgoing edges wound point to a repetitive substring. Here &lt;code&gt;aba&lt;/code&gt; is the longest repeated substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now that we explained how suffix tries can be used to find substrings in text, let&amp;rsquo;s reduce non-branching paths in tries and convert them to trees:&lt;/p&gt;

&lt;h3 id=&#34;from-a-trie-to-a-tree&#34;&gt;From a Trie to a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we collapse all non-branching paths and concatenate their labels we will get:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, let&amp;rsquo;s label every leaf of the tree with offset (position in the text) of the corresponding suffix:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Collapsing non-branching paths has given us a somewhat more compact data structure. Now see how we can use this data structure.&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-tree&#34;&gt;Looking for substrings in a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Checking the above suffix tree to see if &lt;code&gt;baa&lt;/code&gt; is a substring of the text. The logic is exactly the same as with suffix tries, except we now have to account for the fact that along some edges only a portion of the characters within a label will match. In this case matching characters are highlighted with uppercase: &lt;code&gt;BA&lt;/code&gt; matches along the first edge along the blue path, and only &lt;code&gt;A&lt;/code&gt; matches along the second edge. The conclusion is that &lt;code&gt;baa&lt;/code&gt; is a substring of the text.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s see if &lt;code&gt;aba&lt;/code&gt; is a suffix of our text. It matches along the blue path and the last node along this path has an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;. Thus it is a suffix.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And just like with suffix tries we can count occurrences of a substring by counting the number of outgoing edges from the last node.&lt;/p&gt;

&lt;h3 id=&#34;application-of-suffix-trees&#34;&gt;Application of suffix trees&lt;/h3&gt;

&lt;p&gt;One of the common applications of suffix trees to the genome data analysis is finding (longest) common subsequences between two sequences. &lt;a href=&#34;http://mummer.sourceforge.net/manual/&#34;&gt;MUMMER&lt;/a&gt; implements this approach. The following plot shows a comparison between &lt;em&gt;E. coli&lt;/em&gt; K12 and APEC O1 strains. It is computed in 8 seconds using approximately 10 Mb of RAM (K12 and APEC O1 genomes are 4.5 and 4.9. Mb, respectively).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/mum.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To find longest common subsequences a suffix tree can be constructed from both sequences at once as shown in the following slide from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/suffix_trees.pdf&#34;&gt;Ben Langmead&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lcs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While suffix trees allow sequence comparisons to be performed in nearly linear time, they have large memory footprint. At some point this becomes a serious limitation making the use of suffix trees impractical. For example, indexing human genome will require ~47 Gb of memory.&lt;/p&gt;

&lt;h3 id=&#34;suffix-arrays&#34;&gt;Suffix arrays&lt;/h3&gt;

&lt;p&gt;Suffix array offers a more compact solution to representing test suffixes. It specified a lexicographic ordering of suffixes derived from text &lt;em&gt;T&lt;/em&gt;$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sa.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A suffix array. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Because one does not need additional pointers required for tree representation, the suffix array (SA) has a significantly smaller memory footprint. For example, SA for human genome will occupy ~12Gb (down from 47Gb required for a suffix tree). Yet there is an even better idea.&lt;/p&gt;

&lt;h2 id=&#34;burrows-wheeler-transform-and-fm-index&#34;&gt;Burrows-Wheeler Transform and FM index&lt;/h2&gt;

&lt;p&gt;Burrows-Wheeler (BW) transform is a reversible permutation of a string. For example, for a string:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create all rotations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
ba$abaa
aba$aba
aaba$ab
baaba$a
abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sort them lexicographically with &lt;code&gt;$&lt;/code&gt; as first character:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
aaba$ab
aba$aba
abaaba$
ba$abaa
baaba$a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;take the last column. It will be the BWT of the original string &lt;code&gt;abaaba$&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abba$aa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is the entire procedure as one slide:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184566773&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;It has three important features that make it ideas for creating searchable compact representations of genomic data:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It can be compressed&lt;/li&gt;
&lt;li&gt;It can be reversed to reconstruct the original string&lt;/li&gt;
&lt;li&gt;It can be used as an index&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;lf-mapping-of-burrows-wheeler-matrix-bwm&#34;&gt;LF mapping of Burrows-Wheeler Matrix (BWM)&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s take the original string &lt;code&gt;abaaba&lt;/code&gt; add &lt;code&gt;$&lt;/code&gt; and list charters ranks:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;3&lt;/sub&gt;$&lt;/p&gt;

&lt;p&gt;This ranking is done based on the order of the characters in the text (T-ranking). The order of ranked characters is preserved between the first column (F) and the last column (L):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s now rank characters in order of their appearance in the sorted list of rotations (B-ranking):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw_b_rank.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform with B-rankings. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Look at the A very important implication of this is that we can quickly jump from L to F:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/f_from_l.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;L/F jumping. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-1&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184569791&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;reversing-btw&#34;&gt;Reversing BTW&lt;/h3&gt;

&lt;p&gt;Because of the LF mapping property was can also easily reconstruct original text from its BWT:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Reversing BWT. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-2&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568361&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;searching-bwt&#34;&gt;Searching BWT&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try to find is the string &lt;code&gt;aba&lt;/code&gt; is present in a &amp;ldquo;genome&amp;rdquo; stored as a BWT.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We start with suffix of $ab\color{red}a$ shown in red. This gives us a range of characters in the F column (all &lt;strong&gt;a&lt;/strong&gt;s)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We now extend to $a\color{red}{ba}$ and see how many of &lt;strong&gt;a&lt;/strong&gt;s have preceding &lt;strong&gt;b&lt;/strong&gt;s:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally we extend to the entire string $\color{red}{aba}$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This tells us the range [3,5) but, as opposed to suffix array, this does not tell us where these matches occur in the actual sequence. We will come back to this problem shortly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The shide below shows what happens when a match is &lt;strong&gt;not&lt;/strong&gt; present in the &amp;ldquo;genome&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Querying BWT. Images from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/bwt_and_fm_index.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-3&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568259&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;practicalities-of-using-bwt&#34;&gt;Practicalities of using BWT&lt;/h3&gt;

&lt;p&gt;As we have seen BWT is &lt;strong&gt;very&lt;/strong&gt; compact but has few shortcomings such as, for example, the difficulty is seeing where the matches are in the actual genome as well as some performance limitations. Combining BWT with auxiliary data structures creates &lt;a href=&#34;https://en.wikipedia.org/wiki/FM-index&#34;&gt;FM-index&lt;/a&gt; (where FM stands for Full-text index in Minute space; curiously, the names of FM-index creators are &lt;a href=&#34;http://dl.acm.org/citation.cfm?id=796543&#34;&gt;Ferrigina and Manzini&lt;/a&gt;). The components of FM-index used for aligning reads to a genome are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  BWT               Tally        Check    
                                 points 

  F       L         a b          a b       SA    
  ---------        -----        -----     ----       
  $ abaab a         1 0          1 0       6 $
  a $abaa b         1 1                    5 a$
  a aba$a b         1 2                    2 aaba$
  a ba$ab a         2 2          2 2       3 aba$
  a baaba $         2 2                    0 abaaba$
&amp;gt; b a$aba a         3 2                    4 ba$
  b aaba$ a         4 2          4 2       1 baaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where:&lt;/p&gt;

&lt;h4 id=&#34;bwt&#34;&gt;BWT&lt;/h4&gt;

&lt;p&gt;BWT - the BWT (L column from above) is stored and the first column (F) can be easily reconstructed as it is simply a list of all characters (4 in the case of DNA) and their counts.&lt;/p&gt;

&lt;h4 id=&#34;tally&#34;&gt;Tally&lt;/h4&gt;

&lt;p&gt;Because we do not explicitly store ranks they can simply be obtained by counting occurrences of individual characters from the top of L column. Yet this is computationally expensive. Instead we store a tally table. At every row of the BWT matrix it shows how many times each character has been seen up to this point. For example at row marked with &lt;code&gt;&amp;gt;&lt;/code&gt; there were 3 As and 2 Bs up to this point. In reality, to save space, only a subset of Tally entries is stored as &lt;em&gt;Checkpoints&lt;/em&gt; recorded in regular intervals as shown above.&lt;/p&gt;

&lt;h4 id=&#34;sa-sample&#34;&gt;SA Sample&lt;/h4&gt;

&lt;p&gt;Finally, to find coordinates of matches in the genome offsets from an SA index are stored as SA sample (actual suffixes are not stored). This allows quickly finding location of a match within the genome by a direct look up. Similarly to Checkpoints only a fraction of these is stored to save space.&lt;/p&gt;

&lt;p&gt;Thus the final list of components is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = integers corresponding to character type counts. In case of DNA four integers: number of As, Cs, Gs, and Ts.&lt;/li&gt;
&lt;li&gt;Last column = the BWT transform. Size is equal to the length of the original text&lt;/li&gt;
&lt;li&gt;Checkpoints = length of text $\times$ number of character types  $\times$ sampling fraction (how sparse rows are sampled)&lt;/li&gt;
&lt;li&gt;SA sample = length of text $\times$ fraction of the rows kept&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For human genome with DNA alphabet of four nucleotides, saving checkpoint every 128&lt;sup&gt;th&lt;/sup&gt; row, and saving SA offsets every 32&lt;sup&gt;nd&lt;/sup&gt; row we will have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = 16 bytes&lt;/li&gt;
&lt;li&gt;Last column = 2bit $\times$ 3 billion characters = 750 MB&lt;/li&gt;
&lt;li&gt;Checkpoints = 3 billion $\times$ 4 bytes/char / 128 &amp;#x2248; 100 MB&lt;/li&gt;
&lt;li&gt;SA sample = 3 billion $\times$ 4 bytes/char /32 &amp;#x2248; 400 MB&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;watch-more&#34;&gt;Watch more&lt;/h3&gt;

&lt;p&gt;As was mentioned in the beginning, this materials follows a series of lectures by Ben Langmead. Below are two of his amazing videos on the subject:&lt;/p&gt;

&lt;h4 id=&#34;bwt-and-its-properties&#34;&gt;BWT and its properties&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/4n7NPk5lwbI&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h4 id=&#34;fm-index-and-its-practical-applications&#34;&gt;FM index and its practical applications&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/kvVGj5V65io&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;next&#34;&gt;Next&lt;/h1&gt;

&lt;p&gt;Enough theory for now. Next time we will start handling actual data&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Aligning sequences with dynamic programming</title>
      <link>http://nekrut.github.io/BMMB554/post/topic4/</link>
      <pubDate>Mon, 19 Sep 2016 10:12:04 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic4/</guid>
      <description>

&lt;h1 id=&#34;sequence-alignment&#34;&gt;Sequence alignment&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen the principle behind dynamic programming. This approach is extremely useful for comparing biological sequences, which is coincidentally one of the main point of this course. This lecture explain how this is done. In writing this text I heavily relied on wonderful &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image shows pairwise alignments for human, mouse, and dog &lt;em&gt;KIF3&lt;/em&gt; locus from &lt;a href=&#34;http://genome.cshlp.org/content/10/9/1304.long&#34;&gt;Dubchak et al. 2000&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-different-are-two-sequences&#34;&gt;How different are two sequences?&lt;/h2&gt;

&lt;p&gt;Suppose you have two sequences of the same length:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How different are they? In other words, how many bases should be change to turn one sequence onto the other:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
| | * * * | * * *
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the vertical lines above indicate positions that are identical between the two sequences, while asterisks show differences. It will take six substitutions to turn one sequence into the other. This number &amp;ndash; six substitutions &amp;ndash; is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamming_distance&#34;&gt;&lt;em&gt;Hamming distance&lt;/em&gt;&lt;/a&gt; or the &lt;em&gt;minimal&lt;/em&gt; number of substitutions required to turn one string into another. The code below computes the Hamming distance. Try it. You can change &lt;code&gt;seq1&lt;/code&gt; and &lt;code&gt;seq2&lt;/code&gt; into whatever you want except that they should have the same length.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/99a02b790a?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now in addition to &lt;em&gt;substitutions&lt;/em&gt; (i.e., changing one character into another) let&amp;rsquo;s allow &lt;strong&gt;instertions&lt;/strong&gt; and &lt;strong&gt;deletions&lt;/strong&gt;. This will essentially allow us to insert dashes (gaps) between characters:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A -
| | * | | | | | | *
A C - T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case the &lt;a href=&#34;https://en.wikipedia.org/wiki/Edit_distance&#34;&gt;&lt;strong&gt;edit distance&lt;/strong&gt;&lt;/a&gt; between two sequences is 2. It is defined as the minimum number of operations (substitutions, insertions, and deletions) requited to turn one string into another. The compared strings do not have to be of the same length to be able to compute the edit distance as we can compensate for length differences using deletions and insertions. While the situation above (where we inserted two dashes) is biologically much more meaningful (and realistic), it is much more difficult to find.&lt;/p&gt;

&lt;h1 id=&#34;generalizing-the-problem&#34;&gt;Generalizing the problem&lt;/h1&gt;

&lt;p&gt;Before we can develop an algorithm that will help us to compute the edit distance let&amp;rsquo;s develop a general framework that would allow us to think about the problem in exact terms. Let&amp;rsquo;s look at a pair of VERY long sequences. So long, that we do not even see the left end &amp;ndash; it disappears into $\infty$:&lt;/p&gt;

&lt;div&gt;
    $$
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ G}\\
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ C}\\
    $$
&lt;/div&gt;

&lt;p&gt;the red parts of the two sequences represent &lt;strong&gt;prefixes&lt;/strong&gt; for the last nucleotides shown in black. Let&amp;rsquo;s assume that the edit distance between the two prefixes is known (don&amp;rsquo;t ask how we know, we just do). For simplicity let&amp;rsquo;s &amp;ldquo;compact&amp;rdquo; the prefix of the first sequence into $\alpha$ and the prefix of the second sequence into $\beta$:&lt;/p&gt;

&lt;div&gt;
    $$
        \alpha \texttt{G}\\
        \beta  \texttt{C}
    $$
&lt;/div&gt;

&lt;p&gt;again, the edit distance between $\alpha$ and $\beta$ is known to us. The three possibilities for computing the edit distance between $\alpha G$ and $\beta C$ are:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{G},\beta\texttt{C})  = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + 1 \leftarrow\ because\ they\ do\ not\ match&amp; \\
                    Edit\ Distance(\alpha\texttt{G},\beta) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap&amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{C}) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;but we not always have $\texttt{G}$ and $\texttt{C}$ as two last nucleotiodes, so for the general case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ (nucleotides match) and $\delta(x,y) = 1$ if $x \neq y$ (nucleotides do not match). The $\delta(x,y)$ has a particular meaning. If the two nucleotides at the end are equal to each other, there is nothing to be done &amp;ndash; no substitution operation is necessary. If a substitution is necessary however, we will record this by adding 1. When we will be talking about global and local alignment below the power of $\delta(x,y)$ will become even more clear.&lt;/p&gt;

&lt;p&gt;Recall the change problem from the previous lecture. We can write an algorithm that would exhaustively evaluate the above expression for all possible suffixes. This algorithm is below. Try executing it. It will take roughly ~30 seconds to find the edit distance between the two sequences used in the beginning of this lecture:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/eff3a798bf?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Again, don&amp;rsquo;t worry if Python looks scary to you. The take-home-message here is that it takes a very long time to compute the edit distance between two sequences that are only &lt;strong&gt;nine&lt;/strong&gt; nucleotides long! Why is this happening? Figure 1 below shows a small subset of situations the algorithm is evaluating for two very short strings $\texttt{TAG}$ and $\texttt{TAC}$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/editDist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | A fraction of situations evaluated by the naïve algorithm for computing the edit distance. Just like in the case of the change problem discussed in the previous lecture a lot of time is wasted on computing distances between suffixes that has been seen more than once (shown in red).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To understand the magnitude of this problem let&amp;rsquo;s look at slightly modified version of the previous Python code below. All we do here is keeping track how many times a particular pair of suffixes (in this case $\texttt{AC}$ and $\texttt{AC}$) are seen by the program. The number is staggering: 48,639. So this algorithm is &lt;strong&gt;extremely&lt;/strong&gt; wasteful.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/8994bfe46e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;While this approach to the edit distance problem is correct, it will hardly help us on the genome-wide scale. Just like in case of the change problem and Manhattan tourist problem dynamic programming is going to save the day.&lt;/p&gt;

&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583352&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;dynamic-programming-to-the-rescue&#34;&gt;Dynamic programming to the rescue&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s recall Manhattan tourist problem. The objective of the problem was to find a path through Manhattan that visits the highest number of landmarks. If you remember, we represented Manhattan as a matrix where each edge was representing a block and was labeled with the number of landmarks within that block. Here, we will use a similar idea to find an optimal &lt;strong&gt;alignment&lt;/strong&gt; between two sequences. Note that so far this is the first time we use the term &lt;strong&gt;alignment&lt;/strong&gt; in this section. It turns out that in order to find the alignment we first need to learn how to compute edit distances between sequences efficiently. So, suppose we have two sequences that deliberately have different lengths:&lt;/p&gt;

&lt;p&gt;$\texttt{G C T A T A C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G C G T A T G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s represent them as the following matrix where the first character $\epsilon$ represents an empty string:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon\\
                    \hline
                    G\\
                    \hline
                    C\\
                    \hline
                    G\\
                    \hline
                    T\\
                    \hline
                    A\\
                    \hline
                    T\\
                    \hline
                    G\\
                    \hline
                    C

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s fill the first column and first raw of the matrix. Because the distance between a string and an empty string is equal to the length of the string (e.g., a distance between string $\texttt{TAG}$ and an empty string is 3) this resulting matrix will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; 1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Now, let&amp;rsquo;s fill in the cell between $\texttt{G}$ and $\texttt{G}$. Recall that:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ and $\delta(x,y) = 1$ if $x \neq y$. And now let&amp;rsquo;s color each of the cells corresponding to each part of the above expression:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;In this specific case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\epsilon\texttt{G},\epsilon\texttt{G}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\epsilon,\epsilon) + \delta(G,G)\ or\ 0\ +\ 0\ =\ 0} &amp; \\
                    \color{blue}{Edit\ Distance(\epsilon\texttt{G},\epsilon) + 1\ or\ 1\ +\ 1\ =\ 2} &amp; \\
                    \color{green}{Edit\ Distance(\epsilon,\epsilon\texttt{G}) + 1\ or\ 1\ +\ 1\ =\ 2}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This minimum of 0, 2, and 2 will be 0, so we are putting zero into that cell:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C \\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1 &amp; \color{red}0\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Using this uncomplicated logic we can fill the entire matrix like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;The lower rightmost cell highlighted in red is special. It contains the value for the edit distance between the two strings. The following Python script implements this idea. You can see that it is essentially instantaneous:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/1bec8f9150?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;video-1&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583042&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;from-edit-distance-to-alignment&#34;&gt;From edit distance to alignment&lt;/h1&gt;

&lt;p&gt;In the previous section we have filled the dynamic programming matrix to find out that the edit distance between the sequences is 2. But in biological applications we are most often interested not in edit distance &lt;em&gt;per se&lt;/em&gt; but in the actual &lt;strong&gt;alignment&lt;/strong&gt; between two sequences.&lt;/p&gt;

&lt;h2 id=&#34;the-traceback&#34;&gt;The traceback&lt;/h2&gt;

&lt;p&gt;We can use the dynamic programming matrix to reconstruct the alignment. This is done using &lt;strong&gt;traceback&lt;/strong&gt; procedure. Let&amp;rsquo;s look at the rightmost bottom cell of the matrix highlighted in &lt;strong&gt;bold&lt;/strong&gt;:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \textbf{2}

 \end{array}

    $$
&lt;/div&gt;

&lt;p&gt;When we were filling this matrix did we come to this point from above ($\color{green}3$), from the left ($\color{blue}3$), or diagonally ($\color{red}2$):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ | c | c }
                \hline
                   \color{red}2 &amp; \color{green}3\\
                \hline
                   \color{blue}3 &amp; \textbf{2}
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Remembering the fact that when filling the matrix we are trying to minimize the expression for edit distance, we clearly arrived to this point diagonally from $\color{red}2$. This because arriving from top ($\color{green}3$) or left ($\color{blue}3$) would add 1. So we highlight diagonal cell in red:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Continuing this idea we will draw a trace like the one below until we hit an interesting point:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;At this point we have arrived to this value from the top because 0 + 1 = 1. If we were arriving diagonally it would be 1 + 1 = 0 since $\texttt{G}\ \neq\ \texttt{C}$, so we are turning traceback upward and then again diagonally:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Now going through traceback line from the top we are getting the following alignment between two two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;G C - T A T A C
| | * | | | * |
G C G T A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approximate-matching&#34;&gt;Approximate matching&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now get a bit more practical. In many real biological applications we are trying to see if one sequence is contained within another. So, how can we use dynamic programming to find if there is an approximate match between two sequences $\it\texttt{P}$ and $\texttt{T}$?&lt;/p&gt;

&lt;p&gt;Suppose we have two strings:&lt;/p&gt;

&lt;p&gt;$\it{T} = \texttt{A A C C C T A T G T C A T G C C T T G G A}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{P} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s construct the following matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                               \\
                    \hline
                              T\\
                    \hline
                              A\\
                    \hline
                              C\\
                    \hline
                              G\\
                    \hline
                              T\\
                    \hline
                              C\\
                    \hline
                              A\\
                    \hline
                              G\\
                    \hline
                              C\\

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{T}\ is\ horizontal\ while\ \texttt{P}\ is\ vertical.

 $$

&lt;/div&gt;

&lt;p&gt;Let me remind you that our goal is to find where $\it\texttt{P}$ matches $\texttt{T}$. &lt;em&gt;A priori&lt;/em&gt; we do not know when it may be, so we will start by filling the entire first row with zeroes. This is because the match between $\it\texttt{P}$ and $\texttt{T}$ may start at any point up there. The first column we will initialize the same way we did previously: with increasing sequence of numbers:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                         T &amp; 1\\
                    \hline
                         A &amp; 2\\
                    \hline
                         C &amp; 3\\
                    \hline
                         G &amp; 4\\
                    \hline
                         T &amp; 5\\
                    \hline
                         C &amp; 6\\
                    \hline
                         A &amp; 7\\
                    \hline
                         G &amp; 8\\
                    \hline
                         C &amp; 9\\

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now let&amp;rsquo;s fill this matrix in using the same logic we used before:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now that we have filled in the complete matrix let&amp;rsquo;s look at the bottom row. Instead of using the rightmost cell we will find a cell with the lowest number. That would be 2 (highlighted in red):&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Starting already familiar traceback procedure at that cell we will get the following path through the matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;for a corresponding alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A A C C C T A T G T C A T G C C T T G G A
          | | * | | | | * | | 
          T A C G T C A - G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;video-2&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183587535&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;global-alignment&#34;&gt;Global alignment&lt;/h2&gt;

&lt;p&gt;So far in filling the dynamic programming matrix we were using the following expression to compute the number within each cell:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;Basically we were adding 1 if there was a mismatch (the $\delta$ function) and also adding 1 for every gap. This however is not biologically realistic. If we look at the rates of different rates of mutations in the human genome we will see that they vary dramatically. Let&amp;rsquo;s look at substitutions first:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/TsTv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | There are two kinds of nucleotide substitutions: Transitions and Transversions. Transitions are substitutions between nucleotides belonging to the same chemical group. For example, a substitution of Adenine, a purine, to Guanine, also a purine, is a transition. Transversions, on the other hand, occur between chemically dissimilar nucleotides. For example, any substitution of a purine to a pyrimidine and vice verse will be a transition. (Image from &lt;a href=&#34;https://en.wikipedia.org/wiki/Transversion&#34;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;you can see that there are move ways in which we can have a transversion. Despite this fact transversions are significantly less frequent that transitions. In fact in human the so called &lt;em&gt;Transition/Transversion ratio&lt;/em&gt; ($Ts:Tv$) is close to &lt;a href=&#34;http://www.pnas.org/content/107/3/961.long&#34;&gt;2&lt;/a&gt; (or even higher in &lt;a href=&#34;http://genomebiology.biomedcentral.com/articles/10.1186/gb-2011-12-9-r84&#34;&gt;coding regions&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The situation with insertions and deletions (that are often called &lt;em&gt;indels&lt;/em&gt;) is similar in that are relatively rare and their rarity increases with size. A single nucleotide indel may occur every 1,000 bases on average, while a two-nucleotide deletion occurs every 3,000 bases and so on (see &lt;a href=&#34;http://genome.cshlp.org/content/23/5/749.abstract&#34;&gt;Montgomery et al. 2013&lt;/a&gt; for a more detailed statistics).&lt;/p&gt;

&lt;p&gt;As a result it is simply unrealistic to use &amp;ldquo;1&amp;rdquo; is all cases. Instead, we need to &lt;em&gt;penalize&lt;/em&gt; rare events more than we penalize frequent, more probable events. Let&amp;rsquo;s create a &lt;em&gt;penalty matrix&lt;/em&gt; to achieve this goal:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; \color{orange}8\\  
                   C &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{orange}8\\
                   G &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{orange}8\\
                   T &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{orange}8\\
                   - &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Here if two nucleotides match, the penalty is 0. For a transitional substitution we pay $\color{red}2$ and for a transversional we pay $\color{blue}4$. The gap is the most expensive at $\color{orange}8$.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\it{X} = \texttt{T A T G T C A T G C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{Y} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;First, we need to fill the following dynamic programming matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                    \epsilon \\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;But now we using penalty matrix generated above to calculate values in each cell. Specifically, before we were using this expression:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$
&lt;/div&gt;

&lt;p&gt;but now, we will change it into this:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    D(\alpha,\beta) + p\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + p\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + p\texttt{(-,y)}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $p\texttt{(x,y)}$, $p\texttt{(x,-)}$, and $p\texttt{(-,y)}$ are taken directly from penalty matrix. Let&amp;rsquo;s start with the first row. In this row we can only fill from the left were we essentially inserting a gap every time. Since the gap penalty is 8 we will get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Similarly, for the first column we get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8\\
                    \hline
                           A &amp; 16\\
                    \hline
                           C &amp; 24\\
                    \hline
                           G &amp; 32\\
                    \hline
                           T &amp; 40\\
                    \hline
                           C &amp; 48\\
                    \hline
                           A &amp; 56\\
                    \hline
                           G &amp; 64\\
                    \hline
                           C &amp; 72

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;and finally the full matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; 2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; 10 &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; 10

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Drawing a traceback through this matrix will give us:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; \color{red}{10} &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; \color{red}{10} &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; \color{red}{10}

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the following alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T A C G T C A - G C
| | * | | | | * | | 
T A T G T C A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following Python code implements Global alignment approach we have seen above. Note that the first function, &lt;code&gt;exampleCost&lt;/code&gt;, can be changed to set different value for the penalty matrix. You can play with it here:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/911a7ddd2e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;local-alignment&#34;&gt;Local alignment&lt;/h2&gt;

&lt;p&gt;Global alignment discussed above works only in cases when we truly expect sequences to match across their entire lengths. In majority of biological application this is rarely the case. For instance, suppose you want to compare two bacterial genomes to figure out if they have matching sequences. Local alignment algorithm helps with this challenge. Surprisingly, it is almost identical to the approaches we used before. So here is our problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sequence 1: ##################################################
                              |||||||||||||||||
Sequence 2:         #################################################
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;there are two sequences (shown with # characters) and they share a region of high similarity (indicated by vertical lines). How do we find this region? We cannot use global alignment logic here because across the majority of their lengths these sequences are dissimilar.&lt;/p&gt;

&lt;p&gt;To approach this problem we will change our penalty strategy. Instead of giving a high value for each mismatch we will instead give negative penalties. Only matches get positive rewards. Here is an example of such &lt;em&gt;scoring matrix&lt;/em&gt; (as opposed to the &lt;em&gt;penalty matrix&lt;/em&gt; we&amp;rsquo;ve used before):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; \color{orange}{-6}\\  
                   C &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4}  &amp; \color{orange}{-6}\\
                   G &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4}  &amp; \color{orange}{-6}\\
                   T &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4}  &amp; 2 &amp; \color{orange}{-6}\\
                   - &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Our scoring logic will also change:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = max\begin{cases} 
                    D(\alpha,\beta) + s\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + s\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + s\texttt{(-,y)} &amp; \\
                    0
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;We are now looking for &lt;strong&gt;maximum&lt;/strong&gt; and use &lt;em&gt;0&lt;/em&gt; to prevent having negative values in the matrix. This also implies that the first row and column will now be filled with zeros. Let apply this to two sequences:&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\texttt{T A T A T G C G G C G T T T}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G G T A T G C T G G C G C T A}$&lt;/p&gt;

&lt;p&gt;Dynamic programming matrix with initialized first row and column will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\ 
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\
                   
\end{array}

\\

\textbf{Remember}: sequence\ \texttt{X}\ is\ vertical\ while\ \texttt{Y}\ is\ horizontal.


    $$
&lt;/div&gt;

&lt;p&gt;Filling it completely will yield the following matrix. Note that clues to where the local alignment may be are given off by positive numbers in the sea of 0s:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;To identify to boundary of the local alignment we need to identify the cell with the &lt;strong&gt;highest&lt;/strong&gt; value. This cell has value of $\color{red}{12}$ and is highlighted above. Using traceback procedure we will find:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; \color{red}6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; \color{red}8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the best local alignment between the two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; T A T A T G C - G G C G T T T
     | | | | | * | | | |
 G G T A T G C T G G C G C T A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a Python representation of this approach:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/aa05b81499?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;This algorithm was developed by &lt;a href=&#34;http://dornsife.usc.edu/assets/sites/516/docs/papers/msw_papers/msw-042.pdf&#34;&gt;Temple Smith and Michael Waterman&lt;/a&gt; in 1981. This is why it is most often called Smith Waterman local alignment algorithm.&lt;/p&gt;

&lt;h2 id=&#34;video-3&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183588416&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;next&#34;&gt;Next&amp;hellip;&lt;/h1&gt;

&lt;p&gt;In the next lecture we will learn about speeding sequence searches with indexing and talk about mappers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sequence alignment: Introductory concepts</title>
      <link>http://nekrut.github.io/BMMB554/post/topic3/</link>
      <pubDate>Mon, 12 Sep 2016 10:43:18 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic3/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen several ways in which DNA sequence data can be accumulated (the reason for having Manhattan in the figure above will be apparent a bit later). Because sequencing machines (especially the ones made by Illumina) generate billions of sequences (called reads) from every run, the real challenge is what one does with all this data once sequencing is done. So before we get into details of technology and its application we need to introduce some basic algorithmic concepts related to sequence analysis. Today we will start with &lt;strong&gt;dynamic programming&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-the-change-problem&#34;&gt;Dynamic programming for the change problem&lt;/h2&gt;

&lt;p&gt;When introducing algorithmic concepts to biological audience it often becomes critical to use good examples. One of the people who probably succeeded most in this endeavor is &lt;a href=&#34;http://cseweb.ucsd.edu/~ppevzner/&#34;&gt;Pavel Pevzner&lt;/a&gt;, a Ronald R. Taylor Professor of Computer Science at UCSD, who (together with &lt;a href=&#34;http://compeau.cbd.cmu.edu/&#34;&gt;Phillip Compeau&lt;/a&gt;) published a very informatics (and entertaining) &lt;a href=&#34;https://www.amazon.com/Bioinformatics-Algorithms-Active-Learning-Approach/dp/0990374602&#34;&gt;book&lt;/a&gt; on the subject of computational biology. The example I use below comes from this book.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Suppose you are a cashier who&amp;rsquo;s job is, generally speaking, to receive money and to give out change. Suppose that someone buys something that costs \$9.37 and gives you a 10 dollar bill. You need to give \$0.63 back in smallest possible number of coins. The US coin denominations are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100 (1 dollar)&lt;/li&gt;
&lt;li&gt;50 (half-dollar)&lt;/li&gt;
&lt;li&gt;25 (quarter)&lt;/li&gt;
&lt;li&gt;10 (dime)&lt;/li&gt;
&lt;li&gt;5 (nickel)&lt;/li&gt;
&lt;li&gt;1 (penny)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, given these coins you will:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;start with the largest coin smaller than the amount you need to give back = &lt;strong&gt;50 Cents&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;repeat for the remaining $0.13 and select &lt;strong&gt;10 Cents&lt;/strong&gt;  (&lt;strong&gt;NOTE&lt;/strong&gt;: this is recursion happening)&lt;/li&gt;
&lt;li&gt;finish with three 1 cent counts thus you ended up with 5 (&lt;strong&gt;50&lt;/strong&gt; + &lt;strong&gt;10&lt;/strong&gt; + 3x&lt;strong&gt;1&lt;/strong&gt;) coins.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;solving-problem-exhaustively&#34;&gt;Solving problem exhaustively&lt;/h3&gt;

&lt;p&gt;Now (as suggested &lt;a href=&#34;http://interactivepython.org/runestone/static/pythonds/Recursion/DynamicProgramming.html&#34;&gt;here&lt;/a&gt;) suppose you are a cashier in a strange country where there is also a &lt;strong&gt;21&lt;/strong&gt; cent coin in circulation. By using the algorithm above you will still give your customer 5 coins, while the &amp;ldquo;correct&amp;rdquo; solution will certainly be giving him/her 3 &lt;strong&gt;21&lt;/strong&gt; cent coins. So the algorithm we used above simply does not work.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s rephrase the problem. The smallest number of coins summing up to $0.63 cents (in our strange country with a &lt;strong&gt;21&lt;/strong&gt; cent coin) will be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.62 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.58 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.53 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.42 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.38 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.13 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | First iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next, for each of these possibilities we will repeat this again. For example for $0.62 will consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.61 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.57 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.52 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.41 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.37 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.12 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | Second iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And again. For $0.58 we will have:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt; | Note that amounts highlighted in red are repeated. Below we explain why this is &lt;strong&gt;really bad&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and so on. Basically, as every iteration we are trying to find:&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 21) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                         &amp; \\ 1 + numCoins(original\_amount - 50) 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;While this algorithm will find us the smallest number of coins necessary to give out a particular amount in change, it does this at a horrific price: it is extremely inefficient as it recomputes all possibilities at every iteration. For instance, if we ask the algorithm to compute the minimal number of coins necessary to give out 63 cents in change in a country with only four coins (1, 5, 10, and 25 cents) it will take &lt;strong&gt;67,716,925&lt;/strong&gt; iterations (recursive calls). As a result you will probably loose all of your customers while they are waiting for the change.&lt;/p&gt;

&lt;p&gt;The code snippet below implements this algorithm (do not worry if you don&amp;rsquo;t quire understand python. It is OK for now). If you execute it (press the play button) your browser will likely crash as it will get tired waiting for result to come back (try it anyway):&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/a74fb5b988?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;caching-helps-a-bit&#34;&gt;Caching helps a bit&lt;/h3&gt;

&lt;p&gt;One potential way to solve our problem in a reasonable amount of time is to take advantage of red nodes shown in Figure 3. What if before calling the function we check if a minimum number of coins for a particular amount was already computed? Apparently this speeds things up quite dramatically:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/efcc5b3667?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now you can see that it takes under a second to find that it takes 3 coins to give 63 cents in change in a country with 1, 5, 10, 21, and 25 cent coins. Yet this script still makes 221 calls (better than 67,716,925, but still a lot) for find the answer.&lt;/p&gt;

&lt;h3 id=&#34;introducing-dynamic-programming&#34;&gt;Introducing dynamic programming&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s flip things around. Instead of starting from &lt;strong&gt;63&lt;/strong&gt; cents and going down through the tree as shown in Figs 1 - 3 we will instead compute the minimal number of coins for every value from 1 to 63. To save space, let&amp;rsquo;s instead assume that we need to give 11 cents in change. Let&amp;rsquo;s compute a dynamic programming array for minimal number of coins between 1 and 11 (you may need to scroll sideways if your screen is small):&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;Amount                   0  1  2  3  4  5  6  7  8  9 10 11
Minimum number of coins  0  1  2  3  4  1  2  3  4  5  1  2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;for amounts between &lt;strong&gt;1&lt;/strong&gt; and &lt;strong&gt;4&lt;/strong&gt;, we have no choice, since we have only pennies. At &lt;strong&gt;5&lt;/strong&gt; we can either use 5 pennies or 1 nickel. According to this strategy (for a country with 1, 5, 10, and 25 cent coins):&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                                         \end{cases}$$

&lt;/div&gt;

&lt;p&gt;nickel wins (needs just 1 coin). From &lt;strong&gt;6&lt;/strong&gt; to &lt;strong&gt;9&lt;/strong&gt; we can either use all pennies (values will be 6, 7, 8, and 9) or a combination of nickel and pennies (values will be 2, 3, 4, 5). Again, smaller values win.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now use this table to decide what is the minimum number of coins necessary to give 11 cents in change:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt; | Making change for 11 cents. Let&amp;rsquo;s look at leftmost branch. If you give 1 cent in change, you are left with 10 more to give. You consult Table 1 above and see that 10 cents can be given with 1 coin, so it will be 1 + 1 = 2 coins. In the center branch we give 5 cents in one coin and have 6 more cents to give. Looking at Table 1 tells us that 6 cents can be given in 2 coins, so 1 + 2 = 3 coins. Finally, in the rightmost branch giving 10 cents as one coin leaves 1 cent to give in change, which is also 1 coin, so 1 + 1 = 2. Thus we can either give 10 cents + 1 cent or 1 cent + 10 cents, which is equivalent since in both cases we give only 2 coins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following python code implements a function called &lt;code&gt;dynamicCoinChange&lt;/code&gt; which computes a table (like Table 1) for any amount. In line 20 of the script we print a value corresponding to the amount we need to give back. That value is the minimum number of coins. Note that this program takes virtually no time to run.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/81c07a3750?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;So&lt;/strong&gt;, dynamic programming is a methodology where complex problems are broken down to simple subproblems, that are computed just once and then used to solve the complete problem. In this example, we first pre-compute the number of coins needed to make change for any amount up to the required one, and then produce the answer.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-manhattan-tourist-problem&#34;&gt;Dynamic programming for Manhattan tourist problem&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s get into a multi(2)-dimensional world beautifully elaborated in Jones and Pevzner (&lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;2004&lt;/a&gt;) book:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.3.png&#34; alt=&#34;&#34; /&gt;|&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt; | Reproduced from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The goal of this game is to visit the &lt;strong&gt;maximum number&lt;/strong&gt; of attractions along a stroll across Manhattan.
Let&amp;rsquo;s formalize this a bit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;city = &lt;em&gt;n&lt;/em&gt; x &lt;em&gt;m&lt;/em&gt; directed graph&lt;/li&gt;
&lt;li&gt;node = intersection&lt;/li&gt;
&lt;li&gt;edge = block&lt;/li&gt;
&lt;li&gt;edge weight = number of attractions along a city block&lt;/li&gt;
&lt;li&gt;start node = source&lt;/li&gt;
&lt;li&gt;end node = sink&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4a.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4b.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;The city&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;and a path through it (Figure 6.4 from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The figure above provides a path from source to the sink, yet this path is not the longest. We can identify the optimal path recursively, but just like in the case if the change problem we will end up with a very inefficient code. Let&amp;rsquo;s instead pre-fill our matrix using the following logic:&lt;/p&gt;

&lt;div&gt;

$$s_i,_j = max\begin{cases} s_{i-1,j} + weight\ of\ the\ edge\ between\ (i - 1, j)\ and\ (i,j)
                         &amp; \\ s_{i,j-1} + weight\ of\ the\ edge\ between\ (i, j - 1)\ and\ (i,j)
                 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This will result in the following progression:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid4.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid3.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid6.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;From &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can see that wandering from the source may get us into a dead end. However, backtracking from the sink will always get us to source along the longest path! This by pre-computing the matrix we can easily solve the Manhattan tourist problem. Now we are ready to tackle sequence alignment problems.&lt;/p&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/182594750&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>DNA sequencing</title>
      <link>http://nekrut.github.io/BMMB554/post/topic2/</link>
      <pubDate>Thu, 01 Sep 2016 11:17:20 -0400</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic2/</guid>
      <description>

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;h2 id=&#34;the-60s-and-the-70s&#34;&gt;The 60s and the 70s&lt;/h2&gt;

&lt;p&gt;The first complete nucleic acids being sequenced were RNAs (tRNAs in particular; see pioneering work of &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/14263761&#34;&gt;Robert Holley and colleagues&lt;/a&gt;). The work on finding approaches to sequencing DNA molecules began in late 60s and early 70s. One of the earliest contributions has been made by Ray Wu from Cornell, who used &lt;em&gt;E. coli&lt;/em&gt; DNA polymerase to &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/0022283670900045&#34;&gt;incorporate radioactively labelled nucleotides into protruding ends of bacteriphage lambda&lt;/a&gt;. It took several more years for the development of more &amp;ldquo;high throughput&amp;rdquo; technologies by Sanger and Maxam/Gilbert. The Sanger technique has ultimately won over Maxam/Gilbert&amp;rsquo;s protocol due to its relative simplicity (once dideoxynucleotides has become commercially available) and the fact that it required smaller amount of starting material as the polymerase was used to generate fragments necessary for sequence determination.&lt;/p&gt;

&lt;h2 id=&#34;original-approaches-were-laborious&#34;&gt;Original approaches were laborious&lt;/h2&gt;

&lt;p&gt;In the original &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger paper&lt;/a&gt; the authors sequenced bacteriophage phiX174 by using its own restriction fragments as primers. This was an ideal set up to show the proof of principle for the new method. This is because phiX174 DNA is homogeneous and can be isolated in large quantities. Now suppose that you would like to sequence a larger genome (say &lt;em&gt;E. coli&lt;/em&gt;). Remember that the original version of Sanger method can only sequence fragments up to 200 nucleotides at a time. So to sequence the entire &lt;em&gt;E. coli&lt;/em&gt; genome (which by-the-way was not sequenced until &lt;a href=&#34;http://science.sciencemag.org/content/277/5331/1453&#34;&gt;1997&lt;/a&gt;) you would need to split the genome into multiple pieces and sequence each of them individually. This is hard, because to produce a readable Sanger sequencing gel each sequence must be amplified to a suitable amount (around 1 nanogram) and be homogeneous (you cannot mix multiple DNA fragments in a single reaction as it will be impossible to interpret the gel). Molecular cloning enabled by the availability of commercially available restriction enzymes and cloning vectors simplified this process. Until the onset of next generation sequencing in 2005 the process for sequencing looked something like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(&lt;strong&gt;1&lt;/strong&gt;) - Generate a collection of fragments you want to sequence. It can be a collection of fragments from a genome that was mechanically sheared or just a single fragment generated by PCR.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;2&lt;/strong&gt;) - These fragment(s) are then cloned into a plasmid vector (we will talk about other types of vectors such as BACs later in the course).&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;3&lt;/strong&gt;) - Vectors are transformed into bacterial cells and positive colonies (containing vectors with insert) are picked from an agar plate.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;4&lt;/strong&gt;) - Each colony now represents a unique piece of DNA.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;5&lt;/strong&gt;) - An individual colony is used to seed a bacterial culture that is grown overnight.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;6&lt;/strong&gt;) - Plasmid DNA is isolated from this culture and now can be used for sequencing because it is (1) homogeneous and (2) we now a sufficient amount.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;7&lt;/strong&gt;) - It is sequenced using universal primers. For example the image below shows a map for pGEM-3Z plasmid (a pUC18 derivative). Its multiple cloning site is enlarged and sites for &lt;strong&gt;T7&lt;/strong&gt; and &lt;strong&gt;SP6&lt;/strong&gt; sequencing primers are shown. These are the &lt;strong&gt;pads&lt;/strong&gt; I&amp;rsquo;m referring to in the lecture. These provide universal sites that can be used to sequence any insert in between.&lt;/li&gt;
&lt;/ul&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;img/pgem3z.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;blockquote&gt;
&lt;h5 id=&#34;image-from-promega-inc&#34;&gt;Image from Promega, Inc.&lt;/h5&gt;
&lt;/blockquote&gt;

&lt;p&gt;Until the invention of NGS the above protocol was followed witn some degree of automation. But you can see that it was quite laborious if the large number of fragements needed to be sequenced. This is becuase each of them needed to be subcloned and handled separately. This is in part why Human Genome Project, a subject of our next lecture, took so much time to complete.&lt;/p&gt;

&lt;h2 id=&#34;evolution-of-sequencing-machines&#34;&gt;Evolution of sequencing machines&lt;/h2&gt;

&lt;p&gt;The simplest possible sequencing machine is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Polyacrylamide_gel_electrophoresis&#34;&gt;gel rig with polyacrylamide gel&lt;/a&gt;. Sanger used it is his protocol obtaining the following results:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;img/sangerGel.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;blockquote&gt;
&lt;h5 id=&#34;figure-from-sanger-et-al-1977-https-www-ncbi-nlm-nih-gov-pmc-articles-pmc431765-pdf-pnas00043-0271-pdf&#34;&gt;Figure from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger et al. 1977&lt;/a&gt;.&lt;/h5&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here for sequencing each fragment four separate reactions are peformed (with ddA, ddT, ggC, and ddG) and four lanes on the gel are used. One simplification of this process that came in the 90s was to use fluorescently labelled dideoxy nucleotides. This is easier because everything can be performed in a single tube and uses a single lane on a gel:&lt;/p&gt;


&lt;figure &gt;
    
        &lt;img src=&#34;img/dd_labels.png&#34; /&gt;
    
    
&lt;/figure&gt;


&lt;blockquote&gt;
&lt;h5 id=&#34;figure-from-applied-biosystems-support-site-https-www3-appliedbiosystems-com-cms-groups-mcb-support-documents-generaldocuments-cms-041003-pdf&#34;&gt;Figure from Applied Biosystems &lt;a href=&#34;https://www3.appliedbiosystems.com/cms/groups/mcb_support/documents/generaldocuments/cms_041003.pdf&#34;&gt;support site&lt;/a&gt;.&lt;/h5&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, there is still substantial labor involed in pouring the gels, loading them, running machines, and cleaning everything post-run. A significant improvement was offered by the development of capillary electrophoresis allowing automation of liquid handling and sample loading. Although several manufacturers have been developing and selling such machines a &lt;em&gt;de facto&lt;/em&gt; standard in this area was (and still is) the Applied Biosystems (ABI) Genetics and DNA Anlayzer systems. The highest throughput ABI system, 3730&lt;em&gt;xl&lt;/em&gt;, had 96 cappilaries and could automatically process 384 samples.&lt;/p&gt;

&lt;h2 id=&#34;ngs&#34;&gt;NGS!&lt;/h2&gt;

&lt;p&gt;384 samples may sound like a lot, but it is nothing if we are sequencing an entire genome. The beauty of NGS is that these technologies are not bound by sample handling logistics. They still require preparation of libraries, but once a library is made (which can be automated) it is processed more or less automatically to generate multiple copies of each fragment (in the case of 454, Illumina, and Ion Torrent) and loaded onto the machine, where millions of individual fragments are sequenced simultaneously. The following videos and slides explains how these technologies work.&lt;/p&gt;

&lt;h2 id=&#34;watch-introductory-video&#34;&gt;Watch introductory video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/181072208&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;ngs-in-depth&#34;&gt;NGS in depth&lt;/h1&gt;

&lt;h2 id=&#34;1-454-sequencing&#34;&gt;1: 454 sequencing&lt;/h2&gt;

&lt;p&gt;454 Technology is a massively parralel modification of &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;pyrosequencing&lt;/a&gt; technology. Incorporation of nucleotides are registered by a &lt;a href=&#34;https://en.wikipedia.org/wiki/Charge-coupled_device&#34;&gt;CCD&lt;/a&gt; camera as a flash of light generated from the interaction between ATP and Luciferin. The massive scale of 454 process is enabled by generation of a population of beads carrying multiple copies of the same DNA fragment. The beads are distributed across a microtiter plate where each well of the plate holding just one bead. Thus every unique coordinate (a well) on the plate generates flashes when a nucleotide incorporation event takes plate. This is &amp;ldquo;monochrome&amp;rdquo; technique: flash = nucleotid is incorporated; lack of flash = no incorporation. Thus to distinguish between A, C, G, and T individual nucleotides are &amp;ldquo;washed&amp;rdquo; across the microtiter plate at discrete times: if &lt;strong&gt;A&lt;/strong&gt; is being washed across the plate and a flash of light is emitted, this implies that A is present in the fragment being sequenced.&lt;/p&gt;

&lt;p&gt;454 can generated fragments up 1,000 bases in length. Its biggest weakness is inability to precisely determine the length of &lt;a href=&#34;https://www.broadinstitute.org/crd/wiki/index.php/Homopolymer&#34;&gt;homopolymer runs&lt;/a&gt;. Thus the main type if sequecning error generated by 454 are insertions and deletions (indels).&lt;/p&gt;

&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121286060&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-454#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reading&#34;&gt;Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;Overview of pyrosequencing methodology - Ronaghi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.nature.com/nature/journal/v437/n7057/pdf/nature03959.pdf&#34;&gt;Description of 454 process - Margulies et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://link.springer.com/protocol/10.1385/1-59745-377-3:1&#34;&gt;History of pyrosequencing - Pål Nyrén&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2007-8-7-r143.pdf&#34;&gt;Errors in 454 data - Huse et al. &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/18/i420.full.pdf+html&#34;&gt;Properties of 454 data - Balzer et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-illumina-sequencing&#34;&gt;2: Illumina sequencing&lt;/h2&gt;

&lt;p&gt;Illumina (originally called &amp;ldquo;Solexa&amp;rdquo;) uses glass flowcells with oligonucleotides permanently attached to internal surface. These oligonucleotides are complementary to sequencing adapters added to DNA fragments being sequenced during library preparation. The DNA fragements that are &amp;ldquo;stuck&amp;rdquo; on the flowcell due to complementary intercation between adapters are amplified via &amp;ldquo;bridge amplification&amp;rdquo; to form clusters. Sequencing is performed using reversible terminator chemistry with nucleotides modified to carry dyes specific to each nucleotide. As a result all nucleotides can be added at once and are distinguished by colors. Currently, it is possible to sequence up to 300 bases from each end of the fragment being sequenced. Illumina has the highest throughput (and lowest cost per base) of all existing technologies at this moment. The HiSeq 2500 machine can produce &lt;a href=&#34;http://www.illumina.com/systems/hiseq_2500_1500/performance_specifications.html&#34;&gt;600 billion nucleotides in 5 days&lt;/a&gt;. In this course we will most often work with Illumina data.&lt;/p&gt;

&lt;h3 id=&#34;video-1&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121178846&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-illumina#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-1&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.nature.com/nature/journal/v456/n7218/pdf/nature07517.pdf&#34;&gt;Human genome sequencing on Illumina - Bentley et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://nar.oxfordjournals.org/content/39/13/e90.full-text-lowres.pdf&#34;&gt;Data quality 1 - Nakamura et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2011-12-11-r112.pdf&#34;&gt;Data quality 2 - Minoche et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://www.biomedcentral.com/content/pdf/1471-2164-12-382.pdf&#34;&gt;Illumina pitfalls - Kircher et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;3-pacbio-single-molecule-sequencing&#34;&gt;3: PacBio Single Molecule Sequencing&lt;/h2&gt;

&lt;p&gt;PacBio is a fundamentally different approach to DNA sequencing as it allows reading single molecules. Thus it is an example is so called &lt;em&gt;Single Molecule Sequencing&lt;/em&gt; or &lt;em&gt;SMS&lt;/em&gt;. PacBio uses highly processive DNA polymerase placed at the bottom of each well on a microtiter plate. The plate is fused to the glass slide illuminated by a laser. When polymerase is loaded with template it attracts fluorescently labelled nucleotides to the bottom of the well where they emit light with a wavelength characteristic of each nucleotide. As a result a &amp;ldquo;movie&amp;rdquo; is generated for each well recording the sequence and duration of incorporation events. One of the key advantage of PacBio technology is its ability to produce long reads with ones at 10,000 bases being common.&lt;/p&gt;

&lt;h3 id=&#34;video-2&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121267426&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-pacific-biosceinces&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-2&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2003 | &lt;a href=&#34;http://www.sciencemag.org/content/299/5607/682.full.pdf&#34;&gt;Single Molecule Analaysis at High Concentration - Levene et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.pnas.org/content/105/4/1176.full&#34;&gt;ZMW nanostructures - Korlach et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | &lt;a href=&#34;http://www.sciencemag.org/content/323/5910/133.full&#34;&gt;Real Time Sequencing with PacBio - Eid et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n6/pdf/nmeth.1459.pdf&#34;&gt;Modification detection with PacBio - Flusberg et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://www.nature.com/nbt/journal/v30/n7/pdf/nbt.2280.pdf&#34;&gt;Error correction of PacBio reads - Koren et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.pnas.org/cgi/doi/10.1073/pnas.1400447111&#34;&gt;Transcriptome with PacBio - Taligner et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://dx.doi.org/10.1038/nature13907&#34;&gt;Resolving complex regions in Human genomes with PacBio - Chaisson et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-oxford-nanopore&#34;&gt;4: Oxford Nanopore&lt;/h2&gt;

&lt;p&gt;Oxford nanopore is another dramatically different technology that threads single DNA molecules through biologically-derived (transmembrane proteins) pore in a membrane impermeable to ions. It uses polymerase to control the speed of translocation of the DNA molecule through membrane. In that sense it is not &lt;em&gt;Sequencing by synthesis&lt;/em&gt; we have seen in the other technologies discussed here. This technology generates longest reads possible today: in many instances a single read can be hundreds of thousands if nucleotides in length. It still however suffers from high error rate and relatively low throuyghput (compared to Illumina). On the upside Oxforde Nanopore sequencing machines are only slightly bigger than a thumbdrive and cost very little.&lt;/p&gt;

&lt;h3 id=&#34;slides&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;3895a3069bc64ad5bc74c972a0353911&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;reading-3&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2016 | &lt;a href=&#34;http://nature.com/nnano/journal/v11/n2/full/nnano.2016.9.html&#34;&gt;The promises and challenges of solid-state sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://nature.com/nmeth/journal/v12/n4/full/nmeth.3290.html&#34;&gt;Improved data analysis for the minion nanopore sequencer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3444.html&#34;&gt;A complete bacterial genome assembled de novo using only nanopore sequencing data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://nature.com/nbt/journal/v30/n4/full/nbt.2171.html&#34;&gt;Reading DNA at single-nucleotide resolution with a mutant MspA nanopore and phi29 DNA polymerase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Simpson Lab &lt;a href=&#34;http://simpsonlab.github.io/2015/04/08/eventalign/&#34;&gt;blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Poretools analysis &lt;a href=&#34;http://poretools.readthedocs.org/&#34;&gt;suite&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;homework&#34;&gt;Homework&lt;/h1&gt;

&lt;p&gt;To be posted Tuesday Sept 6.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>History</title>
      <link>http://nekrut.github.io/BMMB554/post/topic1/</link>
      <pubDate>Thu, 25 Aug 2016 11:41:14 -0500</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/post/topic1/</guid>
      <description>

&lt;h1 id=&#34;why-history&#34;&gt;Why history?&lt;/h1&gt;

&lt;p&gt;Knowing history is essential for understanding how we arrived to the current state of affairs in our field. It is also full of acciental discoveries and dramatic relationships making it quite interesting to read about. I strongly advise you to take a look at the mansucripts below.&lt;/p&gt;

&lt;h2 id=&#34;classical-publications&#34;&gt;Classical publications&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;1965 | &lt;a href=&#34;http://www.amazon.com/A-History-Genetics-A-H-Sturtevant/dp/0879696079&#34;&gt;A history of genetics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1943 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;Delbruck &amp;amp; Luria&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1944 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/avery-1944.pdf&#34;&gt;Avery, MacLeod, &amp;amp; McCarty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1952 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/hershey-chase-1952.pdf&#34;&gt;Herhey &amp;amp; Chase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1953 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/watsoncrick.pdf&#34;&gt;Watson &amp;amp; Crick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1958 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/Proc%20Natl%20Acad%20Sci%20USA%201958%20Meselson.pdf&#34;&gt;Meselson &amp;amp; Stahl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1960 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/jacob-monod-1961.pdf&#34;&gt;Jacob and Monod&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;popular-yet-very-informative-literature&#34;&gt;Popular (yet very informative) literature&lt;/h2&gt;

&lt;p&gt;Get one of these and read it on a plane:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://www.amazon.com/The-Double-Helix-Discovery-Structure/dp/074321630X&#34;&gt;The double helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.amazon.com/Third-Man-Double-Helix-Autobiography/dp/019280667X&#34;&gt;The Third Man of the Double Helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.amazon.com/Brave-Genius-Philosopher-Adventures-Resistance/dp/0307952347&#34;&gt;Brave Genius&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;publication-highlight-the-fluctuation-test&#34;&gt;Publication highlight | The fluctuation test&lt;/h1&gt;

&lt;p&gt;In a truly collaborative spirit a german physicist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/delbruck-facts.html&#34;&gt;Max Delbrück&lt;/a&gt; joined forces with an italian microbiologist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/luria-facts.html&#34;&gt;Salvador Luria&lt;/a&gt; to prove the stochastic nature of mutations and to reject &amp;ldquo;the last stroghold of Lamarckism&amp;rdquo;. This &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;classical work&lt;/a&gt; was published in 1943 in journal &lt;em&gt;Genetics&lt;/em&gt;. Here we re-examine some of the fundamental aspects of this work. In this we occasionally rely on examples from a classical textbook on &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Molecular Genetics&lt;/a&gt; by Günther Stent.&lt;/p&gt;

&lt;p&gt;It has been know for some time that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bacteria sensitive (infectable) by phage becomes resistant as a result of exposure to bacteriophage;&lt;/li&gt;
&lt;li&gt;The resistance is preserved when descendants of these cells are incubated.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This can, in principle, be explained by two mutually exclusive hypotheses:&lt;/p&gt;

&lt;h2 id=&#34;acquired-resistance-vs-spontaneous-mutation&#34;&gt;Acquired resistance vs. spontaneous mutation&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;direct action of phage on bacteria triggers &amp;ldquo;acquisition&amp;rdquo; of the resistance;&lt;/li&gt;
&lt;li&gt;some cells in a population already have a mutation conferring the resistance and the exposure to the phage merely brings carriers of such mutations to prominence by killing off all sensitive cells.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How can we distinguish between these two alternative possibilities? Let&amp;rsquo;s try to put hypothesis (1) into quantitative framework:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are two bacterial phenotypes: &lt;code&gt;S&lt;/code&gt; - sensitive (is lysed by the phage) and &lt;code&gt;R&lt;/code&gt; - resistant (is not lysed and does not absorb phage)&lt;/li&gt;
&lt;li&gt;Bacterial population progresses from a single cell to &lt;em&gt;&lt;code&gt;N&lt;/code&gt;&lt;/em&gt; cells&lt;/li&gt;
&lt;li&gt;The probability of changing from &lt;code&gt;S&lt;/code&gt; to &lt;code&gt;R&lt;/code&gt; is &lt;em&gt;&lt;code&gt;a&lt;/code&gt;&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, if one grows &lt;code&gt;S&lt;/code&gt; bacteria in a culture and then plates them on agar containing excess of phage, where will be &lt;em&gt;&lt;code&gt;n&lt;/code&gt;&lt;/em&gt; of &lt;code&gt;R&lt;/code&gt; colonies, where &lt;em&gt;&lt;code&gt;n&lt;/code&gt;&lt;/em&gt; = &lt;em&gt;&lt;code&gt;aN&lt;/code&gt;&lt;/em&gt;. Since we can estimate &lt;em&gt;&lt;code&gt;n&lt;/code&gt;&lt;/em&gt; directly (by counting colonies on the plate) and &lt;em&gt;&lt;code&gt;N&lt;/code&gt;&lt;/em&gt; is also known (a function of the number of generations) the fraction of &lt;code&gt;R&lt;/code&gt; individuals in a population is going to be same for all stages of the population:&lt;br&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;code&gt;n/N&lt;/code&gt;&lt;/em&gt; = &lt;em&gt;&lt;code&gt;a&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;This will not be quite the same for hypothesis (2) since the number of cells carrying the resistance mutation will differ depending on when in population history they occurred and how many generation have passed since their occurrence. After &lt;em&gt;&lt;code&gt;g&lt;/code&gt;&lt;/em&gt; generations there will be &lt;br&gt;&lt;em&gt;&lt;code&gt;N&lt;/code&gt;&lt;/em&gt; = &lt;code&gt;2&lt;/code&gt;&lt;sup&gt;&lt;em&gt;&lt;code&gt;g&lt;/code&gt;&lt;/em&gt;&lt;/sup&gt;&lt;br&gt; cells. Consequently, if the probability of mutation is &lt;em&gt;&lt;code&gt;a&lt;/code&gt;&lt;/em&gt;, then by &lt;em&gt;&lt;code&gt;i&lt;/code&gt;&lt;/em&gt;-th generation there will be &lt;br&gt;&lt;em&gt;&lt;code&gt;a&lt;/code&gt;&lt;/em&gt;&lt;code&gt;2&lt;/code&gt;&lt;sup&gt;&lt;em&gt;&lt;code&gt;i&lt;/code&gt;&lt;/em&gt;&lt;/sup&gt;&lt;br&gt; cells carrying mutations and we can arrive to the ratio of &lt;br&gt;&lt;em&gt;&lt;code&gt;n/N&lt;/code&gt;&lt;/em&gt; = &lt;em&gt;&lt;code&gt;ga&lt;/code&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Delbück and Luria&amp;rsquo;s experience with estimating such ratio has proven to be difficult as they were observing great fluctuation in the number of &lt;code&gt;R&lt;/code&gt; cells. They have subsequently realized that such fluctuation was in fact an indirect indication that the mutation hypothesis is likely true. Delbrück has developed a theoretical framework predicting the distribution of mutant phenotypes for both hypotheses. &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Stent&lt;/a&gt; provides the following elegant description of Delbück&amp;rsquo;s reasonong. It is based on measuring the variance in the number of resistant colonies across a number of replicates. Suppose there are &lt;em&gt;&lt;code&gt;C&lt;/code&gt;&lt;/em&gt; &lt;em&gt;E. coli&lt;/em&gt; replicates (cultures) started from a single &lt;code&gt;S&lt;/code&gt; bacterium. Each is grown for &lt;em&gt;&lt;code&gt;g&lt;/code&gt;&lt;/em&gt; generations, and each accumulates &lt;em&gt;&lt;code&gt;N&lt;/code&gt;&lt;/em&gt; = &lt;code&gt;2&lt;/code&gt;&lt;sup&gt;&lt;em&gt;&lt;code&gt;g&lt;/code&gt;&lt;/em&gt;&lt;/sup&gt; cells as a result. The entire content of each culture is then spread over agar plate saturated with the phage. The number &lt;em&gt;&lt;code&gt;n&lt;/code&gt;&lt;/em&gt; of &lt;code&gt;R&lt;/code&gt; colonies is then counted. If &lt;em&gt;&lt;code&gt;n&lt;/code&gt;&lt;/em&gt;&lt;sub&gt;&lt;em&gt;&lt;code&gt;j&lt;/code&gt;&lt;/em&gt;&lt;/sub&gt; is the number of &lt;code&gt;R&lt;/code&gt; colonies from culture &lt;em&gt;&lt;code&gt;j&lt;/code&gt;&lt;/em&gt;, then the mean of resistant colonies and the variance of the number of resistant colonies are:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Average&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Variance&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;img/average.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;img/variance.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Notation 6-3&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Notation 6-4 (from Stent&amp;rsquo;s Molecular Genetics)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The behaviour of ratio of &lt;code&gt;variance/average&lt;/code&gt; is critical to distinguishing between hypothesis (1) and (2). If (1) is true we expect low fluctuation and the ratio will be close to 1. If (2) is true the variation will be considerable and the ratio will be much higher than one. Look at Fig. 1 below.
* In pane A (Hypothesis 1) phage induces changes in the bacteria upon plating and because the probability of changing from &lt;code&gt;S&lt;/code&gt; to &lt;code&gt;R&lt;/code&gt; is the same for all cells we would see approximately the same number of &lt;code&gt;R&lt;/code&gt; cells. The mean here is &lt;code&gt;2.5&lt;/code&gt; and the variance/mean ratio is &lt;code&gt;1.1&lt;/code&gt;.&lt;br /&gt;
* In pane B (Hypothesis 2) every cell has the same mutation rate, but the mutations may occur at any point during the culture propagation. If they occur early - many resistant colonies will be produced from such culture. If they occur late - just a few. As a result one would expect to see significant fluctuation. Here the mean is the same as in A = &lt;code&gt;2.5&lt;/code&gt;, but the variance/mean ratio is much higher at &lt;code&gt;4.3&lt;/code&gt;.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;Figure 1&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Table 1&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;img/luria.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;img/stent.png&#34; /&gt;
    
    
&lt;/figure&gt;
&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;Fig. 6-4&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;Table 6-1 (from Stent&amp;rsquo;s Molecular Genetics)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Table 1 settles these issues. Here one can see a significant fluctuation across 20 independent experiments with the main of &lt;code&gt;11.3&lt;/code&gt; and variance/mean ratio of &lt;code&gt;61&lt;/code&gt;. This table also show the result of plating aliquots from a bulk culture. In this case 10 ml culture was incubated for the same duration as the 20 independent cultures. Small amount from this culture were then plated on 10 independent plates. Because these cells share their genetic ancestry there is very little variation across these platings.&lt;/p&gt;

&lt;p&gt;This paper settled one of the most contentious issues in biology and won the Nobel prize to its authors.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;slides&#34;&gt;Slides&lt;/h1&gt;

&lt;p&gt;Slides covering material for Topic 1&lt;/p&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;7726e8b8b3ee41f0a2a1497128d59ca0&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;

&lt;p&gt;Video presentation (actual lecture). Uses slides from above.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/180735569&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;homework&#34;&gt;Homework&lt;/h1&gt;

&lt;p&gt;Read two following papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;DNA sequencing with chain-terminating inhibitors&amp;rdquo; by Sanger, Nicklen, and Coulson (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;A new method for sequencing DNA&amp;rdquo; by Maxam and Gilbert (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC392330/pdf/pnas00024-0174.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Complete &lt;a href=&#34;https://goo.gl/forms/V6xQ1DMsWPc27yZq1&#34;&gt;this Quiz&lt;/a&gt;. You have a week (until the midnight of Sept 6) to finish it.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Syllabus</title>
      <link>http://nekrut.github.io/BMMB554/about/</link>
      <pubDate>Mon, 25 Jul 2016 00:00:00 +0000</pubDate>
      
      <guid>http://nekrut.github.io/BMMB554/about/</guid>
      <description>

&lt;h1 id=&#34;instructor&#34;&gt;Instructor&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Anton Nekrutenko&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;mailto:aun1@psu.edu?Subject=BMMB554&#34;&gt;aun1@psu.edu&lt;/a&gt;&lt;br&gt;
Wartik 505&lt;br&gt;
Office hours by appointment only&lt;/p&gt;

&lt;blockquote&gt;
&lt;h6 id=&#34;when-contacting-instructor-use-the-above-e-mail-and-include-bmmb554-in-the-subject-line-simply-click-on-e-mail-address&#34;&gt;When contacting instructor use the above e-mail and include &amp;ldquo;BMMB554&amp;rdquo; in the subject line (simply click on e-mail address).&lt;/h6&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;course-description&#34;&gt;Course description&lt;/h1&gt;

&lt;p&gt;This course is designed as a preparation routine for graduate students in Life Sciences. It has several focus areas including evolution of life sciences as well as in-depth overview of sequencing technologies and their applications.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;grading&#34;&gt;Grading&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Homework = 50%&lt;/li&gt;
&lt;li&gt;Final project = 50%&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;topics&#34;&gt;Topics&lt;/h1&gt;

&lt;p&gt;We will cover a breadth of topics. Below is the approaximate list. Keep in mind that this field is very dymanic. To account for that we may skip or extend some of the subjects.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;History: From Genetics to Genomics&lt;/li&gt;
&lt;li&gt;Sequencing: From Sanger to Nanopores&lt;/li&gt;
&lt;li&gt;Alignment and Assembly I: Assembly basics&lt;/li&gt;
&lt;li&gt;Alignment and Assembly II: Alignment basics&lt;/li&gt;
&lt;li&gt;Galaxy: An introduction&lt;/li&gt;
&lt;li&gt;Galaxy: Writing your own tools&lt;/li&gt;
&lt;li&gt;Nanopores and more&lt;/li&gt;
&lt;li&gt;Re-sequencing I: Introduction and non-diploid case&lt;/li&gt;
&lt;li&gt;Re-sequencing II: Diploid genomes&lt;/li&gt;
&lt;li&gt;Practicum: Re-sequencing&lt;/li&gt;
&lt;li&gt;Transcriptomics I: Refrence-based&lt;/li&gt;
&lt;li&gt;Transcriptomics II: Reference-free&lt;/li&gt;
&lt;li&gt;Practicum: Transcriptomics&lt;/li&gt;
&lt;li&gt;RNA analysis: RiboSeq and ShapeSeq&lt;/li&gt;
&lt;li&gt;Practicum: RNA analysis&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions I: Approaches&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions II: ENCODE Project&lt;/li&gt;
&lt;li&gt;Practicum: DNA/Protein interactions&lt;/li&gt;
&lt;li&gt;Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Practicum: Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Metagenomics I: Approaches&lt;/li&gt;
&lt;li&gt;Metagenomics II: Community analysis&lt;/li&gt;
&lt;li&gt;Practicum: Metagenomics&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;h6 id=&#34;in-an-examination-setting-unless-the-instructor-gives-explicit-prior-instructions-to-the-contrary-violations-of-academic-integrity-shall-consist-of-any-attempt-to-receive-assistance-from-written-or-printed-aids-from-any-person-or-papers-or-electronic-devices-or-of-any-attempt-to-give-assistance-whether-the-student-doing-so-has-completed-his-or-her-own-work-or-not-other-violations-include-but-are-not-limited-to-any-attempt-to-gain-an-unfair-advantage-in-regard-to-an-examination-such-as-tampering-with-a-graded-exam-or-claiming-another-s-work-to-be-one-s-own-other-assessments-including-angel-administered-quizzes-and-assessments-as-well-as-homework-assignments-are-expected-to-represent-your-own-independent-work-unless-specifically-stated-otherwise-failure-to-comply-will-lead-to-sanctions-against-the-student-in-accordance-with-the-policy-on-academic-integrity-in-the-eberly-college-of-science-the-eberly-college-of-science-code-of-mutual-respect-and-cooperation-www-science-psu-edu-climate-code-of-mutual-respect-final-pdf-embodies-the-values-that-we-hope-our-faculty-staff-and-students-possess-and-will-endorse-to-make-the-eberly-college-of-science-a-place-where-every-individual-feels-respected-and-valued-as-well-as-challenged-and-rewarded-the-eberly-college-of-science-is-committed-to-the-academic-success-of-students-enrolled-in-the-college-s-courses-and-undergraduate-programs-when-in-need-of-help-students-can-utilize-various-college-and-university-wide-resources-for-learning-assistance-http-www-science-psu-edu-advising-success-penn-state-welcomes-students-with-disabilities-into-the-university-s-educational-programs-if-you-have-a-disability-related-need-for-reasonable-academic-adjustments-in-this-course-contact-the-office-for-disability-services-ods-at-814-863-1807-v-tty-for-further-information-regarding-ods-please-visit-the-office-for-disability-services-web-site-at-http-equity-psu-edu-ods-in-order-to-receive-consideration-for-course-accommodations-you-must-contact-ods-and-provide-documentation-see-the-documentation-guidelines-http-equity-psu-edu-ods-guidelines-documentation-guidelines-if-the-documentation-supports-the-need-for-academic-adjustments-ods-will-provide-a-letter-identifying-appropriate-academic-adjustments-please-share-this-letter-and-discuss-the-adjustments-with-your-instructor-as-early-in-the-course-as-possible-you-must-contact-ods-and-request-academic-adjustment-letters-at-the-beginning-of-each-semester&#34;&gt;In an examination setting, unless the instructor gives explicit prior instructions to the contrary, violations of academic integrity shall consist of any attempt to receive assistance from written or printed aids, from any person or papers or electronic devices, or of any attempt to give assistance, whether the student doing so has completed his or her own work or not. Other violations include, but are not limited to, any attempt to gain an unfair advantage in regard to an examination, such as tampering with a graded exam or claiming another&amp;rsquo;s work to be one&amp;rsquo;s own. Other assessments (including ANGEL-administered quizzes and assessments as well as homework assignments) are expected to represent your own independent work unless specifically stated otherwise. Failure to comply will lead to sanctions against the student in accordance with the Policy on Academic Integrity in the Eberly College of Science. The Eberly College of Science Code of Mutual Respect and Cooperation (www.science.psu.edu/climate/Code-of-Mutual-Respect-final.pdf) embodies the values that we hope our faculty, staff, and students possess and will endorse to make The Eberly College of Science a place where every individual feels respected and valued, as well as challenged and rewarded.   The Eberly College of Science is committed to the academic success of students enrolled in the College&amp;rsquo;s  courses and undergraduate programs. When in need of help, students can utilize various College and University wide resources for learning assistance (&lt;a href=&#34;http://www.science.psu.edu/advising/success&#34;&gt;http://www.science.psu.edu/advising/success&lt;/a&gt;). Penn State welcomes students with disabilities into the University&amp;rsquo;s educational programs. If you have a disability-related need for reasonable academic adjustments in this course, contact the Office for Disability Services (ODS) at 814-863-1807 (V/TTY). For further information regarding ODS, please visit the Office for Disability Services Web site at &lt;a href=&#34;http://equity.psu.edu/ods/.  &#34;&gt;http://equity.psu.edu/ods/.  &lt;/a&gt; In order to receive consideration for course accommodations, you must contact ODS and provide documentation (see the &lt;a href=&#34;http://equity.psu.edu/ods/guidelines/documentation-guidelines&#34;&gt;documentation guidelines&lt;/a&gt;). If the documentation supports the need for academic adjustments, ODS will provide a letter identifying appropriate academic adjustments. Please share this letter and discuss the adjustments with your instructor as early in the course as possible. You must contact ODS and request academic adjustment letters at the beginning of each semester.&lt;/h6&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>