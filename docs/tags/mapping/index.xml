<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mapping on BMMB 554 / 2017</title>
    <link>https://nekrut.github.io/BMMB554/tags/mapping/</link>
    <description>Recent content in Mapping on BMMB 554 / 2017</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Jan 2017 10:13:02 -0400</lastBuildDate>
    
	<atom:link href="https://nekrut.github.io/BMMB554/tags/mapping/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>5. Aligning many sequences quickly</title>
      <link>https://nekrut.github.io/BMMB554/post/topic5/</link>
      <pubDate>Mon, 30 Jan 2017 10:13:02 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic5/</guid>
      <description>Speeding things up The topics we discussed in the past lecture explain fundamental concepts behind analysis of biological sequences. Today, we will be talking about algorithms that allow aligning billions of sequencing reads against reference genomes. Similarly to the previous lecture I have borrowed heavily from the course taught by Ben Langmead at Johns Hopkins. The cover image is from Wikpedia article on Burrows-Wheeler transform.
The challenge of really large datasets In the previous lecture we have seen how dynamic programming helps aligning sequences.</description>
    </item>
    
  </channel>
</rss>