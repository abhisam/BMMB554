<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on BMMB 554 / 2017</title>
    <link>https://nekrut.github.io/BMMB554/post/index.xml</link>
    <description>Recent content in Posts on BMMB 554 / 2017</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Jan 2017 10:13:02 -0400</lastBuildDate>
    <atom:link href="https://nekrut.github.io/BMMB554/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>5. Aligning many sequences quickly</title>
      <link>https://nekrut.github.io/BMMB554/post/topic5/</link>
      <pubDate>Mon, 30 Jan 2017 10:13:02 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic5/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic5_cover.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;speeding-things-up&#34;&gt;Speeding things up&lt;/h1&gt;

&lt;p&gt;The topics we discussed in the past lecture explain fundamental ideas behind analysis of biological sequences. They are essential for understanding how current high throughput approaches evolved. Today, we will be talking about advanced concepts implementation of which allows aligning billions of sequencing reads against reference genomes very quickly. Similarly to the previous lecture I have borrowed heavily from the &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image is from &lt;a href=&#34;https://en.wikipedia.org/wiki/Burrows%E2%80%93Wheeler_transform&#34;&gt;Wikpedia article&lt;/a&gt; on Burrows-Wheeler transform.&lt;/p&gt;

&lt;h2 id=&#34;the-challenge-of-really-large-datasets&#34;&gt;The challenge of really large datasets&lt;/h2&gt;

&lt;p&gt;In the previous lecture we have seen how dynamic programming helps aligning sequences. Unfortunately in reality this approach is not practical for aligning billion of sequencing reads that are routinely generated with NGS technologies.&lt;/p&gt;

&lt;p&gt;If you recall the previous lecture, we were finding alignments using the following approach:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;The performance of this approach expressed as the &lt;a href=&#34;https://en.wikipedia.org/wiki/Big_O_notation&#34;&gt;big O notation&lt;/a&gt; is:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(mn)$&lt;/p&gt;

&lt;p&gt;where $n$ is the read length and $m$ is the genome length. The $m$ is large. For instance, in the case of human genome it is $3\times10^9$. On top of that we &lt;em&gt;very many&lt;/em&gt; reads. The latest Illumina HiSeq 2500 machine can produce as much as $6\times10^9$ 100 bp reads. Taking this into account our big O notation becomes:&lt;/p&gt;

&lt;p&gt;$\mathcal{O}(dmn)$&lt;/p&gt;

&lt;p&gt;where $d\times m\times n = 2\times10^{21}$ ($d$ stands for &lt;em&gt;depth&lt;/em&gt;). In other words to compute alignments between a genome and all these reads we need to perform $2\times10^{21}$ cell updates in the dynamic programming matrices even before we start the traceback. On a 1,000 CPU cluster with 3MHz processors this will take over &lt;strong&gt;2&lt;/strong&gt; years!&lt;/p&gt;

&lt;h2 id=&#34;mapping-versus-alignment&#34;&gt;Mapping versus alignment&lt;/h2&gt;

&lt;p&gt;One possible idea on how to speed things up will be to first find most likely locations for each read and them refine alignments as necessary. In other words reads should be &lt;em&gt;mapped&lt;/em&gt; by identifying regions of the genomes from which they most likely originate. The term &lt;em&gt;mapping&lt;/em&gt; is sometimes used interchangeably with the word &amp;ldquo;alignment&amp;rdquo;. Yet &lt;em&gt;mapping&lt;/em&gt; and &lt;em&gt;alignment&lt;/em&gt; are somewhat different concepts. &lt;a href=&#34;http://lh3lh3.users.sourceforge.net/&#34;&gt;Heng Li&lt;/a&gt; defines them this way:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Mapping&lt;/strong&gt;: assigning a sequencing read to a location within genome. Mapping is said to be correct and it overlaps the true region from which this read has originated.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Alignment&lt;/strong&gt;: detailed placement of every base within a read to a corresponding base within the genome. Alignment is said to be correct is every base if placed correctly.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So let&amp;rsquo;s see how we can find potential read locations quickly. Below is a list of key publications highlighting basic principles of current mapping tools:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;2009 | How to map billions of short reads onto genomes? - &lt;a href=&#34;http://www.nature.com/nbt/journal/v27/n5/full/nbt0509-455.html&#34;&gt;Trapnell &amp;amp; Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | Bowtie 1 - &lt;a href=&#34;http://genomebiology.com/content/10/3/R25&#34;&gt;Langmead et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | Bowtie 2 - &lt;a href=&#34;http://www.nature.com/nmeth/journal/v9/n4/full/nmeth.1923.htm&#34;&gt;Langmead and Salzberg&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/25/14/1754.long&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | BWA - &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/5/589&#34;&gt;Li and Durbin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2013 | BWA-MEM - &lt;a href=&#34;http://arxiv.org/abs/1303.3997&#34;&gt;Li&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Bioinformatics Algorithms - &lt;a href=&#34;http://bioinformaticsalgorithms.com&#34;&gt;Compeau and Pevzner&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | Johns Hopkins Computational Genomics Course - &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;Langmead&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexing-and-substrings&#34;&gt;Indexing and substrings&lt;/h3&gt;

&lt;p&gt;Indexing is not a new idea. Most books have an index where a word is &lt;em&gt;mapped&lt;/em&gt; back to a page where it is found. This particular type of index is called &lt;em&gt;inverted index&lt;/em&gt;. The word &lt;em&gt;inverted&lt;/em&gt; implies that there is also a non-inverted or &lt;em&gt;forward&lt;/em&gt; index. The image below explain the distinction between the two:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/inverted_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Inverted index.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/forward_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Forward index. (From &lt;a href=&#34;https://en.wikipedia.org/wiki/Search_engine_indexing&#34;&gt;Wikipedia&lt;/a&gt;).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;For what we are interested in (searching for the best location of a read in the reference genome) we will use &lt;em&gt;inverted index&lt;/em&gt;. We will refer to it simply as &lt;em&gt;index&lt;/em&gt;. So to find a pattern in string using an index we first need to create that index. To create an index for a string &lt;em&gt;T&lt;/em&gt; (i.e., a genome) we will need to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings of length &lt;em&gt;L&lt;/em&gt; and record where these substrings occur;&lt;/li&gt;
&lt;li&gt;organize the list of substrings and their coordinates and an easily accessible data structure (a &lt;em&gt;map&lt;/em&gt;).&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/create_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now that we&amp;rsquo;ve created an index for text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;CGTGCCTACTTACTTACAT&lt;/code&gt; we might as well search it. Suppose we now want to find whether a pattern &lt;code&gt;CTACTTAC&lt;/code&gt; (we will refer to pattern as to &lt;em&gt;P&lt;/em&gt;) is present in &lt;em&gt;T&lt;/em&gt;. To do this we need:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;extract substrings from &lt;em&gt;P&lt;/em&gt;;&lt;/li&gt;
&lt;li&gt;check the index to see if they are present;&lt;/li&gt;
&lt;li&gt;if they are present extend to see if the entire string is matching.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/search_index.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Looking for &lt;em&gt;P&lt;/em&gt; in &lt;em&gt;T&lt;/em&gt;. The first three substrings don&amp;rsquo;t have a match. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In the figure above you can see that trying various substrings from &lt;em&gt;P&lt;/em&gt; yields three failures and a success with two hits. Of course in our case the &lt;em&gt;T&lt;/em&gt; is very short and you can easily see that an index for a realistic fragment of DNA can be very large. For example, an index for human chromosome 1 (~249,000,000 nucleotides) will occupy over 12 GB of space. In these cases a practical solution may be skipping some of the substrings while making the index. For instance, including only every 4th substring (i.e., using interval of &lt;em&gt;4&lt;/em&gt;) in a human chromosome 1 index will reduce memory usage to a peak of ~8Gb.&lt;/p&gt;

&lt;p&gt;As one can see finding patterns in text using indexes requires finding values for parameters such as substring length and the interval (if we use skipping). These value have significant implications to the speed of the search, memory use, and , importantly, to specificity. The following table shows how choosing different values for substring length and interval affect speed, memory footprint, and specificity for finding pattern&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GCGCGGTGGCTCACGCCTGTAATCCCAGCACTTTGGGAGGCCGAGGCGGG
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;within human chromosome 1 (data from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;here&lt;/a&gt;):&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;Substring length&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Interval&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Indexing time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Search time (s)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Memory usage (Gb)&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Specificity (%)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;59.31&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.40&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~7.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;7&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63.74&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.06&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~5.0&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1.26&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72.52&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~3.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.11&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;40.20&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.02&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~2.1&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4.37&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;30&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;19.78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.00&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;~1.6&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;11.72&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Specificity can be thought of as a proxy for the number of times an index hit can be extended to a true match between &lt;em&gt;T&lt;/em&gt; and &lt;em&gt;P&lt;/em&gt;. The figure below explain this idea:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/specificity.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Specificity. Matching &lt;code&gt;ord&lt;/code&gt; to &lt;code&gt;time_for_such_a_word&lt;/code&gt;. Image from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;here we look for pattern &lt;code&gt;ord&lt;/code&gt; within text &lt;code&gt;time_for_such_a_word&lt;/code&gt;. The first index hit does not produce a match, while the second does. Decreasing the number of fruitless hits increases specificity and speeds up the search. Intuitively, this is achieved by increasing the substring length.&lt;/p&gt;

&lt;p&gt;In summary, we have seen that we can create an index (a map) containing coordinates of substrings from a text &lt;em&gt;T&lt;/em&gt;. We can then use this map to find occurrences (if they exist) of pattern &lt;em&gt;P&lt;/em&gt; within the &lt;em&gt;T&lt;/em&gt;. The map can be represented in variety of ways including sorted lists, hash tables, and trees:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sorted_list.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Sorted list&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/hash.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Hash&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Trie&lt;/p&gt;

&lt;p&gt;Sorted list (top), Hash (middle), and Trie (bottom). From &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Trie#/media/File:Trie_example.svg&#34;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;What&amp;rsquo;s important here is that sorted lists and especially hash tables provide a quick way to find the initial hit, but they are limited by the choice of the substring size. We&amp;rsquo;ve seen before (the &lt;em&gt;Specificity&lt;/em&gt; table above) that the choice of substring size will have profound effects on the performance of the search. Would it be nice if we would not need to make that choice. For this we will continue to &lt;em&gt;Tries and Trees&lt;/em&gt; below.&lt;/p&gt;

&lt;h3 id=&#34;tries-and-trees&#34;&gt;Tries and trees&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s consider text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;gtccacctagtaccatttgt&lt;/code&gt;. Using the logic from previous section we can build an index using substrings of length 2 with interval 2 (skipping every other substring) that would look like this after sorting:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;Substring&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;Offset&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ac&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ag&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;8&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;at&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;14&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;12&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;cc&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ct&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;18&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;gt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;0&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;ta&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;&lt;code&gt;tt&lt;/code&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;16&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Representing this sorted list as a &lt;em&gt;trie&lt;/em&gt; that would map substrings to their positions (offsets) will look like this:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/substring_trie.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A trie. Example from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note that this &lt;em&gt;trie&lt;/em&gt; is the smallest tree (&lt;a href=&#34;http://stackoverflow.com/questions/4737904/difference-between-tries-and-trees&#34;&gt;&lt;em&gt;trie&lt;/em&gt; versus &lt;em&gt;tree&lt;/em&gt;&lt;/a&gt; is indeed a bit confusing) representing a collection of substrings that has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet (in this case &lt;code&gt;A&lt;/code&gt;, &lt;code&gt;C&lt;/code&gt;, &lt;code&gt;G&lt;/code&gt;, and &lt;code&gt;T&lt;/code&gt;);&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each &lt;em&gt;key&lt;/em&gt; (substrings of length 2 in the above case) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;While the above example shows how we can quickly find positions for a given substring, it still relies on a fixed substring length. To see how we can deal with this limitation let&amp;rsquo;s introduce the idea of indexing with &lt;em&gt;suffixes&lt;/em&gt; rather than with fixed substrings. Consider the following text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG&lt;/code&gt;. Let&amp;rsquo;s add a special symbol &lt;code&gt;$&lt;/code&gt; to the end of this text. For &lt;em&gt;T$&lt;/em&gt; a list of all substrings will look like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;GTTATAGCTGATCGCGGCGTAGCGG$
 TTATAGCTGATCGCGGCGTAGCGG$
  TATAGCTGATCGCGGCGTAGCGG$
   ATAGCTGATCGCGGCGTAGCGG$
    TAGCTGATCGCGGCGTAGCGG$
     AGCTGATCGCGGCGTAGCGG$
      GCTGATCGCGGCGTAGCGG$
       CTGATCGCGGCGTAGCGG$
        TGATCGCGGCGTAGCGG$
         GATCGCGGCGTAGCGG$
          ATCGCGGCGTAGCGG$
           TCGCGGCGTAGCGG$
            CGCGGCGTAGCGG$
             GCGGCGTAGCGG$
              CGGCGTAGCGG$
               GGCGTAGCGG$
                GCGTAGCGG$
                 CGTAGCGG$
                  GTAGCGG$
                   TAGCGG$
                    AGCGG$
                     GCGG$
                      CGG$
                       GG$
                        G$
                         $
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Recall that a trie has the following properties:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each edge is labeled with a character from a given alphabet;&lt;/li&gt;
&lt;li&gt;Each node has a single outgoing edge corresponding to an alphabet character;&lt;/li&gt;
&lt;li&gt;Each substring (in this case a suffix) is spelled out along a path starting at the root.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let&amp;rsquo;s now use these rules to build a suffix trie for a much simpler text &lt;em&gt;T&lt;/em&gt; = &lt;code&gt;abaaba&lt;/code&gt;. It is much smaller than the text we used above and so it will be easier to get the point across. First, let&amp;rsquo;s add &lt;code&gt;$&lt;/code&gt; and create a list of all suffixes:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
baaba$
aaba$
aba$
ba$
a$
$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;now let&amp;rsquo;s create a trie:&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-trie&#34;&gt;Looking for substrings in a Trie&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The green path shows the longest suffix (the entire thing). The blue path is the shortest suffix containing only the terminal character.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/trie_no_end.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Note, that the trie would look &lt;strong&gt;dramatically&lt;/strong&gt; different had we not added the &lt;code&gt;$&lt;/code&gt; at the end. The difference is that without the &lt;code&gt;$&lt;/code&gt; the trie will &lt;strong&gt;not&lt;/strong&gt; have every suffix to be represented by a path from &lt;code&gt;root&lt;/code&gt; to a leaf.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In suffix trie every edge is labeled with a single character and nodes have no labels in our representation. However, you can think of every node as being labeled with a string that spells out all characters occurring along a path from the root up to the that node. For example, the blue node &lt;code&gt;baa&lt;/code&gt; spells out characters &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;a&lt;/code&gt; along a path from the root.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Suffix trie is an ideal data stricture to quickly check if a pattern is or is not present in a text. The following three examples highlight how this can be done. Suppose we want to check if a substring &lt;code&gt;baa&lt;/code&gt; is present within text &lt;code&gt;abaaba&lt;/code&gt; represented as our suffix trie. We start at the root and take an edge labeled with &lt;code&gt;b&lt;/code&gt;. We next proceed through an edge labeled &lt;code&gt;a&lt;/code&gt;. At this point there are two outgoing edges: &lt;code&gt;a&lt;/code&gt; and &lt;code&gt;$&lt;/code&gt;. Since the last character in &lt;code&gt;baa&lt;/code&gt; is &lt;code&gt;a&lt;/code&gt; we take the edge labeled as &lt;code&gt;a&lt;/code&gt;. Because the entire substring &lt;code&gt;baa&lt;/code&gt; can be spelled out as a path from the root we conclude that &lt;code&gt;baa&lt;/code&gt; is indeed a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s do the same for &lt;code&gt;abaaba&lt;/code&gt;. Proceeding along the green path spells out all characters. Again, we conclude that &lt;code&gt;abaaba&lt;/code&gt; is valid substring. |&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;But for &lt;code&gt;baabb&lt;/code&gt; things look different. We proceed successfully (red path) through &lt;code&gt;b&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, &lt;code&gt;a&lt;/code&gt;, and &lt;code&gt;b&lt;/code&gt;. However, there is no edge labeled &lt;code&gt;b&lt;/code&gt; at &lt;code&gt;baab&lt;/code&gt; node. Thus we fall off and conclude that &lt;code&gt;baabb&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We can also use suffix trie to check if a string is a suffix of a text. You can see that &lt;code&gt;baa&lt;/code&gt; is &lt;strong&gt;not&lt;/strong&gt; a suffix. This is because although it is valid substring, which traces a path through the trie, such path does not with an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here &lt;code&gt;aba&lt;/code&gt; is a suffix because one of the outgoing edges from the final node is labeled with &lt;code&gt;$&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_8.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Another useful feature of suffix trie is the ability to tell how many times a particular substring if found in a text. Here &lt;code&gt;aba&lt;/code&gt; is found twice as the last edge of a path spelling &lt;code&gt;aba&lt;/code&gt; leads to a node (&lt;code&gt;n&lt;/code&gt;) with two outgoing edges.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_9.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Finally, similar logic allows to find the longest repeated substrings within a text. A deepest (furthest from the root) node with multiple outgoing edges wound point to a repetitive substring. Here &lt;code&gt;aba&lt;/code&gt; is the longest repeated substring of &lt;code&gt;abaaba&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Now that we explained how suffix tries can be used to find substrings in text, let&amp;rsquo;s reduce non-branching paths in tries and convert them to trees:&lt;/p&gt;

&lt;h3 id=&#34;from-a-trie-to-a-tree&#34;&gt;From a Trie to a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_trie_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;If we collapse all non-branching paths and concatenate their labels we will get:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now, let&amp;rsquo;s label every leaf of the tree with offset (position in the text) of the corresponding suffix:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Collapsing non-branching paths has given us a somewhat more compact data structure. Now see how we can use this data structure.&lt;/p&gt;

&lt;h3 id=&#34;looking-for-substrings-in-a-tree&#34;&gt;Looking for substrings in a Tree&lt;/h3&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Checking the above suffix tree to see if &lt;code&gt;baa&lt;/code&gt; is a substring of the text. The logic is exactly the same as with suffix tries, except we now have to account for the fact that along some edges only a portion of the characters within a label will match. In this case matching characters are highlighted with uppercase: &lt;code&gt;BA&lt;/code&gt; matches along the first edge along the blue path, and only &lt;code&gt;A&lt;/code&gt; matches along the second edge. The conclusion is that &lt;code&gt;baa&lt;/code&gt; is a substring of the text.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Now let&amp;rsquo;s see if &lt;code&gt;aba&lt;/code&gt; is a suffix of our text. It matches along the blue path and the last node along this path has an outgoing edge labeled with &lt;code&gt;$&lt;/code&gt;. Thus it is a suffix.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/suffix_tree_5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And just like with suffix tries we can count occurrences of a substring by counting the number of outgoing edges from the last node.&lt;/p&gt;

&lt;h3 id=&#34;application-of-suffix-trees&#34;&gt;Application of suffix trees&lt;/h3&gt;

&lt;p&gt;One of the common applications of suffix trees to the genome data analysis is finding (longest) common subsequences between two sequences. &lt;a href=&#34;http://mummer.sourceforge.net/manual/&#34;&gt;MUMMER&lt;/a&gt; implements this approach. The following plot shows a comparison between &lt;em&gt;E. coli&lt;/em&gt; K12 and APEC O1 strains. It is computed in 8 seconds using approximately 10 Mb of RAM (K12 and APEC O1 genomes are 4.5 and 4.9. Mb, respectively).&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/mum.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To find longest common subsequences a suffix tree can be constructed from both sequences at once as shown in the following slide from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/suffix_trees.pdf&#34;&gt;Ben Langmead&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lcs.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;While suffix trees allow sequence comparisons to be performed in nearly linear time, they have large memory footprint. At some point this becomes a serious limitation making the use of suffix trees impractical. For example, indexing human genome will require ~47 Gb of memory.&lt;/p&gt;

&lt;h3 id=&#34;suffix-arrays&#34;&gt;Suffix arrays&lt;/h3&gt;

&lt;p&gt;Suffix array offers a more compact solution to representing test suffixes. It specified a lexicographic ordering of suffixes derived from text &lt;em&gt;T&lt;/em&gt;$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/sa.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A suffix array. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Because one does not need additional pointers required for tree representation, the suffix array (SA) has a significantly smaller memory footprint. For example, SA for human genome will occupy ~12Gb (down from 47Gb required for a suffix tree). Yet there is an even better idea.&lt;/p&gt;

&lt;h2 id=&#34;burrows-wheeler-transform-and-fm-index&#34;&gt;Burrows-Wheeler Transform and FM index&lt;/h2&gt;

&lt;p&gt;Burrows-Wheeler (BW) transform is a reversible permutation of a string. For example, for a string:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;create all rotations:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
ba$abaa
aba$aba
aaba$ab
baaba$a
abaaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;sort them lexicographically with &lt;code&gt;$&lt;/code&gt; as first character:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$abaaba
a$abaab
aaba$ab
aba$aba
abaaba$
ba$abaa
baaba$a
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;take the last column. It will be the BWT of the original string &lt;code&gt;abaaba$&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;abba$aa
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below is the entire procedure as one slide:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184566773&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;It has three important features that make it ideas for creating searchable compact representations of genomic data:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;It can be compressed&lt;/li&gt;
&lt;li&gt;It can be reversed to reconstruct the original string&lt;/li&gt;
&lt;li&gt;It can be used as an index&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;lf-mapping-of-burrows-wheeler-matrix-bwm&#34;&gt;LF mapping of Burrows-Wheeler Matrix (BWM)&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s take the original string &lt;code&gt;abaaba&lt;/code&gt; add &lt;code&gt;$&lt;/code&gt; and list charters ranks:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;0&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;2&lt;/sub&gt;&lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;1&lt;/sub&gt;&lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;3&lt;/sub&gt;$&lt;/p&gt;

&lt;p&gt;This ranking is done based on the order of the characters in the text (T-ranking). The order of ranked characters is preserved between the first column (F) and the last column (L):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_a.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;a&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/lf_b.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;LF mapping: &lt;strong&gt;b&lt;/strong&gt;&lt;sub&gt;s&lt;/sub&gt; has the same order in F and L&lt;/p&gt;

&lt;p&gt;Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Let&amp;rsquo;s now rank characters in order of their appearance in the sorted list of rotations (B-ranking):&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bw_b_rank.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Burrows-Wheeler transform with B-rankings. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Look at the A very important implication of this is that we can quickly jump from L to F:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/f_from_l.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;L/F jumping. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-1&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184569791&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;reversing-btw&#34;&gt;Reversing BTW&lt;/h3&gt;

&lt;p&gt;Because of the LF mapping property was can also easily reconstruct original text from its BWT:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_rev2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Reversing BWT. Image by &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/indexing_with_substrings.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-2&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568361&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;searching-bwt&#34;&gt;Searching BWT&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s try to find is the string &lt;code&gt;aba&lt;/code&gt; is present in a &amp;ldquo;genome&amp;rdquo; stored as a BWT.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;We start with suffix of $ab\color{red}a$ shown in red. This gives us a range of characters in the F column (all &lt;strong&gt;a&lt;/strong&gt;s)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We now extend to $a\color{red}{ba}$ and see how many of &lt;strong&gt;a&lt;/strong&gt;s have preceding &lt;strong&gt;b&lt;/strong&gt;s:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Finally we extend to the entire string $\color{red}{aba}$:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This tells us the range [3,5) but, as opposed to suffix array, this does not tell us where these matches occur in the actual sequence. We will come back to this problem shortly.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The shide below shows what happens when a match is &lt;strong&gt;not&lt;/strong&gt; present in the &amp;ldquo;genome&amp;rdquo;:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/bwt_q5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Querying BWT. Images from &lt;a href=&#34;http://www.cs.jhu.edu/~langmea/resources/lecture_notes/bwt_and_fm_index.pdf&#34;&gt;Ben Langmead&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h4 id=&#34;video-3&#34;&gt;Video&lt;/h4&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/184568259&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;practicalities-of-using-bwt&#34;&gt;Practicalities of using BWT&lt;/h3&gt;

&lt;p&gt;As we have seen BWT is &lt;strong&gt;very&lt;/strong&gt; compact but has few shortcomings such as, for example, the difficulty is seeing where the matches are in the actual genome as well as some performance limitations. Combining BWT with auxiliary data structures creates &lt;a href=&#34;https://en.wikipedia.org/wiki/FM-index&#34;&gt;FM-index&lt;/a&gt; (where FM stands for Full-text index in Minute space; curiously, the names of FM-index creators are &lt;a href=&#34;http://dl.acm.org/citation.cfm?id=796543&#34;&gt;Ferrigina and Manzini&lt;/a&gt;). The components of FM-index used for aligning reads to a genome are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;  BWT               Tally        Check    
                                 points 

  F       L         a b          a b       SA    
  ---------        -----        -----     ----       
  $ abaab a         1 0          1 0       6 $
  a $abaa b         1 1                    5 a$
  a aba$a b         1 2                    2 aaba$
  a ba$ab a         2 2          2 2       3 aba$
  a baaba $         2 2                    0 abaaba$
&amp;gt; b a$aba a         3 2                    4 ba$
  b aaba$ a         4 2          4 2       1 baaba$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Where:&lt;/p&gt;

&lt;h4 id=&#34;bwt&#34;&gt;BWT&lt;/h4&gt;

&lt;p&gt;BWT - the BWT (L column from above) is stored and the first column (F) can be easily reconstructed as it is simply a list of all characters (4 in the case of DNA) and their counts.&lt;/p&gt;

&lt;h4 id=&#34;tally&#34;&gt;Tally&lt;/h4&gt;

&lt;p&gt;Because we do not explicitly store ranks they can simply be obtained by counting occurrences of individual characters from the top of L column. Yet this is computationally expensive. Instead we store a tally table. At every row of the BWT matrix it shows how many times each character has been seen up to this point. For example at row marked with &lt;code&gt;&amp;gt;&lt;/code&gt; there were 3 As and 2 Bs up to this point. In reality, to save space, only a subset of Tally entries is stored as &lt;em&gt;Checkpoints&lt;/em&gt; recorded in regular intervals as shown above.&lt;/p&gt;

&lt;h4 id=&#34;sa-sample&#34;&gt;SA Sample&lt;/h4&gt;

&lt;p&gt;Finally, to find coordinates of matches in the genome offsets from an SA index are stored as SA sample (actual suffixes are not stored). This allows quickly finding location of a match within the genome by a direct look up. Similarly to Checkpoints only a fraction of these is stored to save space.&lt;/p&gt;

&lt;p&gt;Thus the final list of components is:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = integers corresponding to character type counts. In case of DNA four integers: number of As, Cs, Gs, and Ts.&lt;/li&gt;
&lt;li&gt;Last column = the BWT transform. Size is equal to the length of the original text&lt;/li&gt;
&lt;li&gt;Checkpoints = length of text $\times$ number of character types  $\times$ sampling fraction (how sparse rows are sampled)&lt;/li&gt;
&lt;li&gt;SA sample = length of text $\times$ fraction of the rows kept&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For human genome with DNA alphabet of four nucleotides, saving checkpoint every 128&lt;sup&gt;th&lt;/sup&gt; row, and saving SA offsets every 32&lt;sup&gt;nd&lt;/sup&gt; row we will have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;First column = 16 bytes&lt;/li&gt;
&lt;li&gt;Last column = 2bit $\times$ 3 billion characters = 750 MB&lt;/li&gt;
&lt;li&gt;Checkpoints = 3 billion $\times$ 4 bytes/char / 128 &amp;#x2248; 100 MB&lt;/li&gt;
&lt;li&gt;SA sample = 3 billion $\times$ 4 bytes/char /32 &amp;#x2248; 400 MB&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;next&#34;&gt;Next&lt;/h2&gt;

&lt;p&gt;We will start pitting these ideas into practice.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>4. Aligning sequences with dynamic programming</title>
      <link>https://nekrut.github.io/BMMB554/post/topic4/</link>
      <pubDate>Wed, 25 Jan 2017 11:12:04 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic4/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/topic4_cover.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;sequence-alignment&#34;&gt;Sequence alignment&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen the principle behind dynamic programming. This approach is extremely useful for comparing biological sequences, which is coincidentally one of the main points of this course. This lecture explain how this is done. In writing this text I heavily relied on wonderful &lt;a href=&#34;http://www.langmead-lab.org/teaching-materials/&#34;&gt;course&lt;/a&gt; taught by Ben Langmead at Johns Hopkins. The cover image shows pairwise alignments for human, mouse, and dog &lt;em&gt;KIF3&lt;/em&gt; locus from &lt;a href=&#34;http://genome.cshlp.org/content/10/9/1304.long&#34;&gt;Dubchak et al. 2000&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;how-different-are-two-sequences&#34;&gt;How different are two sequences?&lt;/h2&gt;

&lt;p&gt;Suppose you have two sequences of the same length:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;How different are they? In other words, how many bases should be change to turn one sequence onto the other:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A
| | * * * | * * *
A C T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;the vertical lines above indicate positions that are identical between the two sequences, while asterisks show differences. It will take six substitutions to turn one sequence into the other. This number &amp;ndash; six substitutions &amp;ndash; is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Hamming_distance&#34;&gt;&lt;em&gt;Hamming distance&lt;/em&gt;&lt;/a&gt; or the &lt;em&gt;minimal&lt;/em&gt; number of substitutions required to turn one string into another. The code below computes the Hamming distance. Try it. You can change &lt;code&gt;seq1&lt;/code&gt; and &lt;code&gt;seq2&lt;/code&gt; into whatever you want except that they should have the same length.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/99a02b790a?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now in addition to &lt;em&gt;substitutions&lt;/em&gt; (i.e., changing one character into another) let&amp;rsquo;s allow &lt;strong&gt;instertions&lt;/strong&gt; and &lt;strong&gt;deletions&lt;/strong&gt;. This will essentially allow us to insert dashes (gaps) between characters:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A C A T G C C T A -
| | * | | | | | | *
A C - T G C C T A C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this case the &lt;a href=&#34;https://en.wikipedia.org/wiki/Edit_distance&#34;&gt;&lt;strong&gt;edit distance&lt;/strong&gt;&lt;/a&gt; between two sequences is 2. It is defined as the minimum number of operations (substitutions, insertions, and deletions) requited to turn one string into another. The compared strings do not have to be of the same length to be able to compute the edit distance as we can compensate for length differences using deletions and insertions. While the situation above (where we inserted two dashes) is biologically much more meaningful (and realistic), it is much more difficult to find.&lt;/p&gt;

&lt;h1 id=&#34;generalizing-the-problem&#34;&gt;Generalizing the problem&lt;/h1&gt;

&lt;p&gt;Before we can develop an algorithm that will help us to compute the edit distance let&amp;rsquo;s develop a general framework that would allow us to think about the problem in exact terms. Let&amp;rsquo;s look at a pair of VERY long sequences. So long, that we do not even see the left end &amp;ndash; it disappears into $\infty$:&lt;/p&gt;

&lt;div&gt;
    $$
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ G}\\
        \color{red}{\texttt{.....A C T G C C T A}}\texttt{ C}\\
    $$
&lt;/div&gt;

&lt;p&gt;the red parts of the two sequences represent &lt;strong&gt;prefixes&lt;/strong&gt; for the last nucleotides shown in black. Let&amp;rsquo;s assume that the edit distance between the two prefixes is known (don&amp;rsquo;t ask how we know, we just do). For simplicity let&amp;rsquo;s &amp;ldquo;compact&amp;rdquo; the prefix of the first sequence into $\alpha$ and the prefix of the second sequence into $\beta$:&lt;/p&gt;

&lt;div&gt;
    $$
        \alpha \texttt{G}\\
        \beta  \texttt{C}
    $$
&lt;/div&gt;

&lt;p&gt;again, the edit distance between $\alpha$ and $\beta$ is known to us. The three possibilities for computing the edit distance between $\alpha G$ and $\beta C$ are:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{G},\beta\texttt{C})  = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + 1 \leftarrow\ because\ they\ do\ not\ match&amp; \\
                    Edit\ Distance(\alpha\texttt{G},\beta) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap&amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{C}) + 1 \leftarrow\ because\ we\ are\ adding\ a\ gap
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;but we not always have $\texttt{G}$ and $\texttt{C}$ as two last nucleotiodes, so for the general case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ (nucleotides match) and $\delta(x,y) = 1$ if $x \neq y$ (nucleotides do not match). The $\delta(x,y)$ has a particular meaning. If the two nucleotides at the end are equal to each other, there is nothing to be done &amp;ndash; no substitution operation is necessary. If a substitution is necessary however, we will record this by adding 1. When we will be talking about global and local alignment below the power of $\delta(x,y)$ will become even more clear.&lt;/p&gt;

&lt;p&gt;Recall the change problem from the previous lecture. We can write an algorithm that would exhaustively evaluate the above expression for all possible suffixes. This algorithm is below. Try executing it. It will take roughly ~30 seconds to find the edit distance between the two sequences used in the beginning of this lecture:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/eff3a798bf?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Again, don&amp;rsquo;t worry if Python looks scary to you. The take-home-message here is that it takes a very long time to compute the edit distance between two sequences that are only &lt;strong&gt;nine&lt;/strong&gt; nucleotides long! Why is this happening? Figure 1 below shows a small subset of situations the algorithm is evaluating for two very short strings $\texttt{TAG}$ and $\texttt{TAC}$:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/editDist.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | A fraction of situations evaluated by the naïve algorithm for computing the edit distance. Just like in the case of the change problem discussed in the previous lecture a lot of time is wasted on computing distances between suffixes that has been seen more than once (shown in red).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;To understand the magnitude of this problem let&amp;rsquo;s look at slightly modified version of the previous Python code below. All we do here is keeping track how many times a particular pair of suffixes (in this case $\texttt{AC}$ and $\texttt{AC}$) are seen by the program. The number is staggering: 48,639. So this algorithm is &lt;strong&gt;extremely&lt;/strong&gt; wasteful.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/8994bfe46e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;While this approach to the edit distance problem is correct, it will hardly help us on the genome-wide scale. Just like in case of the change problem and Manhattan tourist problem dynamic programming is going to save the day.&lt;/p&gt;

&lt;h2 id=&#34;video&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583352&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;dynamic-programming-to-the-rescue&#34;&gt;Dynamic programming to the rescue&lt;/h1&gt;

&lt;p&gt;Let&amp;rsquo;s recall Manhattan tourist problem. The objective of the problem was to find a path through Manhattan that visits the highest number of landmarks. If you remember, we represented Manhattan as a matrix where each edge was representing a block and was labeled with the number of landmarks within that block. Here, we will use a similar idea to find an optimal &lt;strong&gt;alignment&lt;/strong&gt; between two sequences. Note that so far this is the first time we use the term &lt;strong&gt;alignment&lt;/strong&gt; in this section. It turns out that in order to find the alignment we first need to learn how to compute edit distances between sequences efficiently. So, suppose we have two sequences that deliberately have different lengths:&lt;/p&gt;

&lt;p&gt;$\texttt{G C T A T A C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G C G T A T G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s represent them as the following matrix where the first character $\epsilon$ represents an empty string:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon\\
                    \hline
                    G\\
                    \hline
                    C\\
                    \hline
                    G\\
                    \hline
                    T\\
                    \hline
                    A\\
                    \hline
                    T\\
                    \hline
                    G\\
                    \hline
                    C

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Let&amp;rsquo;s fill the first column and first raw of the matrix. Because the distance between a string and an empty string is equal to the length of the string (e.g., a distance between string $\texttt{TCG}$ and an empty string is 3) this resulting matrix will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; 1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Now, let&amp;rsquo;s fill in the cell between $\texttt{G}$ and $\texttt{G}$. Recall that:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $\delta(x,y) = 0$ if $x = y$ and $\delta(x,y) = 1$ if $x \neq y$. And now let&amp;rsquo;s color each of the cells corresponding to each part of the above expression:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

  \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;In this specific case:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\epsilon\texttt{G},\epsilon\texttt{G}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\epsilon,\epsilon) + \delta(G,G)\ or\ 0\ +\ 0\ =\ 0} &amp; \\
                    \color{blue}{Edit\ Distance(\epsilon\texttt{G},\epsilon) + 1\ or\ 1\ +\ 1\ =\ 2} &amp; \\
                    \color{green}{Edit\ Distance(\epsilon,\epsilon\texttt{G}) + 1\ or\ 1\ +\ 1\ =\ 2}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This minimum of 0, 2, and 2 will be 0, so we are putting zero into that cell:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C \\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; \color{green}1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                    G &amp; \color{blue}1 &amp; \color{red}0\\
                    \hline
                    C &amp; 2\\
                    \hline
                    G &amp; 3\\
                    \hline
                    T &amp; 4\\
                    \hline
                    A &amp; 5\\
                    \hline
                    T &amp; 6\\
                    \hline
                    G &amp; 7\\
                    \hline
                    C &amp; 8

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Using this uncomplicated logic we can fill the entire matrix like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}

 \\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;The lower rightmost cell highlighted in red is special. It contains the value for the edit distance between the two strings. The following Python script implements this idea. You can see that it is essentially instantaneous:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/1bec8f9150?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;video-1&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183583042&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;from-edit-distance-to-alignment&#34;&gt;From edit distance to alignment&lt;/h1&gt;

&lt;p&gt;In the previous section we have filled the dynamic programming matrix to find out that the edit distance between the sequences is 2. But in biological applications we are most often interested not in edit distance &lt;em&gt;per se&lt;/em&gt; but in the actual &lt;strong&gt;alignment&lt;/strong&gt; between two sequences.&lt;/p&gt;

&lt;h2 id=&#34;the-traceback&#34;&gt;The traceback&lt;/h2&gt;

&lt;p&gt;We can use the dynamic programming matrix to reconstruct the alignment. This is done using &lt;strong&gt;traceback&lt;/strong&gt; procedure. Let&amp;rsquo;s look at the rightmost bottom cell of the matrix highlighted in &lt;strong&gt;bold&lt;/strong&gt;:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \textbf{2}

 \end{array}

    $$
&lt;/div&gt;

&lt;p&gt;When we were filling this matrix did we come to this point from above ($\color{green}3$), from the left ($\color{blue}3$), or diagonally ($\color{red}2$):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ | c | c }
                \hline
                   \color{red}2 &amp; \color{green}3\\
                \hline
                   \color{blue}3 &amp; \textbf{2}
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Remembering the fact that when filling the matrix we are trying to minimize the expression for edit distance, we clearly arrived to this point diagonally from $\color{red}2$. This because arriving from top ($\color{green}3$) or left ($\color{blue}3$) would add 1. So we highlight diagonal cell in red:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Continuing this idea we will draw a trace like the one below until we hit an interesting point:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;At this point we have arrived to this value from the top because 0 + 1 = 1. If we were arriving diagonally it would be 1 + 1 = 2 since $\texttt{G}\ \neq\ \texttt{C}$, so we are turning traceback upward and then again diagonally:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; G &amp; C &amp; T &amp; A &amp; T &amp; A &amp; C\\
                    \hline
                    \epsilon &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7\\
                    \hline
                           G &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6\\
                    \hline
                           C &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           G &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\
                    \hline
                           T &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3 &amp; 4\\
                    \hline
                           A &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3\\
                    \hline
                           G &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}2 &amp; 3\\
                    \hline
                           C &amp; 8 &amp; 7 &amp; 6 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; \color{red}2

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Now going through traceback line from the top we are getting the following alignment between two two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;G C - T A T A C
| | * | | | * |
G C G T A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;approximate-matching&#34;&gt;Approximate matching&lt;/h2&gt;

&lt;p&gt;Let&amp;rsquo;s now get a bit more practical. In many real biological applications we are trying to see if one sequence is contained within another. So, how can we use dynamic programming to find if there is an approximate match between two sequences $\it\texttt{P}$ and $\texttt{T}$?&lt;/p&gt;

&lt;p&gt;Suppose we have two strings:&lt;/p&gt;

&lt;p&gt;$\it{T} = \texttt{A A C C C T A T G T C A T G C C T T G G A}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{P} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s construct the following matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                               \\
                    \hline
                              T\\
                    \hline
                              A\\
                    \hline
                              C\\
                    \hline
                              G\\
                    \hline
                              T\\
                    \hline
                              C\\
                    \hline
                              A\\
                    \hline
                              G\\
                    \hline
                              C\\

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{T}\ is\ horizontal\ while\ \texttt{P}\ is\ vertical.

 $$

&lt;/div&gt;

&lt;p&gt;Let me remind you that our goal is to find where $\it\texttt{P}$ matches $\texttt{T}$. &lt;em&gt;A priori&lt;/em&gt; we do not know when it may be, so we will start by filling the entire first row with zeroes. This is because the match between $\it\texttt{P}$ and $\texttt{T}$ may start at any point up there. The first column we will initialize the same way we did previously: with increasing sequence of numbers:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                         T &amp; 1\\
                    \hline
                         A &amp; 2\\
                    \hline
                         C &amp; 3\\
                    \hline
                         G &amp; 4\\
                    \hline
                         T &amp; 5\\
                    \hline
                         C &amp; 6\\
                    \hline
                         A &amp; 7\\
                    \hline
                         G &amp; 8\\
                    \hline
                         C &amp; 9\\

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now let&amp;rsquo;s fill this matrix in using the same logic we used before:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Now that we have filled in the complete matrix let&amp;rsquo;s look at the bottom row. Instead of using the rightmost cell we will find a cell with the lowest number. That would be 2 (highlighted in red):&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;Starting already familiar traceback procedure at that cell we will get the following path through the matrix:&lt;/p&gt;

&lt;div&gt;
$$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                    &amp; \epsilon &amp; A &amp; A &amp; C &amp; C &amp; C &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C &amp; C &amp; T &amp; T &amp; G &amp; G &amp; A\\
                    \hline
                             &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; \color{red}0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                           T &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 0 &amp; 1 &amp; 1 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 1 &amp; 1\\
                    \hline
                           A &amp; 2 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}0 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 2 &amp; 1 &amp; 1 &amp; 1 &amp; 2 &amp; 1\\
                    \hline
                           C &amp; 3 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 1 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                           G &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 2 &amp; 2 &amp; 2 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; 3\\
                    \hline
                           T &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3\\
                    \hline
                           C &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 3 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; 2 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 3 &amp; 4 &amp; 4 &amp; 4\\
                    \hline
                           A &amp; 7 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; \color{red}1 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 4 &amp; 5 &amp; 4\\
                    \hline
                           G &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 3 &amp; 2 &amp; 2 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 4 &amp; 4 &amp; 5\\
                    \hline
                           C &amp; 9 &amp; 8 &amp; 7 &amp; 6 &amp; 6 &amp; 5 &amp; 6 &amp; 6 &amp; 6 &amp; 5 &amp; 5 &amp; 4 &amp; 3 &amp; 3 &amp; 3 &amp; \color{red}2 &amp; 3 &amp; 4 &amp; 5 &amp; 5 &amp; 5 &amp; 5

 \end{array}
 $$

&lt;/div&gt;

&lt;p&gt;for a corresponding alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;A A C C C T A T G T C A T G C C T T G G A
          | | * | | | | * | | 
          T A C G T C A - G C
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;video-2&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183587535&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;global-alignment&#34;&gt;Global alignment&lt;/h1&gt;

&lt;p&gt;So far in filling the dynamic programming matrix we were using the following expression to compute the number within each cell:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    \color{red}{Edit\ Distance(\alpha,\beta) + \delta(x,y)} &amp; \\
                    \color{blue}{Edit\ Distance(\alpha\texttt{x},\beta) + 1} &amp; \\
                    \color{green}{Edit\ Distance(\alpha,\beta\texttt{y}) + 1}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;Basically we were adding 1 if there was a mismatch (the $\delta$ function) and also adding 1 for every gap. This however is not biologically realistic. If we look at the rates of different rates of mutations in the human genome we will see that they vary dramatically. Let&amp;rsquo;s look at substitutions first:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/TsTv.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | There are two kinds of nucleotide substitutions: Transitions and Transversions. Transitions are substitutions between nucleotides belonging to the same chemical group. For example, a substitution of Adenine, a purine, to Guanine, also a purine, is a transition. Transversions, on the other hand, occur between chemically dissimilar nucleotides. For example, any substitution of a purine to a pyrimidine and vice verse will be a transition. (Image from &lt;a href=&#34;https://en.wikipedia.org/wiki/Transversion&#34;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;you can see that there are move ways in which we can have a transversion. Despite this fact transversions are significantly less frequent that transitions. In fact in human the so called &lt;em&gt;Transition/Transversion ratio&lt;/em&gt; ($Ts:Tv$) is close to &lt;a href=&#34;http://www.pnas.org/content/107/3/961.long&#34;&gt;2&lt;/a&gt; (or even higher in &lt;a href=&#34;http://genomebiology.biomedcentral.com/articles/10.1186/gb-2011-12-9-r84&#34;&gt;coding regions&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The situation with insertions and deletions (that are often called &lt;em&gt;indels&lt;/em&gt;) is similar in that are relatively rare and their rarity increases with size. A single nucleotide indel may occur every 1,000 bases on average, while a two-nucleotide deletion occurs every 3,000 bases and so on (see &lt;a href=&#34;http://genome.cshlp.org/content/23/5/749.abstract&#34;&gt;Montgomery et al. 2013&lt;/a&gt; for a more detailed statistics).&lt;/p&gt;

&lt;p&gt;As a result it is simply unrealistic to use &amp;ldquo;1&amp;rdquo; is all cases. Instead, we need to &lt;em&gt;penalize&lt;/em&gt; rare events more than we penalize frequent, more probable events. Let&amp;rsquo;s create a &lt;em&gt;penalty matrix&lt;/em&gt; to achieve this goal:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; \color{orange}8\\  
                   C &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{orange}8\\
                   G &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{blue}4 &amp; \color{orange}8\\
                   T &amp; \color{blue}4 &amp; \color{red}2 &amp; \color{blue}4 &amp; 0 &amp; \color{orange}8\\
                   - &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \color{orange}8 &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Here if two nucleotides match, the penalty is 0. For a transitional substitution we pay $\color{red}2$ and for a transversional we pay $\color{blue}4$. The gap is the most expensive at $\color{orange}8$.&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\it{X} = \texttt{T A T G T C A T G C}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\it{Y} = \texttt{T A C G T C A G C}$&lt;/p&gt;

&lt;p&gt;First, we need to fill the following dynamic programming matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                    \epsilon \\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;But now we using penalty matrix generated above to calculate values in each cell. Specifically, before we were using this expression:&lt;/p&gt;

&lt;div&gt;

$$Edit\ Distance(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    Edit\ Distance(\alpha,\beta) + \delta(x,y) &amp; \\
                    Edit\ Distance(\alpha\texttt{x},\beta) + 1 &amp; \\
                    Edit\ Distance(\alpha,\beta\texttt{y}) + 1
             \end{cases}$$
&lt;/div&gt;

&lt;p&gt;but now, we will change it into this:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = min\begin{cases} 
                    D(\alpha,\beta) + p\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + p\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + p\texttt{(-,y)}
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;where $p\texttt{(x,y)}$, $p\texttt{(x,-)}$, and $p\texttt{(-,y)}$ are taken directly from penalty matrix. Let&amp;rsquo;s start with the first row. In this row we can only fill from the left were we essentially inserting a gap every time. Since the gap penalty is 8 we will get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T \\
                    \hline
                           A \\
                    \hline
                           C \\
                    \hline
                           G \\
                    \hline
                           T \\
                    \hline
                           C \\
                    \hline
                           A \\
                    \hline
                           G \\
                    \hline
                           C 

 \end{array}

\\

\textbf{Note}: sequence\ \texttt{X}\ is\ vertical\ and\ sequence\ \texttt{Y}\ is\ horizontal.

    $$
&lt;/div&gt;

&lt;p&gt;Similarly, for the first column we get:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8\\
                    \hline
                           A &amp; 16\\
                    \hline
                           C &amp; 24\\
                    \hline
                           G &amp; 32\\
                    \hline
                           T &amp; 40\\
                    \hline
                           C &amp; 48\\
                    \hline
                           A &amp; 56\\
                    \hline
                           G &amp; 64\\
                    \hline
                           C &amp; 72

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;and finally the full matrix:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; 0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; 2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 2 &amp; 10 &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; 10 &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; 10

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Drawing a traceback through this matrix will give us:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c}
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; G &amp; T &amp; C &amp; A &amp; T &amp; G &amp; C\\
                    \hline
                \epsilon &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72 &amp; 80\\
                    \hline
                           T &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64 &amp; 72\\
                    \hline
                           A &amp; 16 &amp; 8 &amp; \color{red}0 &amp; 8 &amp; 16 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56 &amp; 64\\
                    \hline
                           C &amp; 24 &amp; 16 &amp; 8 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 24 &amp; 32 &amp; 40 &amp; 48 &amp; 56\\
                    \hline
                           G &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 40 &amp; 48\\
                    \hline
                           T &amp; 40 &amp; 32 &amp; 24 &amp; 16 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34 &amp; 42\\
                    \hline
                           C &amp; 48 &amp; 40 &amp; 32 &amp; 24 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; 10 &amp; 18 &amp; 26 &amp; 34\\
                    \hline
                           A &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; \color{red}2 &amp; \color{red}{10} &amp; 18 &amp; 26\\
                    \hline
                           G &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 32 &amp; 26 &amp; 18 &amp; 10 &amp; 6 &amp; \color{red}{10} &amp; 18\\
                    \hline
                           C &amp; 72 &amp; 64 &amp; 56 &amp; 48 &amp; 40 &amp; 34 &amp; 26 &amp; 18 &amp; 12 &amp; 10 &amp; \color{red}{10}

 \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the following alignment:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;T A C G T C A - G C
| | * | | | | * | | 
T A T G T C A T G C
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The following Python code implements Global alignment approach we have seen above. Note that the first function, &lt;code&gt;exampleCost&lt;/code&gt;, can be changed to set different value for the penalty matrix. You can play with it here:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/911a7ddd2e?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h2 id=&#34;local-alignment&#34;&gt;Local alignment&lt;/h2&gt;

&lt;p&gt;Global alignment discussed above works only in cases when we truly expect sequences to match across their entire lengths. In majority of biological application this is rarely the case. For instance, suppose you want to compare two bacterial genomes to figure out if they have matching sequences. Local alignment algorithm helps with this challenge. Surprisingly, it is almost identical to the approaches we used before. So here is our problem:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Sequence 1: ##################################################
                              |||||||||||||||||
Sequence 2:         #################################################
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;there are two sequences (shown with # characters) and they share a region of high similarity (indicated by vertical lines). How do we find this region? We cannot use global alignment logic here because across the majority of their lengths these sequences are dissimilar.&lt;/p&gt;

&lt;p&gt;To approach this problem we will change our penalty strategy. Instead of giving a high value for each mismatch we will instead give negative penalties. Only matches get positive rewards. Here is an example of such &lt;em&gt;scoring matrix&lt;/em&gt; (as opposed to the &lt;em&gt;penalty matrix&lt;/em&gt; we&amp;rsquo;ve used before):&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c  c  c  c  c }
                     &amp; A &amp; C &amp; G &amp; T &amp; -\\
                  \hline
                   A &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; \color{orange}{-6}\\  
                   C &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4} &amp; \color{red}{-4}  &amp; \color{orange}{-6}\\
                   G &amp; \color{red}{-4} &amp; \color{blue}{-4} &amp; 2 &amp; \color{blue}{-4}  &amp; \color{orange}{-6}\\
                   T &amp; \color{blue}{-4} &amp; \color{red}{-4} &amp; \color{blue}{-4}  &amp; 2 &amp; \color{orange}{-6}\\
                   - &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \color{orange}{-6} &amp; \\
                \hline
                   
    \end{array}
    $$
&lt;/div&gt;

&lt;p&gt;Our scoring logic will also change:&lt;/p&gt;

&lt;div&gt;

$$D(\alpha\texttt{x},\beta\texttt{y}) = max\begin{cases} 
                    D(\alpha,\beta) + s\texttt{(x,y)} &amp; \\
                    D(\alpha\texttt{x},\beta) + s\texttt{(x,-)} &amp; \\
                    D(\alpha,\beta\texttt{y}) + s\texttt{(-,y)} &amp; \\
                    0
             \end{cases}$$

&lt;/div&gt;

&lt;p&gt;We are now looking for &lt;strong&gt;maximum&lt;/strong&gt; and use &lt;em&gt;0&lt;/em&gt; to prevent having negative values in the matrix. This also implies that the first row and column will now be filled with zeros. Let apply this to two sequences:&lt;/p&gt;

&lt;p&gt;Now, let&amp;rsquo;s align two sequences:&lt;/p&gt;

&lt;p&gt;$\texttt{T A T A T G C G G C G T T T}$&lt;/p&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;p&gt;$\texttt{G G T A T G C T G G C G C T A}$&lt;/p&gt;

&lt;p&gt;Dynamic programming matrix with initialized first row and column will look like this:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\ 
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          G &amp; 0\\
                    \hline
                          C &amp; 0\\
                    \hline
                          T &amp; 0\\
                    \hline
                          A &amp; 0\\
                   
\end{array}

\\

\textbf{Remember}: sequence\ \texttt{X}\ is\ vertical\ while\ \texttt{Y}\ is\ horizontal.


    $$
&lt;/div&gt;

&lt;p&gt;Filling it completely will yield the following matrix. Note that clues to where the local alignment may be are given off by positive numbers in the sea of 0s:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 10 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;To identify to boundary of the local alignment we need to identify the cell with the &lt;strong&gt;highest&lt;/strong&gt; value. This cell has value of $\color{red}{12}$ and is highlighted above. Using traceback procedure we will find:&lt;/p&gt;

&lt;div&gt;
    $$
    \begin{array}{ c | c | c | c | c | c | c | c | c | c | c | c | c | c }
                     &amp; \epsilon &amp; T &amp; A &amp; T &amp; A &amp; T &amp; G &amp; C &amp; G &amp; G &amp; C &amp; G &amp; T &amp; T &amp; T\\
                     \hline
                   \epsilon &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 4 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 2 &amp; 2\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\ 
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 0 &amp; \color{red}6 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}8 &amp; 2 &amp; 2 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; \color{red}4 &amp; 6 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 2 &amp; 2\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; \color{red}6 &amp; 8 &amp; 2 &amp; 2 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; \color{red}8 &amp; 4 &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; \color{red}{10} &amp; 4 &amp; 0 &amp; 0 &amp; 0\\
                    \hline
                          G &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 0 &amp; 6 &amp; 2 &amp; 4 &amp; \color{red}{12} &amp; 6 &amp; 0 &amp; 0\\
                    \hline
                          C &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 2 &amp; 0\\
                    \hline
                          T &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 2 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 8 &amp; 10 &amp; 4\\
                    \hline
                          A &amp; 0 &amp; 0 &amp; 4 &amp; 0 &amp; 4 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 2 &amp; 4 &amp; 6\\
                   
\end{array}
    $$
&lt;/div&gt;

&lt;p&gt;This corresponds to the best local alignment between the two sequences:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; T A T A T G C - G G C G T T T
     | | | | | * | | | |
 G G T A T G C T G G C G C T A
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Here is a Python representation of this approach:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python3/aa05b81499?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;600&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;This algorithm was developed by &lt;a href=&#34;http://dornsife.usc.edu/assets/sites/516/docs/papers/msw_papers/msw-042.pdf&#34;&gt;Temple Smith and Michael Waterman&lt;/a&gt; in 1981. This is why it is most often called Smith Waterman local alignment algorithm.&lt;/p&gt;

&lt;h2 id=&#34;video-3&#34;&gt;Video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/183588416&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;next&#34;&gt;Next&amp;hellip;&lt;/h1&gt;

&lt;p&gt;In the next lecture we will learn about speeding sequence searches with indexing and talk about mappers.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>3. Sequence alignment: Introductory concepts</title>
      <link>https://nekrut.github.io/BMMB554/post/topic3/</link>
      <pubDate>Wed, 25 Jan 2017 10:43:18 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic3/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/nyc.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;introduction&#34;&gt;Introduction&lt;/h1&gt;

&lt;p&gt;In the previous lecture we have seen several ways in which DNA sequence data can be accumulated (the reason for having Manhattan in the figure above will be apparent a bit later). Because sequencing machines (especially the ones made by Illumina) generate billions of sequences (called reads) from every run, the real challenge is what one does with all this data once sequencing is done. So before we get into details of technology and its application we need to introduce some basic algorithmic concepts related to sequence analysis. Today we will start with &lt;strong&gt;dynamic programming&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-the-change-problem&#34;&gt;Dynamic programming for the change problem&lt;/h2&gt;

&lt;p&gt;When introducing algorithmic concepts to biological audience it often becomes critical to use good examples. One of the people who probably succeeded most in this endeavor is &lt;a href=&#34;http://cseweb.ucsd.edu/~ppevzner/&#34;&gt;Pavel Pevzner&lt;/a&gt;, a Ronald R. Taylor Professor of Computer Science at UCSD, who (together with &lt;a href=&#34;http://compeau.cbd.cmu.edu/&#34;&gt;Phillip Compeau&lt;/a&gt;) published a very informatics (and entertaining) &lt;a href=&#34;https://www.amazon.com/Bioinformatics-Algorithms-Active-Learning-Approach/dp/0990374602&#34;&gt;book&lt;/a&gt; on the subject of computational biology. The example I use below comes from this book.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Suppose you are a cashier who&amp;rsquo;s job is, generally speaking, to receive money and to give out change. Suppose that someone buys something that costs \$9.37 and gives you a 10 dollar bill. You need to give \$0.63 back in smallest possible number of coins. The US coin denominations are:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;100 (1 dollar)&lt;/li&gt;
&lt;li&gt;50 (half-dollar)&lt;/li&gt;
&lt;li&gt;25 (quarter)&lt;/li&gt;
&lt;li&gt;10 (dime)&lt;/li&gt;
&lt;li&gt;5 (nickel)&lt;/li&gt;
&lt;li&gt;1 (penny)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, given these coins you will:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;start with the largest coin smaller than the amount you need to give back = &lt;strong&gt;50 Cents&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;repeat for the remaining $0.13 and select &lt;strong&gt;10 Cents&lt;/strong&gt;  (&lt;strong&gt;NOTE&lt;/strong&gt;: this is recursion happening)&lt;/li&gt;
&lt;li&gt;finish with three 1 cent counts thus you ended up with 5 (&lt;strong&gt;50&lt;/strong&gt; + &lt;strong&gt;10&lt;/strong&gt; + 3x&lt;strong&gt;1&lt;/strong&gt;) coins.&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;solving-problem-exhaustively&#34;&gt;Solving problem exhaustively&lt;/h3&gt;

&lt;p&gt;Now (as suggested &lt;a href=&#34;http://interactivepython.org/runestone/static/pythonds/Recursion/DynamicProgramming.html&#34;&gt;here&lt;/a&gt;) suppose you are a cashier in a strange country where there is also a &lt;strong&gt;21&lt;/strong&gt; cent coin in circulation. By using the algorithm above you will still give your customer 5 coins, while the &amp;ldquo;correct&amp;rdquo; solution will certainly be giving him/her 3 &lt;strong&gt;21&lt;/strong&gt; cent coins. So the algorithm we used above simply does not work.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s rephrase the problem. The smallest number of coins summing up to $0.63 cents (in our strange country with a &lt;strong&gt;21&lt;/strong&gt; cent coin) will be:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.62 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.58 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.53 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.42 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.38 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.13 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; | First iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Next, for each of these possibilities we will repeat this again. For example for $0.62 will consider:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.61 plus a &lt;strong&gt;1&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.57 plus a &lt;strong&gt;5&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.52 plus a &lt;strong&gt;10&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.41 plus a &lt;strong&gt;21&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.37 plus a &lt;strong&gt;25&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;li&gt;a minimal collection of coins summing up to $0.12 plus a &lt;strong&gt;50&lt;/strong&gt; cent coin&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 2&lt;/strong&gt; | Second iteration&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And again. For $0.58 we will have:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 3&lt;/strong&gt; | Note that amounts highlighted in red are repeated. Below we explain why this is &lt;strong&gt;really bad&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;and so on. Basically, as every iteration we are trying to find:&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 21) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                         &amp; \\ 1 + numCoins(original\_amount - 50) 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;While this algorithm will find us the smallest number of coins necessary to give out a particular amount in change, it does this at a horrific price: it is extremely inefficient as it recomputes all possibilities at every iteration. For instance, if we ask the algorithm to compute the minimal number of coins necessary to give out 63 cents in change in a country with only four coins (1, 5, 10, and 25 cents) it will take &lt;strong&gt;67,716,925&lt;/strong&gt; iterations (recursive calls). As a result you will probably loose all of your customers while they are waiting for the change.&lt;/p&gt;

&lt;p&gt;The code snippet below implements this algorithm (do not worry if you don&amp;rsquo;t quire understand python. It is OK for now). If you execute it (press the play button) your browser will likely crash as it will get tired waiting for result to come back (try it anyway):&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/a74fb5b988?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;caching-helps-a-bit&#34;&gt;Caching helps a bit&lt;/h3&gt;

&lt;p&gt;One potential way to solve our problem in a reasonable amount of time is to take advantage of red nodes shown in Figure 3. What if before calling the function we check if a minimum number of coins for a particular amount was already computed? Apparently this speeds things up quite dramatically:&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/efcc5b3667?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;Now you can see that it takes under a second to find that it takes 3 coins to give 63 cents in change in a country with 1, 5, 10, 21, and 25 cent coins. Yet this script still makes 221 calls (better than 67,716,925, but still a lot) for find the answer.&lt;/p&gt;

&lt;h3 id=&#34;introducing-dynamic-programming&#34;&gt;Introducing dynamic programming&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s flip things around. Instead of starting from &lt;strong&gt;63&lt;/strong&gt; cents and going down through the tree as shown in Figs 1 - 3 we will instead compute the minimal number of coins for every value from 1 to 63. To save space, let&amp;rsquo;s instead assume that we need to give 11 cents in change. Let&amp;rsquo;s compute a dynamic programming array for minimal number of coins between 1 and 11 (you may need to scroll sideways if your screen is small):&lt;/p&gt;

&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt;Amount                   0  1  2  3  4  5  6  7  8  9 10 11
Minimum number of coins  0  1  2  3  4  1  2  3  4  5  1  2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Table 1&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;for amounts between &lt;strong&gt;1&lt;/strong&gt; and &lt;strong&gt;4&lt;/strong&gt;, we have no choice, since we have only pennies. At &lt;strong&gt;5&lt;/strong&gt; we can either use 5 pennies or 1 nickel. According to this strategy (for a country with 1, 5, 10, and 25 cent coins):&lt;/p&gt;

&lt;div&gt;

$$numCoins = min\begin{cases} 1 + numCoins(original\_amount - 1) 
                         &amp; \\ 1 + numCoins(original\_amount - 5) 
                         &amp; \\ 1 + numCoins(original\_amount - 10) 
                         &amp; \\ 1 + numCoins(original\_amount - 25) 
                                         \end{cases}$$

&lt;/div&gt;

&lt;p&gt;nickel wins (needs just 1 coin). From &lt;strong&gt;6&lt;/strong&gt; to &lt;strong&gt;9&lt;/strong&gt; we can either use all pennies (values will be 6, 7, 8, and 9) or a combination of nickel and pennies (values will be 2, 3, 4, 5). Again, smaller values win.&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s now use this table to decide what is the minimum number of coins necessary to give 11 cents in change:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/change4.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 4&lt;/strong&gt; | Making change for 11 cents. Let&amp;rsquo;s look at leftmost branch. If you give 1 cent in change, you are left with 10 more to give. You consult Table 1 above and see that 10 cents can be given with 1 coin, so it will be 1 + 1 = 2 coins. In the center branch we give 5 cents in one coin and have 6 more cents to give. Looking at Table 1 tells us that 6 cents can be given in 2 coins, so 1 + 2 = 3 coins. Finally, in the rightmost branch giving 10 cents as one coin leaves 1 cent to give in change, which is also 1 coin, so 1 + 1 = 2. Thus we can either give 10 cents + 1 cent or 1 cent + 10 cents, which is equivalent since in both cases we give only 2 coins.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The following python code implements a function called &lt;code&gt;dynamicCoinChange&lt;/code&gt; which computes a table (like Table 1) for any amount. In line 20 of the script we print a value corresponding to the amount we need to give back. That value is the minimum number of coins. Note that this program takes virtually no time to run.&lt;/p&gt;

&lt;iframe src=&#34;https://trinket.io/embed/python/81c07a3750?toggleCode=true&#34; width=&#34;100%&#34; height=&#34;400&#34; frameborder=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;&lt;strong&gt;So&lt;/strong&gt;, dynamic programming is a methodology where complex problems are broken down to simple subproblems, that are computed just once and then used to solve the complete problem. In this example, we first pre-compute the number of coins needed to make change for any amount up to the required one, and then produce the answer.&lt;/p&gt;

&lt;h2 id=&#34;dynamic-programming-for-manhattan-tourist-problem&#34;&gt;Dynamic programming for Manhattan tourist problem&lt;/h2&gt;

&lt;p&gt;Now let&amp;rsquo;s get into a multi(2)-dimensional world beautifully elaborated in Jones and Pevzner (&lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;2004&lt;/a&gt;) book:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.3.png&#34; alt=&#34;&#34; /&gt;|&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Figure 5&lt;/strong&gt; | Reproduced from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The goal of this game is to visit the &lt;strong&gt;maximum number&lt;/strong&gt; of attractions along a stroll across Manhattan.
Let&amp;rsquo;s formalize this a bit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;city = &lt;em&gt;n&lt;/em&gt; x &lt;em&gt;m&lt;/em&gt; directed graph&lt;/li&gt;
&lt;li&gt;node = intersection&lt;/li&gt;
&lt;li&gt;edge = block&lt;/li&gt;
&lt;li&gt;edge weight = number of attractions along a city block&lt;/li&gt;
&lt;li&gt;start node = source&lt;/li&gt;
&lt;li&gt;end node = sink&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;right&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;center&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4a.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/6.4b.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;right&#34;&gt;The city&lt;/td&gt;
&lt;td align=&#34;center&#34;&gt;and a path through it (Figure 6.4 from &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The figure above provides a path from source to the sink, yet this path is not the longest. We can identify the optimal path recursively, but just like in the case if the change problem we will end up with a very inefficient code. Let&amp;rsquo;s instead pre-fill our matrix using the following logic:&lt;/p&gt;

&lt;div&gt;

$$s_i,_j = max\begin{cases} s_{i-1,j} + weight\ of\ the\ edge\ between\ (i - 1, j)\ and\ (i,j)
                         &amp; \\ s_{i,j-1} + weight\ of\ the\ edge\ between\ (i, j - 1)\ and\ (i,j)
                 
                 \end{cases}$$

&lt;/div&gt;

&lt;p&gt;This will result in the following progression:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid1.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid2.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid4.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid3.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td&gt;&lt;img src=&#34;http://www.bx.psu.edu/~anton/bioinf-images/grid6.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;From &lt;a href=&#34;http://www.amazon.com/Introduction-Bioinformatics-Algorithms-Computational-Molecular/dp/0262101068/&#34;&gt;JP&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;You can see that wandering from the source may get us into a dead end. However, backtracking from the sink will always get us to source along the longest path! This by pre-computing the matrix we can easily solve the Manhattan tourist problem. Now we are ready to tackle sequence alignment problems.&lt;/p&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/182594750&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;

</description>
    </item>
    
    <item>
      <title>2. DNA sequencing</title>
      <link>https://nekrut.github.io/BMMB554/post/topic2/</link>
      <pubDate>Tue, 17 Jan 2017 11:17:20 -0400</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic2/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/illumina_pseudocolor.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;the-60s-and-the-70s&#34;&gt;The 60s and the 70s&lt;/h1&gt;

&lt;p&gt;The first complete nucleic acids being sequenced were RNAs (tRNAs in particular; see pioneering work of &lt;a href=&#34;http://www.ncbi.nlm.nih.gov/pubmed/14263761&#34;&gt;Robert Holley and colleagues&lt;/a&gt;). The work on finding approaches to sequencing DNA molecules began in late 60s and early 70s. One of the earliest contributions has been made by Ray Wu from Cornell, who used &lt;em&gt;E. coli&lt;/em&gt; DNA polymerase to &lt;a href=&#34;http://www.sciencedirect.com/science/article/pii/0022283670900045&#34;&gt;incorporate radioactively labelled nucleotides into protruding ends of bacteriphage lambda&lt;/a&gt;. It took several more years for the development of more &amp;ldquo;high throughput&amp;rdquo; technologies by Sanger and Maxam/Gilbert. The Sanger technique has ultimately won over Maxam/Gilbert&amp;rsquo;s protocol due to its relative simplicity (once dideoxynucleotides has become commercially available) and the fact that it required smaller amount of starting material as the polymerase was used to generate fragments necessary for sequence determination.&lt;/p&gt;

&lt;h1 id=&#34;original-approaches-were-laborious&#34;&gt;Original approaches were laborious&lt;/h1&gt;

&lt;p&gt;In the original &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger paper&lt;/a&gt; the authors sequenced bacteriophage phiX174 by using its own restriction fragments as primers. This was an ideal set up to show the proof of principle for the new method. This is because phiX174 DNA is homogeneous and can be isolated in large quantities. Now suppose that you would like to sequence a larger genome (say &lt;em&gt;E. coli&lt;/em&gt;). Remember that the original version of Sanger method can only sequence fragments up to 200 nucleotides at a time. So to sequence the entire &lt;em&gt;E. coli&lt;/em&gt; genome (which by-the-way was not sequenced until &lt;a href=&#34;http://science.sciencemag.org/content/277/5331/1453&#34;&gt;1997&lt;/a&gt;) you would need to split the genome into multiple pieces and sequence each of them individually. This is hard, because to produce a readable Sanger sequencing gel each sequence must be amplified to a suitable amount (around 1 nanogram) and be homogeneous (you cannot mix multiple DNA fragments in a single reaction as it will be impossible to interpret the gel). Molecular cloning enabled by the availability of commercially available restriction enzymes and cloning vectors simplified this process. Until the onset of next generation sequencing in 2005 the process for sequencing looked something like this:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(&lt;strong&gt;1&lt;/strong&gt;) - Generate a collection of fragments you want to sequence. It can be a collection of fragments from a genome that was mechanically sheared or just a single fragment generated by PCR.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;2&lt;/strong&gt;) - These fragment(s) are then cloned into a plasmid vector (we will talk about other types of vectors such as BACs later in the course).&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;3&lt;/strong&gt;) - Vectors are transformed into bacterial cells and positive colonies (containing vectors with insert) are picked from an agar plate.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;4&lt;/strong&gt;) - Each colony now represents a unique piece of DNA.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;5&lt;/strong&gt;) - An individual colony is used to seed a bacterial culture that is grown overnight.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;6&lt;/strong&gt;) - Plasmid DNA is isolated from this culture and now can be used for sequencing because it is (1) homogeneous and (2) we now a sufficient amount.&lt;/li&gt;
&lt;li&gt;(&lt;strong&gt;7&lt;/strong&gt;) - It is sequenced using universal primers. For example the image below shows a map for pGEM-3Z plasmid (a pUC18 derivative). Its multiple cloning site is enlarged and sites for &lt;strong&gt;T7&lt;/strong&gt; and &lt;strong&gt;SP6&lt;/strong&gt; sequencing primers are shown. These are the &lt;strong&gt;pads&lt;/strong&gt; I&amp;rsquo;m referring to in the lecture. These provide universal sites that can be used to sequence any insert in between.&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/pgem3z.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from Promega, Inc.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Until the invention of NGS the above protocol was followed with some degree of automation. But you can see that it was quite laborious if the large number of fragements needed to be sequenced. This is because each of them needed to be subcloned and handled separately. This is in part why Human Genome Project, a subject of our next lecture, took so much time to complete.&lt;/p&gt;

&lt;h2 id=&#34;evolution-of-sequencing-machines&#34;&gt;Evolution of sequencing machines&lt;/h2&gt;

&lt;p&gt;The simplest possible sequencing machine is a &lt;a href=&#34;https://en.wikipedia.org/wiki/Polyacrylamide_gel_electrophoresis&#34;&gt;gel rig with polyacrylamide gel&lt;/a&gt;. Sanger used it is his protocol obtaining the following results:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/sangerGel.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;Sanger et al. 1977&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here for sequencing each fragment four separate reactions are peformed (with ddA, ddT, ggC, and ddG) and four lanes on the gel are used. One simplification of this process that came in the 90s was to use fluorescently labelled dideoxy nucleotides. This is easier because everything can be performed in a single tube and uses a single lane on a gel:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;
&lt;figure &gt;
    
        &lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/dd_labels.png&#34; /&gt;
    
    
&lt;/figure&gt;

Figure from Applied Biosystems &lt;a href=&#34;https://www3.appliedbiosystems.com/cms/groups/mcb_support/documents/generaldocuments/cms_041003.pdf&#34;&gt;support site&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;However, there is still substantial labor involved in pouring the gels, loading them, running machines, and cleaning everything post-run. A significant improvement was offered by the development of capillary electrophoresis allowing automation of liquid handling and sample loading. Although several manufacturers have been developing and selling such machines a &lt;em&gt;de facto&lt;/em&gt; standard in this area was (and still is) the Applied Biosystems (ABI) Genetics and DNA Anlayzer systems. The highest throughput ABI system, 3730&lt;em&gt;xl&lt;/em&gt;, had 96 capillaries and could automatically process 384 samples.&lt;/p&gt;

&lt;h1 id=&#34;ngs&#34;&gt;NGS!&lt;/h1&gt;

&lt;p&gt;384 samples may sound like a lot, but it is nothing if we are sequencing an entire genome. The beauty of NGS is that these technologies are not bound by sample handling logistics. They still require preparation of libraries, but once a library is made (which can be automated) it is processed more or less automatically to generate multiple copies of each fragment (in the case of 454, Illumina, and Ion Torrent) and loaded onto the machine, where millions of individual fragments are sequenced simultaneously. The following videos and slides explains how these technologies work.&lt;/p&gt;

&lt;h2 id=&#34;watch-introductory-video&#34;&gt;Watch introductory video&lt;/h2&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/181072208&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h1 id=&#34;ngs-in-depth&#34;&gt;NGS in depth&lt;/h1&gt;

&lt;h2 id=&#34;1-454-sequencing&#34;&gt;1: 454 sequencing&lt;/h2&gt;

&lt;p&gt;454 Technology is a massively parallel modification of &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;pyrosequencing&lt;/a&gt; technology. Incorporation of nucleotides are registered by a &lt;a href=&#34;https://en.wikipedia.org/wiki/Charge-coupled_device&#34;&gt;CCD&lt;/a&gt; camera as a flash of light generated from the interaction between ATP and Luciferin. The massive scale of 454 process is enabled by generation of a population of beads carrying multiple copies of the same DNA fragment. The beads are distributed across a microtiter plate where each well of the plate holding just one bead. Thus every unique coordinate (a well) on the plate generates flashes when a nucleotide incorporation event takes plate. This is &amp;ldquo;monochrome&amp;rdquo; technique: flash = nucleotide is incorporated; lack of flash = no incorporation. Thus to distinguish between A, C, G, and T individual nucleotides are &amp;ldquo;washed&amp;rdquo; across the microtiter plate at discrete times: if &lt;strong&gt;A&lt;/strong&gt; is being washed across the plate and a flash of light is emitted, this implies that A is present in the fragment being sequenced.&lt;/p&gt;

&lt;p&gt;454 can generated fragments up 1,000 bases in length. Its biggest weakness is inability to precisely determine the length of &lt;a href=&#34;https://www.broadinstitute.org/crd/wiki/index.php/Homopolymer&#34;&gt;homopolymer runs&lt;/a&gt;. Thus the main type if sequencing error generated by 454 are insertions and deletions (indels).&lt;/p&gt;

&lt;h3 id=&#34;slides&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;28bd628499b54d09b4f9c6e7534c7e8f&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121286060&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-454#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;reading&#34;&gt;Reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://genome.cshlp.org/content/11/1/3&#34;&gt;Overview of pyrosequencing methodology - Ronaghi&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.nature.com/nature/journal/v437/n7057/pdf/nature03959.pdf&#34;&gt;Description of 454 process - Margulies et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://link.springer.com/protocol/10.1385/1-59745-377-3:1&#34;&gt;History of pyrosequencing - Pål Nyrén&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2007 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2007-8-7-r143.pdf&#34;&gt;Errors in 454 data - Huse et al. &lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://bioinformatics.oxfordjournals.org/content/26/18/i420.full.pdf+html&#34;&gt;Properties of 454 data - Balzer et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;2-illumina-sequencing&#34;&gt;2: Illumina sequencing&lt;/h2&gt;

&lt;p&gt;Illumina (originally called &amp;ldquo;Solexa&amp;rdquo;) uses glass flowcells with oligonucleotides permanently attached to internal surface. These oligonucleotides are complementary to sequencing adapters added to DNA fragments being sequenced during library preparation. The DNA fragements that are &amp;ldquo;stuck&amp;rdquo; on the flowcell due to complementary interaction between adapters are amplified via &amp;ldquo;bridge amplification&amp;rdquo; to form clusters. Sequencing is performed using reversible terminator chemistry with nucleotides modified to carry dyes specific to each nucleotide. As a result all nucleotides can be added at once and are distinguished by colors. Currently, it is possible to sequence up to 300 bases from each end of the fragment being sequenced. Illumina has the highest throughput (and lowest cost per base) of all existing technologies at this moment. The HiSeq 2500 machine can produce &lt;a href=&#34;http://www.illumina.com/systems/hiseq_2500_1500/performance_specifications.html&#34;&gt;600 billion nucleotides in 5 days&lt;/a&gt;. In this course we will most often work with Illumina data.&lt;/p&gt;

&lt;h3 id=&#34;slides-1&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;942908c8c24546d58cf8b61b3598feb3&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video-1&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121178846&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-illumina#&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-1&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.nature.com/nature/journal/v456/n7218/pdf/nature07517.pdf&#34;&gt;Human genome sequencing on Illumina - Bentley et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://nar.oxfordjournals.org/content/39/13/e90.full-text-lowres.pdf&#34;&gt;Data quality 1 - Nakamura et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://genomebiology.com/content/pdf/gb-2011-12-11-r112.pdf&#34;&gt;Data quality 2 - Minoche et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2011 | &lt;a href=&#34;http://www.biomedcentral.com/content/pdf/1471-2164-12-382.pdf&#34;&gt;Illumina pitfalls - Kircher et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;10x-a-way-to-extend-the-utility-of-short-illumina-reads&#34;&gt;10X: A way to extend the utility of short Illumina reads&lt;/h3&gt;

&lt;p&gt;A company called &lt;a href=&#34;http://www.10xgenomics.com/technology/&#34;&gt;10X Genomics&lt;/a&gt; has developed a technology which labels reads derived from continuous fragments of genomic DNA. In this technology a gel bead covered with a large number of adapter molecules is placed within a droplet containing PCR reagents and one or several long molecules of genomic DNA to be sequenced.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/10x.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10X bead&lt;/strong&gt; containing the standard Illumina P5 adapter combined with barcode, sequencing primer annealing site (R1) and random primer (N-mer) Slide from &lt;a href=&#34;http://www.slideshare.net/GenomeInABottle/aug2015-analysis-team-04-10x-genomics&#34;&gt;Slideshare&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The droplets are generated by combining beads, PCR reagents, and genomic DNA in a microfluidic device:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;http://www.nature.com/nbt/journal/v34/n3/fig_tab/nbt.3432_F1.html&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/10x-overview.jpg&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;10X workflow&lt;/strong&gt; (&lt;strong&gt;a&lt;/strong&gt;) Gel beads loaded with primers and barcoded oligonucleotides are mixed with DNA and enzyme mixture then oil-surfactant solution at a microfluidic &amp;lsquo;double-cross&amp;rsquo; junction. Gel bead–containing droplets flow to a reservoir where gel beads are dissolved, initiating whole-genome primer extension. The products are pooled from each droplet. The final library preparation requires shearing the libraries and incorporation of Illumina adapters. (&lt;strong&gt;b&lt;/strong&gt;) Top, linked reads of the ALK gene from the NA12878 WGS sample. Lines represent linked reads; dots represent reads; color indicates barcode. Middle, exon boundaries of the ALK gene. Bottom, linked reads of the ALK gene from the NA12878 exome data. Reads from neighboring exons are linked by common barcodes. Only a small fraction of linked reads is presented here. Reproduced from &lt;a href=&#34;http://www.nature.com/nbt/journal/v34/n3/full/nbt.3432.html&#34;&gt;Zheng:2015&lt;/a&gt; (click the image to go to the original paper).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In essence, 10X allows to uniquely map reads derived from long genomic fragments. This information is essential for bridging together genome and transcriptome assemblies as we will see in later in this course.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/120429438&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h2 id=&#34;3-pacbio-single-molecule-sequencing&#34;&gt;3: PacBio Single Molecule Sequencing&lt;/h2&gt;

&lt;p&gt;PacBio is a fundamentally different approach to DNA sequencing as it allows reading single molecules. Thus it is an example is so called &lt;em&gt;Single Molecule Sequencing&lt;/em&gt; or &lt;em&gt;SMS&lt;/em&gt;. PacBio uses highly processive DNA polymerase placed at the bottom of each well on a microtiter plate. The plate is fused to the glass slide illuminated by a laser. When polymerase is loaded with template it attracts fluorescently labeled nucleotides to the bottom of the well where they emit light with a wavelength characteristic of each nucleotide. As a result a &amp;ldquo;movie&amp;rdquo; is generated for each well recording the sequence and duration of incorporation events. One of the key advantage of PacBio technology is its ability to produce long reads with ones at 10,000 bases being common.&lt;/p&gt;

&lt;h3 id=&#34;slides-2&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;ccb3d34f1a214f66ac7a2d233caedaf5&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;h3 id=&#34;video-2&#34;&gt;Video&lt;/h3&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/121267426&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;p&gt;Underlying slides are &lt;a href=&#34;https://speakerdeck.com/nekrut/ngs-technologies-pacific-biosceinces&#34;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;reading-2&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2003 | &lt;a href=&#34;http://www.sciencemag.org/content/299/5607/682.full.pdf&#34;&gt;Single Molecule Analaysis at High Concentration - Levene et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2008 | &lt;a href=&#34;http://www.pnas.org/content/105/4/1176.full&#34;&gt;ZMW nanostructures - Korlach et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2009 | &lt;a href=&#34;http://www.sciencemag.org/content/323/5910/133.full&#34;&gt;Real Time Sequencing with PacBio - Eid et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2010 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v7/n6/pdf/nmeth.1459.pdf&#34;&gt;Modification detection with PacBio - Flusberg et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://www.nature.com/nbt/journal/v30/n7/pdf/nbt.2280.pdf&#34;&gt;Error correction of PacBio reads - Koren et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.pnas.org/cgi/doi/10.1073/pnas.1400447111&#34;&gt;Transcriptome with PacBio - Taligner et al.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://dx.doi.org/10.1038/nature13907&#34;&gt;Resolving complex regions in Human genomes with PacBio - Chaisson et al.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;4-oxford-nanopore&#34;&gt;4: Oxford Nanopore&lt;/h2&gt;

&lt;p&gt;Oxford nanopore is another dramatically different technology that threads single DNA molecules through biologically-derived (transmembrane proteins) pore in a membrane impermeable to ions. It uses polymerase to control the speed of translocation of the DNA molecule through membrane. In that sense it is not &lt;em&gt;Sequencing by synthesis&lt;/em&gt; we have seen in the other technologies discussed here. This technology generates longest reads possible today: in many instances a single read can be hundreds of thousands if nucleotides in length. It still however suffers from high error rate and relatively low throughput (compared to Illumina). On the upside Oxford Nanopore sequencing machines are only slightly bigger than a thumb-drive and cost very little.&lt;/p&gt;

&lt;h3 id=&#34;slides-3&#34;&gt;Slides&lt;/h3&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;3895a3069bc64ad5bc74c972a0353911&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;p&gt;A recent overview of latest developments at Oxford Nanopore can be found &lt;a href=&#34;https://github.com/lmmx/talk-transcripts/blob/master/Nanopore/NoThanksIveAlreadyGotOne.md&#34;&gt;here&lt;/a&gt; as well as in the following video&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//www.youtube.com/embed/nizGyutn6v4&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; allowfullscreen frameborder=&#34;0&#34;&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;h3 id=&#34;reading-3&#34;&gt;Reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;2016 | &lt;a href=&#34;http://nature.com/nnano/journal/v11/n2/full/nnano.2016.9.html&#34;&gt;The promises and challenges of solid-state sequencing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://nature.com/nmeth/journal/v12/n4/full/nmeth.3290.html&#34;&gt;Improved data analysis for the minion nanopore sequencer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4722697/&#34;&gt;MinION Analysis and Reference Consortium&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2015 | &lt;a href=&#34;http://www.nature.com/nmeth/journal/v12/n8/full/nmeth.3444.html&#34;&gt;A complete bacterial genome assembled &lt;em&gt;de novo&lt;/em&gt; using only nanopore sequencing data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2012 | &lt;a href=&#34;http://nature.com/nbt/journal/v30/n4/full/nbt.2171.html&#34;&gt;Reading DNA at single-nucleotide resolution with a mutant MspA nanopore and phi29 DNA polymerase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Simpson Lab &lt;a href=&#34;http://simpsonlab.github.io/2015/04/08/eventalign/&#34;&gt;blog&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Poretools analysis &lt;a href=&#34;http://poretools.readthedocs.org/&#34;&gt;suite&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>1. History</title>
      <link>https://nekrut.github.io/BMMB554/post/topic1/</link>
      <pubDate>Wed, 11 Jan 2017 11:41:14 -0500</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/topic1/</guid>
      <description>

&lt;p&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/luria_small.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;why-history&#34;&gt;Why history?&lt;/h1&gt;

&lt;p&gt;Knowing history is essential for understanding how we arrived to the current state of affairs in our field. It is also full of acciental discoveries and dramatic relationships making it quite interesting to read about. I strongly advise you to take a look at the mansucripts below.&lt;/p&gt;

&lt;h2 id=&#34;classical-publications&#34;&gt;Classical publications&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;1965 | &lt;a href=&#34;http://www.amazon.com/A-History-Genetics-A-H-Sturtevant/dp/0879696079&#34;&gt;A history of genetics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1943 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;Delbruck &amp;amp; Luria&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1944 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/avery-1944.pdf&#34;&gt;Avery, MacLeod, &amp;amp; McCarty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1952 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/hershey-chase-1952.pdf&#34;&gt;Herhey &amp;amp; Chase&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1953 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/watsoncrick.pdf&#34;&gt;Watson &amp;amp; Crick&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1958 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/Proc%20Natl%20Acad%20Sci%20USA%201958%20Meselson.pdf&#34;&gt;Meselson &amp;amp; Stahl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1960 | &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/jacob-monod-1961.pdf&#34;&gt;Jacob and Monod&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;popular-yet-very-informative-literature&#34;&gt;Popular (yet very informative) literature&lt;/h2&gt;

&lt;p&gt;Get one of these and read it on a plane:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;1978 | &lt;a href=&#34;https://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Molecular Gemetics: An Itroductory Narrative&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2001 | &lt;a href=&#34;http://www.amazon.com/The-Double-Helix-Discovery-Structure/dp/074321630X&#34;&gt;The double helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2005 | &lt;a href=&#34;http://www.amazon.com/Third-Man-Double-Helix-Autobiography/dp/019280667X&#34;&gt;The Third Man of the Double Helix&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014 | &lt;a href=&#34;http://www.amazon.com/Brave-Genius-Philosopher-Adventures-Resistance/dp/0307952347&#34;&gt;Brave Genius&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;publication-highlight-the-fluctuation-test&#34;&gt;Publication highlight | The fluctuation test&lt;/h1&gt;

&lt;p&gt;In a truly collaborative spirit a german physicist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/delbruck-facts.html&#34;&gt;Max Delbrück&lt;/a&gt; joined forces with an italian microbiologist &lt;a href=&#34;http://www.nobelprize.org/nobel_prizes/medicine/laureates/1969/luria-facts.html&#34;&gt;Salvador Luria&lt;/a&gt; to prove the stochastic nature of mutations and to reject &amp;ldquo;the last stroghold of Lamarckism&amp;rdquo;. This &lt;a href=&#34;http://www.bx.psu.edu/~anton/bioinf1-2014/delbruck-luria-1943.pdf&#34;&gt;classical work&lt;/a&gt; was published in 1943 in journal &lt;em&gt;Genetics&lt;/em&gt;. Here we re-examine some of the fundamental aspects of this work. In this we occasionally rely on a classical textbook in &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Molecular Genetics&lt;/a&gt; by Günther Stent.&lt;/p&gt;

&lt;p&gt;So, it has been know for some time that:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Bacteria sensitive (infectable) by phage becomes resistant as a result of exposure to bacteriophage&lt;/li&gt;
&lt;li&gt;The resistance is preserved when descendants of these cells are incubated&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This can, in principle, be explained by two mutually exclusive hypotheses:&lt;/p&gt;

&lt;h2 id=&#34;acquired-resistance-vs-spontaneous-mutation&#34;&gt;Acquired resistance vs. spontaneous mutation&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;direct action of phage on bacteria triggers &amp;ldquo;acquisition&amp;rdquo; of the resistance;&lt;/li&gt;
&lt;li&gt;some cells in a population already have a mutation conferring the resistance and the exposure to the phage merely brings carriers of such mutations to prominence by killing off all sensitive cells.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;How can we distinguish between these two alternative possibilities? Let&amp;rsquo;s try to put hypothesis (1) into quantitative framework:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are two bacterial phenotypes: &lt;em&gt;S&lt;/em&gt; - sensitive (is lysed by the phage) and &lt;em&gt;R&lt;/em&gt; - resistant (is not lysed and does not absorb phage)&lt;/li&gt;
&lt;li&gt;Bacterial population progresses from a single cell to $N$ cells&lt;/li&gt;
&lt;li&gt;The probability of changing from &lt;em&gt;S&lt;/em&gt; to &lt;em&gt;R&lt;/em&gt; is $a$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;So, if one grows $S$ bacteria in a culture and then plates them on agar containing excess of phage, where will be $n$ of $R$ colonies, where $n =  aN$. Since we can estimate $n$ directly (by counting colonies on the plate) and $N$ is also known (a function of the number of generations) the fraction of $R$ individuals in a population is going to be same for all stages of the population:&lt;/p&gt;

&lt;div&gt;
$$

\frac{n}{N} = a

$$
&lt;/div&gt;

&lt;p&gt;This will not be quite the same for hypothesis (2) since the number of cells carrying the resistance mutation will differ depending on when in population history they occurred and how many generation have passed since their occurrence. After $g$ generations there will be&lt;/p&gt;

&lt;div&gt;
$$

N = 2^g

$$
&lt;/div&gt;

&lt;p&gt;cells. Consequently, if the probability of mutation is $a$, then by $i$-th generation there will be $a2^i$ cells carrying mutations and we can arrive to the ratio of&lt;/p&gt;

&lt;div&gt;
$$

\frac{n}{N} = ga

$$
&lt;/div&gt;

&lt;p&gt;Delbück and Luria&amp;rsquo;s experience with estimating such ratio has proven to be difficult as they were observing great fluctuation in the number of $R$ cells. They have subsequently realized that such fluctuation was in fact an indirect indication that the mutation hypothesis is likely true. Delbrück has developed a theoretical framework predicting the distribution of mutant phenotypes for both hypotheses. &lt;a href=&#34;http://www.amazon.com/Molecular-Genetics-Introductory-Gunther-Stent/dp/0716700484&#34;&gt;Stent&lt;/a&gt; provides the following elegant description of Delbück&amp;rsquo;s reasonong. It is based on measuring the variance in the number of resistant colonies across a number of replicates. Suppose there are $c$ &lt;em&gt;E. coli&lt;/em&gt; replicates (cultures) started from a single &lt;em&gt;S&lt;/em&gt; bacterium. Each is grown for $g$ generations, and each accumulates $N = 2^g$ cells as a result. The entire content of each culture is then spread over agar plate saturated with the phage. The number $n$ of &lt;em&gt;R&lt;/em&gt; colonies is then counted. If $n_j$ is the number of &lt;em&gt;R&lt;/em&gt; colonies from culture $j$, then the average of the numbner of resistant colonies is:&lt;/p&gt;

&lt;div&gt;
$$

\bar{n} = \frac{\sum_{j=1}^{c}n_j}{c}

$$
&lt;/div&gt;

&lt;p&gt;and the variance is:&lt;/p&gt;

&lt;div&gt;
$$ 

var_n = \frac{\sum_{j=1}^{c}(\bar{n}-n_j)}{c}

$$
&lt;/div&gt;

&lt;p&gt;The behaviour of ratio of &lt;code&gt;variance/average&lt;/code&gt; is critical to distinguishing between hypothesis (1) and (2). If (1) is true we expect low fluctuation and the ratio will be close to 1. If (2) is true the variation will be considerable and the ratio will be much higher than one. Look at Fig. 1 below.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;In pane A (Hypothesis 1) phage induces changes in the bacteria upon plating and because the probability of changing from &lt;code&gt;S&lt;/code&gt; to &lt;code&gt;R&lt;/code&gt; is the same for  all cells we would see approximately the same number of &lt;code&gt;R&lt;/code&gt; cells. The mean here is &lt;code&gt;2.5&lt;/code&gt; and the variance/mean ratio is &lt;code&gt;1.1&lt;/code&gt;.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;In pane B (Hypothesis 2) every cell has the same mutation rate, but the mutations may occur at any point during the culture propagation. If they occur early - many resistant colonies will be produced from such culture. If they occur late - just a few. As a result one would expect to see significant fluctuation. Here the mean is the same as in A = &lt;code&gt;2.5&lt;/code&gt;, but the variance/mean ratio is much higher at &lt;code&gt;4.3&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/luria.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;img src=&#34;https://nekrut.github.io/BMMB554/BMMB554/img/stent.png&#34; alt=&#34;&#34; /&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Figure 1&lt;/strong&gt; (Fig. 6-4 from Stent)&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;&lt;strong&gt;Table 1&lt;/strong&gt; (Table 6-1 from Stent)&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Table 1 settles these issues. Here one can see a significant fluctuation across 20 independent experiments with the main of &lt;code&gt;11.3&lt;/code&gt; and variance/mean ratio of &lt;code&gt;61&lt;/code&gt;. This table also show the result of plating aliquots from a bulk culture. In this case 10 ml culture was incubated for the same duration as the 20 independent cultures. Small amount from this culture were then plated on 10 independent plates. Because these cells share their genetic ancestry there is very little variation across these platings.&lt;/p&gt;

&lt;p&gt;This paper settled one of the most contentious issues in biology and won the Nobel prize to its authors.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;slides&#34;&gt;Slides&lt;/h1&gt;

&lt;p&gt;Slides covering material for Lecture 1&lt;/p&gt;

&lt;script async class=&#39;speakerdeck-embed&#39; data-id=&#39;7726e8b8b3ee41f0a2a1497128d59ca0&#39; data-ratio=&#39;1.33333333333333&#39; src=&#39;//speakerdeck.com/assets/embed.js&#39;&gt;&lt;/script&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;

&lt;p&gt;Video presentation from last year.&lt;/p&gt;


&lt;div style=&#34;position: relative; padding-bottom: 56.25%; padding-top: 30px; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;//player.vimeo.com/video/180735569&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%;&#34; webkitallowfullscreen mozallowfullscreen allowfullscreen&gt;&lt;/iframe&gt;
 &lt;/div&gt;


&lt;hr /&gt;

&lt;h1 id=&#34;what-to-do-before-next-lecture&#34;&gt;What to do before next lecture&lt;/h1&gt;

&lt;p&gt;Read two following papers:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;DNA sequencing with chain-terminating inhibitors&amp;rdquo; by Sanger, Nicklen, and Coulson (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC431765/pdf/pnas00043-0271.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;A new method for sequencing DNA&amp;rdquo; by Maxam and Gilbert (&lt;a href=&#34;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC392330/pdf/pnas00024-0174.pdf&#34;&gt;1977&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Syllabus</title>
      <link>https://nekrut.github.io/BMMB554/post/syllabus/</link>
      <pubDate>Mon, 09 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://nekrut.github.io/BMMB554/post/syllabus/</guid>
      <description>

&lt;p&gt;&lt;a href=&#34;https://xkcd.com/451/&#34;&gt;&lt;img src=&#34;http://imgs.xkcd.com/comics/impostor.png&#34; alt=&#34;&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;instructor&#34;&gt;Instructor&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;Anton Nekrutenko&lt;/strong&gt;&lt;br&gt;
&lt;a href=&#34;mailto:aun1@psu.edu?Subject=BMMB554&#34;&gt;aun1@psu.edu&lt;/a&gt;&lt;br&gt;
Wartik 505&lt;br&gt;
Office hours by appointment only&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;&lt;font color=&#34;orange&#34;&gt;&amp;#9888;&lt;/font&gt; When contacting instructor use the above e-mail and include &amp;ldquo;BMMB554&amp;rdquo; in the subject line (simply click on e-mail address).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;course-description&#34;&gt;Course description&lt;/h1&gt;

&lt;p&gt;This course is designed as a preparation routine for graduate students in Life Sciences. It has several focus areas including evolution of life sciences as well as in-depth overview of sequencing technologies and their applications.&lt;/p&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;grading&#34;&gt;Grading&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;Homework = 50%&lt;/li&gt;
&lt;li&gt;Final project = 50%&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h1 id=&#34;topics&#34;&gt;Topics&lt;/h1&gt;

&lt;p&gt;We will cover a breadth of topics. Below is the approximate list. Keep in mind that this field is very dynamic. To account for that we may skip or extend some of the subjects.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;History: From Genetics to Genomics&lt;/li&gt;
&lt;li&gt;Sequencing: From Sanger to Nanopores I&lt;/li&gt;
&lt;li&gt;Sequencing: From Sanger to Nanopores II&lt;/li&gt;
&lt;li&gt;Algorithms: Alignment Basics&lt;/li&gt;
&lt;li&gt;Algorithms: Aligning many sequences quickly&lt;/li&gt;
&lt;li&gt;Algorithms: Assembly I&lt;/li&gt;
&lt;li&gt;Algorithms: Assembly II&lt;/li&gt;
&lt;li&gt;Galaxy: An introduction&lt;/li&gt;
&lt;li&gt;Galaxy: Writing your own tools&lt;/li&gt;
&lt;li&gt;Re-sequencing I: Introduction and non-diploid case&lt;/li&gt;
&lt;li&gt;Re-sequencing II: Diploid genomes&lt;/li&gt;
&lt;li&gt;Practicum: Re-sequencing&lt;/li&gt;
&lt;li&gt;Transcriptomics I: Refrence-based&lt;/li&gt;
&lt;li&gt;Transcriptomics II: Reference-free&lt;/li&gt;
&lt;li&gt;Practicum: Transcriptomics&lt;/li&gt;
&lt;li&gt;RNA analysis: RiboSeq and ShapeSeq&lt;/li&gt;
&lt;li&gt;Practicum: RNA analysis&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions I: Approaches&lt;/li&gt;
&lt;li&gt;DNA/Protein interactions II: ENCODE Project&lt;/li&gt;
&lt;li&gt;Practicum: DNA/Protein interactions&lt;/li&gt;
&lt;li&gt;Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Practicum: Genome conformation analysis&lt;/li&gt;
&lt;li&gt;Metagenomics I: Approaches&lt;/li&gt;
&lt;li&gt;Metagenomics II: Community analysis&lt;/li&gt;
&lt;li&gt;Practicum: Metagenomics&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;blockquote&gt;
&lt;p&gt;In an examination setting, unless the instructor gives explicit prior instructions to the contrary, violations of academic integrity shall consist of any attempt to receive assistance from written or printed aids, from any person or papers or electronic devices, or of any attempt to give assistance, whether the student doing so has completed his or her own work or not. Other violations include, but are not limited to, any attempt to gain an unfair advantage in regard to an examination, such as tampering with a graded exam or claiming another&amp;rsquo;s work to be one&amp;rsquo;s own. Other assessments (including ANGEL-administered quizzes and assessments as well as homework assignments) are expected to represent your own independent work unless specifically stated otherwise. Failure to comply will lead to sanctions against the student in accordance with the Policy on Academic Integrity in the Eberly College of Science. The Eberly College of Science Code of Mutual Respect and Cooperation (www.science.psu.edu/climate/Code-of-Mutual-Respect-final.pdf) embodies the values that we hope our faculty, staff, and students possess and will endorse to make The Eberly College of Science a place where every individual feels respected and valued, as well as challenged and rewarded.   The Eberly College of Science is committed to the academic success of students enrolled in the College&amp;rsquo;s  courses and undergraduate programs. When in need of help, students can utilize various College and University wide resources for learning assistance (&lt;a href=&#34;http://www.science.psu.edu/advising/success&#34;&gt;http://www.science.psu.edu/advising/success&lt;/a&gt;). Penn State welcomes students with disabilities into the University&amp;rsquo;s educational programs. If you have a disability-related need for reasonable academic adjustments in this course, contact the Office for Disability Services (ODS) at 814-863-1807 (V/TTY). For further information regarding ODS, please visit the Office for Disability Services Web site at &lt;a href=&#34;http://equity.psu.edu/ods/.  &#34;&gt;http://equity.psu.edu/ods/.  &lt;/a&gt; In order to receive consideration for course accommodations, you must contact ODS and provide documentation (see the &lt;a href=&#34;http://equity.psu.edu/student-disability-resources/guidelines&#34;&gt;documentation guidelines&lt;/a&gt;). If the documentation supports the need for academic adjustments, ODS will provide a letter identifying appropriate academic adjustments. Please share this letter and discuss the adjustments with your instructor as early in the course as possible. You must contact ODS and request academic adjustment letters at the beginning of each semester.&lt;/p&gt;
&lt;/blockquote&gt;
</description>
    </item>
    
  </channel>
</rss>